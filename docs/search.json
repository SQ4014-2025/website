[
  {
    "objectID": "problems/pset_8/pset_8.html",
    "href": "problems/pset_8/pset_8.html",
    "title": "Problem Set week 8",
    "section": "",
    "text": "Complete the following problems\n\nSeasons of Love\nCookie Jar",
    "crumbs": [
      "Problem Sets",
      "Problem Set 08 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_8/pset_8.html#what-to-do",
    "href": "problems/pset_8/pset_8.html#what-to-do",
    "title": "Problem Set week 8",
    "section": "",
    "text": "Complete the following problems\n\nSeasons of Love\nCookie Jar",
    "crumbs": [
      "Problem Sets",
      "Problem Set 08 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_8/8.2_seasons_of_love.html",
    "href": "problems/pset_8/8.2_seasons_of_love.html",
    "title": "Seasons of Love",
    "section": "",
    "text": "Five hundred twenty-five thousand, six hundred minutes\nFive hundred twenty-five thousand moments so dear\nFive hundred twenty-five thousand, six hundred minutes\nHow do you measure, measure a year?\n‚Äî ‚ÄúSeasons of Love,‚Äù Rent\n\nAssuming there are 365 days in a year, there are (365 = 525,600) minutes in that same year (because there are 24 hours in a day and 60 minutes in an hour). But how many minutes are there in two or more years? Well, it depends on how many of those are leap years with 366 days, per the Gregorian calendar, as some of them could have (1 = 1,440) additional minutes. In fact, how many minutes has it been since you were born? Well, that, too, depends on how many leap years there have been since! There is an algorithm for such, but let‚Äôs not reinvent that wheel. Let‚Äôs use a library instead. Fortunately, Python comes with a datetime module that has a class called date that can help, per docs.python.org/3/library/datetime.html#date-objects.\nIn a file called seasons.py, implement a program that prompts the user for their date of birth in YYYY-MM-DD format and then sings prints how old they are in minutes, rounded to the nearest integer, using English words instead of numerals, just like the song from Rent, without any and between words. Since a user might not know the time at which they were born, assume, for simplicity, that the user was born at midnight (i.e., 00:00:00) on that date. And assume that the current time is also midnight. In other words, even if the user runs the program at noon, assume that it‚Äôs actually midnight, on the same date. Use datetime.date.today to get today‚Äôs date, per docs.python.org/3/library/datetime.html#datetime.date.today.\nStructure your program per the below, not only with a main function but also with one or more other functions as well:\nfrom datetime import date\n\n\ndef main():\n    ...\n\n\n...\n\n\nif __name__ == \"__main__\":\n    main()\n\nYou‚Äôre welcome to import other (built-in) libraries, or any that are specified in the below hints. Exit via sys.exit if the user does not input a date in YYYY-MM-DD format. Ensure that your program will not raise any exceptions.\nEither before or after you implement seasons.py, additionally implement, in a file called test_seasons.py, one or more functions that test your implementation of any functions besides main in seasons.py thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_seasons.py\n\n\n\n\nNote that the date class comes with quite a few methods and ‚Äúsupported operations,‚Äù per docs.python.org/3/library/datetime.html#date-objects. In particular, the class implements __sub__, per docs.python.org/3/library/operator.html#operator.__sub__, overloading - in such a way that subtracting one date object from another returns a timedelta object, which itself comes with several (read-only) ‚Äúinstance attributes,‚Äù per docs.python.org/3/library/datetime.html#timedelta-objects.\nNote that the inflect module comes with quite a few methods, per pypi.org/project/inflect. You can install it with:\npip install inflect\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir seasons\n\nto make a folder called seasons in your codespace.\nThen execute\ncd seasons\n\nto change directories into that folder. You should now see your terminal prompt as seasons/ $. You can now execute\ncode seasons.py\n\nto make a file called seasons.py where you‚Äôll write your program. Be sure to also execute\ncode test_seasons.py\n\nto create a file called test_seasons.py where you‚Äôll write tests for your program.\n\n\n\n\n\nHere‚Äôs how to test seasons.py manually:\n\nRun your program with python seasons.py. Ensure your program prompts you for a birthdate. Type a date one year ago from today, in the specified format, then press Enter. Your program should sing print Five hundred twenty-five thousand, six hundred minutes. If this is a leap year, there should be one more day‚Äôs worth of minutes, so expect Five hundred twenty-seven thousand forty minutes instead!\nRun your program with python seasons.py. Type a date two years ago from today, in the specified format, then press Enter. Your program should print One million, fifty-one thousand, two hundred minutes (or One million, fifty-two thousand, six hundred forty minutes in a leap year).\nRun your program with python seasons.py. Type a date of your choice, but this time use an invalid format. Press Enter and your program should exit using sys.exit without raising an Exception.\n\n\n\n\nTo test your tests, run pytest test_seasons.py. Try to use correct and incorrect versions of seasons.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of seasons.py. Run your tests by executing pytest test_seasons.py. pytest should show that all of your tests have passed.\nModify one of the functions you‚Äôve implemented in seasons.py and imported into test_seasons.py. One of your functions might, for example, fail to raise a ValueError when it should. Run your tests by executing pytest test_seasons.py. pytest should show that at least one of your tests has failed.\nContinue to modify the behavior of seasons.py, creating (predictably) incorrect versions of your implementation. Run your tests by executing pytest test_seasons.py. Do the tests you expect to fail, fail?"
  },
  {
    "objectID": "problems/pset_8/8.2_seasons_of_love.html#hints",
    "href": "problems/pset_8/8.2_seasons_of_love.html#hints",
    "title": "Seasons of Love",
    "section": "",
    "text": "Note that the date class comes with quite a few methods and ‚Äúsupported operations,‚Äù per docs.python.org/3/library/datetime.html#date-objects. In particular, the class implements __sub__, per docs.python.org/3/library/operator.html#operator.__sub__, overloading - in such a way that subtracting one date object from another returns a timedelta object, which itself comes with several (read-only) ‚Äúinstance attributes,‚Äù per docs.python.org/3/library/datetime.html#timedelta-objects.\nNote that the inflect module comes with quite a few methods, per pypi.org/project/inflect. You can install it with:\npip install inflect"
  },
  {
    "objectID": "problems/pset_8/8.2_seasons_of_love.html#before-you-begin",
    "href": "problems/pset_8/8.2_seasons_of_love.html#before-you-begin",
    "title": "Seasons of Love",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir seasons\n\nto make a folder called seasons in your codespace.\nThen execute\ncd seasons\n\nto change directories into that folder. You should now see your terminal prompt as seasons/ $. You can now execute\ncode seasons.py\n\nto make a file called seasons.py where you‚Äôll write your program. Be sure to also execute\ncode test_seasons.py\n\nto create a file called test_seasons.py where you‚Äôll write tests for your program."
  },
  {
    "objectID": "problems/pset_8/8.2_seasons_of_love.html#how-to-test",
    "href": "problems/pset_8/8.2_seasons_of_love.html#how-to-test",
    "title": "Seasons of Love",
    "section": "",
    "text": "Here‚Äôs how to test seasons.py manually:\n\nRun your program with python seasons.py. Ensure your program prompts you for a birthdate. Type a date one year ago from today, in the specified format, then press Enter. Your program should sing print Five hundred twenty-five thousand, six hundred minutes. If this is a leap year, there should be one more day‚Äôs worth of minutes, so expect Five hundred twenty-seven thousand forty minutes instead!\nRun your program with python seasons.py. Type a date two years ago from today, in the specified format, then press Enter. Your program should print One million, fifty-one thousand, two hundred minutes (or One million, fifty-two thousand, six hundred forty minutes in a leap year).\nRun your program with python seasons.py. Type a date of your choice, but this time use an invalid format. Press Enter and your program should exit using sys.exit without raising an Exception.\n\n\n\n\nTo test your tests, run pytest test_seasons.py. Try to use correct and incorrect versions of seasons.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of seasons.py. Run your tests by executing pytest test_seasons.py. pytest should show that all of your tests have passed.\nModify one of the functions you‚Äôve implemented in seasons.py and imported into test_seasons.py. One of your functions might, for example, fail to raise a ValueError when it should. Run your tests by executing pytest test_seasons.py. pytest should show that at least one of your tests has failed.\nContinue to modify the behavior of seasons.py, creating (predictably) incorrect versions of your implementation. Run your tests by executing pytest test_seasons.py. Do the tests you expect to fail, fail?"
  },
  {
    "objectID": "problems/pset_7/7.5_response_validation.html",
    "href": "problems/pset_7/7.5_response_validation.html",
    "title": "Response Validation",
    "section": "",
    "text": "When creating a Google Form that prompts users for a short answer (or paragraph), it‚Äôs possible to enable response validation and require that the user‚Äôs input match a regular expression. For instance, you could require that a user input an email address with a regex like this one:\n^[a-zA-Z0-9.!#$%&'*+\\/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$\n\nOr you could more easily use Google‚Äôs built-in support for validating an email address, per the screenshot below, much like you could use a library in your own code:\n\n\n\nGoogle Form\n\n\nIn a file called response.py, using either validator-collection or validators from PyPI, implement a program that prompts the user for an email address via input and then prints Valid or Invalid, respectively, if the input is a syntatically valid email address. You may not use re. And do not validate whether the email address‚Äôs domain name actually exists.\n\n\n\nNote that you can install validator-collection with:\npip install validator-collection\n\nIt may be useful to find your way to the library‚Äôs documentation.\nNote that you can install validators with:\npip install validators\n\nClick Homepage to find your way to the library‚Äôs documentation.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir response\n\nto make a folder called response in your codespace.\nThen execute\ncd response\n\nto change directories into that folder. You should now see your terminal prompt as response/ $. You can now execute\ncode response.py\n\nto make a file called response.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python response.py. Ensure your program prompts you for an email, then type malan@harvard.edu, followed by Enter. Your program should output Valid.\nRun your program with python response.py. Type your own email, followed by Enter. Your program should output Valid.\nRun your program with python response.py. Type malan@@@harvard.edu, followed by Enter. Your program should output Invalid.\nRun your program with python response.py. Mistype your own email, including an extra . before .com, for example. Press enter and your program should output Invalid."
  },
  {
    "objectID": "problems/pset_7/7.5_response_validation.html#hints",
    "href": "problems/pset_7/7.5_response_validation.html#hints",
    "title": "Response Validation",
    "section": "",
    "text": "Note that you can install validator-collection with:\npip install validator-collection\n\nIt may be useful to find your way to the library‚Äôs documentation.\nNote that you can install validators with:\npip install validators\n\nClick Homepage to find your way to the library‚Äôs documentation."
  },
  {
    "objectID": "problems/pset_7/7.5_response_validation.html#before-you-begin",
    "href": "problems/pset_7/7.5_response_validation.html#before-you-begin",
    "title": "Response Validation",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir response\n\nto make a folder called response in your codespace.\nThen execute\ncd response\n\nto change directories into that folder. You should now see your terminal prompt as response/ $. You can now execute\ncode response.py\n\nto make a file called response.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_7/7.5_response_validation.html#how-to-test",
    "href": "problems/pset_7/7.5_response_validation.html#how-to-test",
    "title": "Response Validation",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python response.py. Ensure your program prompts you for an email, then type malan@harvard.edu, followed by Enter. Your program should output Valid.\nRun your program with python response.py. Type your own email, followed by Enter. Your program should output Valid.\nRun your program with python response.py. Type malan@@@harvard.edu, followed by Enter. Your program should output Invalid.\nRun your program with python response.py. Mistype your own email, including an extra . before .com, for example. Press enter and your program should output Invalid."
  },
  {
    "objectID": "problems/pset_7/7.3_working_9_to_5.html",
    "href": "problems/pset_7/7.3_working_9_to_5.html",
    "title": "Working 9 to 5",
    "section": "",
    "text": "Whereas most countries use a 24-hour clock, the United States tends to use a 12-hour clock. Accordingly, instead of ‚Äú09:00 to 17:00‚Äù, many Americans would say they work ‚Äú9:00 AM to 5:00 PM‚Äù (or ‚Äú9 AM to 5 PM‚Äù), wherein ‚ÄúAM‚Äù is an abbreviation for ‚Äúante meridiem‚Äù and ‚ÄúPM‚Äù is an abbreviation for ‚Äúpost meridiem‚Äù, wherein ‚Äúmeridiem‚Äù means midday (i.e., noon).\nConversion Table\nJust as ‚Äú12:00 AM‚Äù in 12-hour format would be ‚Äú00:00‚Äù in 24-hour format, so would ‚Äú12:01 AM‚Äù through ‚Äú12:59 AM‚Äù be ‚Äú00:01‚Äù through ‚Äú00:59‚Äù, respectively.\n\n\n\n12-Hour\n24-Hour\n\n\n\n\n12:00 AM\n00:00\n\n\n1:00 AM\n01:00\n\n\n2:00 AM\n02:00\n\n\n3:00 AM\n03:00\n\n\n4:00 AM\n04:00\n\n\n5:00 AM\n05:00\n\n\n6:00 AM\n06:00\n\n\n7:00 AM\n07:00\n\n\n8:00 AM\n08:00\n\n\n9:00 AM\n09:00\n\n\n10:00 AM\n10:00\n\n\n11:00 AM\n11:00\n\n\n12:00 PM\n12:00\n\n\n1:00 PM\n13:00\n\n\n2:00 PM\n14:00\n\n\n3:00 PM\n15:00\n\n\n4:00 PM\n16:00\n\n\n5:00 PM\n17:00\n\n\n6:00 PM\n18:00\n\n\n7:00 PM\n19:00\n\n\n8:00 PM\n20:00\n\n\n9:00 PM\n21:00\n\n\n10:00 PM\n22:00\n\n\n11:00 PM\n23:00\n\n\n12:00 AM\n00:00\n\n\n\nIn a file called working.py, implement a function called convert that expects a str in any of the 12-hour formats below and returns the corresponding str in 24-hour format (i.e., 9:00 to 17:00). Expect that AM and PM will be capitalized (with no periods therein) and that there will be a space before each. Assume that these times are representative of actual times, not necessarily 9:00 AM and 5:00 PM specifically.\n\n9:00 AM to 5:00 PM\n9 AM to 5 PM\n9:00 AM to 5 PM\n9 AM to 5:00 PM\n\nRaise a ValueError instead if the input to convert is not in either of those formats or if either time is invalid (e.g., 12:60 AM, 13:00 PM, etc.). But do not assume that someone‚Äôs hours will start ante meridiem and end post meridiem; someone might work late and even long hours (e.g., 5:00 PM to 9:00 AM).\nStructure working.py as follows, wherein you‚Äôre welcome to modify main and/or implement other functions as you see fit, but you may not import any other libraries. You‚Äôre welcome, but not required, to use re and/or sys.\nimport re\nimport sys\n\n\ndef main():\n    print(convert(input(\"Hours: \")))\n\n\ndef convert(s):\n    ...\n\n\n...\n\n\nif __name__ == \"__main__\":\n    main()\n\nEither before or after you implement convert in working.py, additionally implement, in a file called test_working.py, three or more functions that collectively test your implementation of convert thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_working.py\n\n\n\n\nRecall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including search.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns, else pytest will warn with DeprecationWarning: invalid escape sequence. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that re.search, if passed a pattern with ‚Äúcapturing groups‚Äù (i.e., parentheses), returns a ‚Äúmatch object,‚Äù per docs.python.org/3/library/re.html#match-objects, wherein matches are 1-indexed, which you can access individually with group, per docs.python.org/3/library/re.html#re.Match.group, or collectively with groups, per docs.python.org/3/library/re.html#re.Match.groups.\nNote that you can format an int with leading zeroes with code like\nprint(f\"{n:02}\")\n\nwherein, if n is a single digit, it will be prefixed with one 0, per docs.python.org/3/library/string.html#format-string-syntax.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir working\n\nto make a folder called working in your codespace.\nThen execute\ncd working\n\nto change directories into that folder. You should now see your terminal prompt as working/ $. You can now execute\ncode working.py\n\nto make a file called working.py where you‚Äôll write your program. Be sure to also execute\ncode test_working.py\n\nto create a file called test_working.py where you‚Äôll write tests for your program.\n\n\n\n\n\nHere‚Äôs how to test working.py manually:\n\nRun your program with python working.py. Ensure your program prompts you for a time. Type 9 AM to 5 PM, followed by Enter. Your program should output 09:00 to 17:00.\nRun your program with python working.py. Type 9:00 AM to 5:00 PM, followed by Enter. Your program should again output 09:00 to 17:00.\nRun your program with python working.py. Ensure your program prompts you for a time. Type 10 AM to 8:50 PM, followed by Enter. Your program should output 10:00 to 20:50.\nRun your program with python working.py. Ensure your program prompts you for a time. Type 10:30 PM to 8 AM, followed by Enter. Your program should output 22:30 to 08:00.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 9:60 AM to 5:60 PM, followed by Enter. Your program should indeed raise a ValueError.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 9 AM - 5 PM, followed by Enter. Your program should indeed raise a ValueError.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 09:00 AM - 17:00 PM, followed by Enter. Your program should indeed raise a ValueError.\n\n\n\n\nTo test your tests, run pytest test_working.py. Try to use correct and incorrect versions of working.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of working.py. Run your tests by executing pytest test_working.py. pytest should show that all of your tests have passed.\nModify the correct version of working.py, particularly its function convert. Your program might, for example, fail to raise a ValueError when it should. Run your tests by executing pytest test_working.py. pytest should show that at least one of your tests has failed.\nSimilarly, modify the correct version of working.py, changing the return values of convert. Your program might, for example, mistakenly omit minutes. Run your tests by executing pytest test_working.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_7/7.3_working_9_to_5.html#hints",
    "href": "problems/pset_7/7.3_working_9_to_5.html#hints",
    "title": "Working 9 to 5",
    "section": "",
    "text": "Recall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including search.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns, else pytest will warn with DeprecationWarning: invalid escape sequence. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that re.search, if passed a pattern with ‚Äúcapturing groups‚Äù (i.e., parentheses), returns a ‚Äúmatch object,‚Äù per docs.python.org/3/library/re.html#match-objects, wherein matches are 1-indexed, which you can access individually with group, per docs.python.org/3/library/re.html#re.Match.group, or collectively with groups, per docs.python.org/3/library/re.html#re.Match.groups.\nNote that you can format an int with leading zeroes with code like\nprint(f\"{n:02}\")\n\nwherein, if n is a single digit, it will be prefixed with one 0, per docs.python.org/3/library/string.html#format-string-syntax."
  },
  {
    "objectID": "problems/pset_7/7.3_working_9_to_5.html#before-you-begin",
    "href": "problems/pset_7/7.3_working_9_to_5.html#before-you-begin",
    "title": "Working 9 to 5",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir working\n\nto make a folder called working in your codespace.\nThen execute\ncd working\n\nto change directories into that folder. You should now see your terminal prompt as working/ $. You can now execute\ncode working.py\n\nto make a file called working.py where you‚Äôll write your program. Be sure to also execute\ncode test_working.py\n\nto create a file called test_working.py where you‚Äôll write tests for your program."
  },
  {
    "objectID": "problems/pset_7/7.3_working_9_to_5.html#how-to-test",
    "href": "problems/pset_7/7.3_working_9_to_5.html#how-to-test",
    "title": "Working 9 to 5",
    "section": "",
    "text": "Here‚Äôs how to test working.py manually:\n\nRun your program with python working.py. Ensure your program prompts you for a time. Type 9 AM to 5 PM, followed by Enter. Your program should output 09:00 to 17:00.\nRun your program with python working.py. Type 9:00 AM to 5:00 PM, followed by Enter. Your program should again output 09:00 to 17:00.\nRun your program with python working.py. Ensure your program prompts you for a time. Type 10 AM to 8:50 PM, followed by Enter. Your program should output 10:00 to 20:50.\nRun your program with python working.py. Ensure your program prompts you for a time. Type 10:30 PM to 8 AM, followed by Enter. Your program should output 22:30 to 08:00.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 9:60 AM to 5:60 PM, followed by Enter. Your program should indeed raise a ValueError.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 9 AM - 5 PM, followed by Enter. Your program should indeed raise a ValueError.\nRun your program with python working.py. Ensure your program prompts you for a time. Try intentionally inducing a ValueError by typing 09:00 AM - 17:00 PM, followed by Enter. Your program should indeed raise a ValueError.\n\n\n\n\nTo test your tests, run pytest test_working.py. Try to use correct and incorrect versions of working.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of working.py. Run your tests by executing pytest test_working.py. pytest should show that all of your tests have passed.\nModify the correct version of working.py, particularly its function convert. Your program might, for example, fail to raise a ValueError when it should. Run your tests by executing pytest test_working.py. pytest should show that at least one of your tests has failed.\nSimilarly, modify the correct version of working.py, changing the return values of convert. Your program might, for example, mistakenly omit minutes. Run your tests by executing pytest test_working.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_6/pset_6.html",
    "href": "problems/pset_6/pset_6.html",
    "title": "Problem Set week 6",
    "section": "",
    "text": "Complete the following problems\n\nLines of Code\nPizza Py\nScourgify",
    "crumbs": [
      "Problem Sets",
      "Problem Set 06 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_6/pset_6.html#what-to-do",
    "href": "problems/pset_6/pset_6.html#what-to-do",
    "title": "Problem Set week 6",
    "section": "",
    "text": "Complete the following problems\n\nLines of Code\nPizza Py\nScourgify",
    "crumbs": [
      "Problem Sets",
      "Problem Set 06 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_6/6.3_pizza_py.html",
    "href": "problems/pset_6/6.3_pizza_py.html",
    "title": "Pizza Py",
    "section": "",
    "text": "A famous place for pizza in Harvard Square is Pinocchio‚Äôs Pizza & Subs, aka Noch‚Äôs, known for its Sicilian pizza, which is ‚Äúa deep-dish or thick-crust pizza.‚Äù\nStudents on the university campus tend to buy pizza by the slice, but Pinocchio‚Äôs also has whole pizzas on its menu too, per this CSV file of Sicilian pizzas, &lt;sicilian.csv&gt;, below:\nSicilian Pizza,Small,Large\nCheese,$25.50,$39.95\n1 item,$27.50,$41.95\n2 items,$29.50,$43.95\n3 items,$31.50,$45.95\nSpecial,$33.50,$47.95\n\nSee &lt;regular.csv&gt; for a CSV file of regular pizzas as well.\nOf course, a CSV file isn‚Äôt the most customer-friendly format to look at. Prettier might be a table, formatted as ASCII art, like this one:\n+------------------+---------+---------+\n| Sicilian Pizza   | Small   | Large   |\n+==================+=========+=========+\n| Cheese           | $25.50  | $39.95  |\n+------------------+---------+---------+\n| 1 item           | $27.50  | $41.95  |\n+------------------+---------+---------+\n| 2 items          | $29.50  | $43.95  |\n+------------------+---------+---------+\n| 3 items          | $31.50  | $45.95  |\n+------------------+---------+---------+\n| Special          | $33.50  | $47.95  |\n+------------------+---------+---------+\n\nIn a file called pizza.py, implement a program that expects exactly one command-line argument, the name (or path) of a CSV file in Pinocchio‚Äôs format, and outputs a table formatted as ASCII art using tabulate, a package on PyPI at pypi.org/project/tabulate. Format the table using the library‚Äôs grid format. If the user does not specify exactly one command-line argument, or if the specified file‚Äôs name does not end in .csv, or if the specified file does not exist, the program should instead exit via sys.exit.\n\n\n\nRecall that the csv module comes with quite a few methods, per docs.python.org/3/library/csv.html, among which are reader, per docs.python.org/3/library/csv.html#csv.reader, and DictReader, per docs.python.org/3/library/csv.html#csv.DictReader.\nNote that open can raise a FileNotFoundError, per docs.python.org/3/library/exceptions.html#FileNotFoundError.\nNote that the tabulate package comes with just one function, per pypi.org/project/tabulate. You can install the package with:\npip install tabulate\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir pizza\n\nto make a folder called pizza in your codespace.\nThen execute\ncd pizza\n\nto change directories into that folder. You should now see your terminal prompt as pizza/ $. You can now execute\ncode pizza.py\n\nto make a file called pizza.py where you‚Äôll write your program. Be sure to run\nwget https://cs50.harvard.edu/python/2022/psets/6/pizza/sicilian.csv\n\nto download &lt;sicilian.csv&gt; into your folder. Also run\nwget https://cs50.harvard.edu/python/2022/psets/6/pizza/regular.csv\n\nto download &lt;regular.csv&gt; into your folder.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python pizza.py. Your program should exit using sys.exit and provide an error message:\nToo few command-line arguments\n\nBe sure to download &lt;regular.csv&gt; and &lt;sicilian.csv&gt;, placing them in the same folder as pizza.py. Run your program with python pizza.py regular.csv sicilian.csv. Your program should output:\nToo many command-line arguments\n\nRun your program with python pizza.py invalid_file.csv. Assuming invalid_file.csv doesn‚Äôt exist, your program should exit using sys.exit and provide an error message:\nFile does not exist\n\nCreate a file named sicilian.txt. Run your program with python pizza.py sicilian.txt. Your program should exit using sys.exit and provide an error message:\nNot a CSV file\n\nRun your program with python pizza.py regular.csv. Assuming you‚Äôve downloaded &lt;regular.csv&gt;, your program should print a table like the below:\n+-----------------+---------+---------+\n| Regular Pizza   | Small   | Large   |\n+=================+=========+=========+\n| Cheese          | $13.50  | $18.95  |\n+-----------------+---------+---------+\n| 1 topping       | $14.75  | $20.95  |\n+-----------------+---------+---------+\n| 2 toppings      | $15.95  | $22.95  |\n+-----------------+---------+---------+\n| 3 toppings      | $16.95  | $24.95  |\n+-----------------+---------+---------+\n| Special         | $18.50  | $26.95  |\n+-----------------+---------+---------+"
  },
  {
    "objectID": "problems/pset_6/6.3_pizza_py.html#hints",
    "href": "problems/pset_6/6.3_pizza_py.html#hints",
    "title": "Pizza Py",
    "section": "",
    "text": "Recall that the csv module comes with quite a few methods, per docs.python.org/3/library/csv.html, among which are reader, per docs.python.org/3/library/csv.html#csv.reader, and DictReader, per docs.python.org/3/library/csv.html#csv.DictReader.\nNote that open can raise a FileNotFoundError, per docs.python.org/3/library/exceptions.html#FileNotFoundError.\nNote that the tabulate package comes with just one function, per pypi.org/project/tabulate. You can install the package with:\npip install tabulate"
  },
  {
    "objectID": "problems/pset_6/6.3_pizza_py.html#before-you-begin",
    "href": "problems/pset_6/6.3_pizza_py.html#before-you-begin",
    "title": "Pizza Py",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir pizza\n\nto make a folder called pizza in your codespace.\nThen execute\ncd pizza\n\nto change directories into that folder. You should now see your terminal prompt as pizza/ $. You can now execute\ncode pizza.py\n\nto make a file called pizza.py where you‚Äôll write your program. Be sure to run\nwget https://cs50.harvard.edu/python/2022/psets/6/pizza/sicilian.csv\n\nto download &lt;sicilian.csv&gt; into your folder. Also run\nwget https://cs50.harvard.edu/python/2022/psets/6/pizza/regular.csv\n\nto download &lt;regular.csv&gt; into your folder."
  },
  {
    "objectID": "problems/pset_6/6.3_pizza_py.html#how-to-test",
    "href": "problems/pset_6/6.3_pizza_py.html#how-to-test",
    "title": "Pizza Py",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python pizza.py. Your program should exit using sys.exit and provide an error message:\nToo few command-line arguments\n\nBe sure to download &lt;regular.csv&gt; and &lt;sicilian.csv&gt;, placing them in the same folder as pizza.py. Run your program with python pizza.py regular.csv sicilian.csv. Your program should output:\nToo many command-line arguments\n\nRun your program with python pizza.py invalid_file.csv. Assuming invalid_file.csv doesn‚Äôt exist, your program should exit using sys.exit and provide an error message:\nFile does not exist\n\nCreate a file named sicilian.txt. Run your program with python pizza.py sicilian.txt. Your program should exit using sys.exit and provide an error message:\nNot a CSV file\n\nRun your program with python pizza.py regular.csv. Assuming you‚Äôve downloaded &lt;regular.csv&gt;, your program should print a table like the below:\n+-----------------+---------+---------+\n| Regular Pizza   | Small   | Large   |\n+=================+=========+=========+\n| Cheese          | $13.50  | $18.95  |\n+-----------------+---------+---------+\n| 1 topping       | $14.75  | $20.95  |\n+-----------------+---------+---------+\n| 2 toppings      | $15.95  | $22.95  |\n+-----------------+---------+---------+\n| 3 toppings      | $16.95  | $24.95  |\n+-----------------+---------+---------+\n| Special         | $18.50  | $26.95  |\n+-----------------+---------+---------+"
  },
  {
    "objectID": "problems/pset_5/pset_5.html",
    "href": "problems/pset_5/pset_5.html",
    "title": "Problem Set week 5",
    "section": "",
    "text": "Complete the following problems\n\nTesting my twttr\nBack to the Bank\nRe-requesting a Vanity Plate\nRefueling",
    "crumbs": [
      "Problem Sets",
      "Problem Set 05 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_5/pset_5.html#what-to-do",
    "href": "problems/pset_5/pset_5.html#what-to-do",
    "title": "Problem Set week 5",
    "section": "",
    "text": "Complete the following problems\n\nTesting my twttr\nBack to the Bank\nRe-requesting a Vanity Plate\nRefueling",
    "crumbs": [
      "Problem Sets",
      "Problem Set 05 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html",
    "href": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html",
    "title": "Re-requesting a Vanity Plate",
    "section": "",
    "text": "In a file called plates.py, reimplement Vanity Plates from Problem Set 2, restructuring your code per the below, wherein is_valid still expects a str as input and returns True if that str meets all requirements and False if it does not, but main is only called if the value of __name__ is \"__main__\":\ndef main():\n    ...\n\n\ndef is_valid(s):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\nThen, in a file called test_plates.py, implement four or more functions that collectively test your implementation of is_valid thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_plates.py\n\n\n\n\nBe sure to include\nimport plates\n\nor\nfrom plates import is_valid\n\natop test_plates.py so that you can call is_valid in your tests.\nTake care to return, not print, a bool in is_valid. Only main should call print.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_plates\n\nto make a folder called test_plates in your codespace.\nThen execute\ncd test_plates\n\nto change directories into that folder. You should now see your terminal prompt as test_plates/ $. You can now execute\ncode test_plates.py\n\nto make a file called test_plates.py where you‚Äôll write your tests.\n\n\n\nTo test your tests, run pytest test_plates.py. Be sure you have a copy of a plates.py file in the same folder. Try to use correct and incorrect versions of plates.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of plates.py. Run your tests by executing pytest test_plates.py. pytest should show that all of your tests have passed.\nModify the correct version of plates.py, perhaps eliminating some of its constraints. Your program might, for example, mistakenly print ‚ÄúValid‚Äù for a license plate of any length! Run your tests by executing pytest test_plates.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#hints",
    "href": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#hints",
    "title": "Re-requesting a Vanity Plate",
    "section": "",
    "text": "Be sure to include\nimport plates\n\nor\nfrom plates import is_valid\n\natop test_plates.py so that you can call is_valid in your tests.\nTake care to return, not print, a bool in is_valid. Only main should call print."
  },
  {
    "objectID": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#before-you-begin",
    "href": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#before-you-begin",
    "title": "Re-requesting a Vanity Plate",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_plates\n\nto make a folder called test_plates in your codespace.\nThen execute\ncd test_plates\n\nto change directories into that folder. You should now see your terminal prompt as test_plates/ $. You can now execute\ncode test_plates.py\n\nto make a file called test_plates.py where you‚Äôll write your tests."
  },
  {
    "objectID": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#how-to-test",
    "href": "problems/pset_5/5.4_re_requesting_a_vanity_plate.html#how-to-test",
    "title": "Re-requesting a Vanity Plate",
    "section": "",
    "text": "To test your tests, run pytest test_plates.py. Be sure you have a copy of a plates.py file in the same folder. Try to use correct and incorrect versions of plates.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of plates.py. Run your tests by executing pytest test_plates.py. pytest should show that all of your tests have passed.\nModify the correct version of plates.py, perhaps eliminating some of its constraints. Your program might, for example, mistakenly print ‚ÄúValid‚Äù for a license plate of any length! Run your tests by executing pytest test_plates.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.2_testing_my_twttr.html",
    "href": "problems/pset_5/5.2_testing_my_twttr.html",
    "title": "Testing my twttr",
    "section": "",
    "text": "In a file called twttr.py, reimplement Setting up my twttr from Problem Set 2, restructuring your code per the below, wherein shorten expects a str as input and returns that same str but with all vowels (A, E, I, O, and U) omitted, whether inputted in uppercase or lowercase.\ndef main():\n    ...\n\n\ndef shorten(word):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\nThen, in a file called test_twttr.py, implement one or more functions that collectively test your implementation of shorten thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_twttr.py\n\n\n\n\nBe sure to include\nimport twttr\n\nor\nfrom twttr import shorten\n\natop test_twttr.py so that you can call shorten in your tests.\nTake care to return, not print, a str in shorten. Only main should call print.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_twttr\n\nto make a folder called test_twttr in your codespace.\nThen execute\ncd test_twttr\n\nto change directories into that folder. You should now see your terminal prompt as test_twttr/ $. You can now execute\ncode test_twttr.py\n\nto make a file called test_twttr.py where you‚Äôll write your tests.\n\n\n\nTo test your tests, run pytest test_twttr.py. Be sure you have a copy of a twttr.py file in the same folder. Try to use correct and incorrect versions of twttr.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of twttr.py. Run your tests by executing pytest test_twttr.py. pytest should show that all of your tests have passed.\nModify the correct version of twttr.py in such a way as to create a bug. Your program might, for example, mistakenly only omit lowercase vowels! Run your tests by executing pytest test_twttr.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.2_testing_my_twttr.html#hints",
    "href": "problems/pset_5/5.2_testing_my_twttr.html#hints",
    "title": "Testing my twttr",
    "section": "",
    "text": "Be sure to include\nimport twttr\n\nor\nfrom twttr import shorten\n\natop test_twttr.py so that you can call shorten in your tests.\nTake care to return, not print, a str in shorten. Only main should call print."
  },
  {
    "objectID": "problems/pset_5/5.2_testing_my_twttr.html#before-you-begin",
    "href": "problems/pset_5/5.2_testing_my_twttr.html#before-you-begin",
    "title": "Testing my twttr",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_twttr\n\nto make a folder called test_twttr in your codespace.\nThen execute\ncd test_twttr\n\nto change directories into that folder. You should now see your terminal prompt as test_twttr/ $. You can now execute\ncode test_twttr.py\n\nto make a file called test_twttr.py where you‚Äôll write your tests."
  },
  {
    "objectID": "problems/pset_5/5.2_testing_my_twttr.html#how-to-test",
    "href": "problems/pset_5/5.2_testing_my_twttr.html#how-to-test",
    "title": "Testing my twttr",
    "section": "",
    "text": "To test your tests, run pytest test_twttr.py. Be sure you have a copy of a twttr.py file in the same folder. Try to use correct and incorrect versions of twttr.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of twttr.py. Run your tests by executing pytest test_twttr.py. pytest should show that all of your tests have passed.\nModify the correct version of twttr.py in such a way as to create a bug. Your program might, for example, mistakenly only omit lowercase vowels! Run your tests by executing pytest test_twttr.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_4/4.7_bitcoin_price_index.html",
    "href": "problems/pset_4/4.7_bitcoin_price_index.html",
    "title": "Bitcoin Price Index",
    "section": "",
    "text": "To complete this problem, you will need to sign up for a CoinCap account and obtain an API key. You can do this by visiting CoinCap. Once you have your API key, you can use it in your code to access the CoinCap v3 API.\n\n\n\nBitcoin logo\n\n\nBitcoin is a form of digital currency, otherwise known as cryptocurrency. Rather than rely on a central authority like a bank, Bitcoin instead relies on a distributed network, otherwise known as a blockchain, to record transactions.\nBecause there‚Äôs demand for Bitcoin (i.e., users want it), users are willing to buy it, as by exchanging one currency (e.g., USD) for Bitcoin.\nIn a file called bitcoin.py, implement a program that:\n\nExpects the user to specify as a command-line argument the number of Bitcoins, (n), that they would like to buy. If that argument cannot be converted to a float, the program should exit via sys.exit with an error message.\nQueries the API for the CoinCap Bitcoin Price Index at rest.coincap.io/v3/assets/bitcoin?apiKey=YourApiKey. You should replace YourApiKey with the actual API key you obtained from your CoinCap account dashboard, which returns a JSON object, among whose nested keys is the current price of Bitcoin as a float. Be sure to catch any exceptions, as with code like:\nimport requests\n\ntry:\n    ...\nexcept requests.RequestException:\n    ...\n\nOutputs the current cost of (n) Bitcoins in USD to four decimal places, using , as a thousands separator.\n\n\n\n\nRecall that the sys module comes with argv, per docs.python.org/3/library/sys.html#sys.argv.\nNote that the requests module comes with quite a few methods, per requests.readthedocs.io/en/latest, among which are get, per requests.readthedocs.io/en/latest/user/quickstart.html#make-a-request, and json, per requests.readthedocs.io/en/latest/user/quickstart.html#json-response-content. You can install it with:\npip install requests\n\nNote that CoinCap‚Äôs API returns a JSON response like:\n{\n  \"data\": {\n    \"id\": \"bitcoin\",\n    \"rank\": \"1\",\n    \"symbol\": \"BTC\",\n    \"name\": \"Bitcoin\",\n    \"supply\": \"19823321.0000000000000000\",\n    \"maxSupply\": \"21000000.0000000000000000\",\n    \"marketCapUsd\": \"1939613325892.4607145113457500\",\n    \"volumeUsd24Hr\": \"12341417371.3505338276601668\",\n    \"priceUsd\": \"97845.0243474572557500\",\n    \"changePercent24Hr\": \"1.4324165997531723\",\n    \"vwap24Hr\": \"96203.8859537212418977\",\n    \"explorer\": \"https://blockchain.info/\"\n  },\n  \"timestamp\": 1739399343596\n}\n\nRecall that you can format USD to four decimal places with a thousands separator with code like:\nprint(f\"${amount:,.4f}\")\n\n\n\n\n\nCreate a CoinCap account at CoinCap Sign Up and obtain an API key by clicking the ‚ÄúAdd New Key‚Äù button in your CoinCap Dashboard. You will need to use this API key in your program. You can read more about the API usage in the CoinCap API documentation.\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir bitcoin\n\nto make a folder called bitcoin in your codespace.\nThen execute\ncd bitcoin\n\nto change directories into that folder. You should now see your terminal prompt as bitcoin/ $. You can now execute\ncode bitcoin.py\n\nto make a file called bitcoin.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python bitcoin.py. Your program should use sys.exit to exit with an error message:\nMissing command-line argument   \n\nRun your program with python bitcoin.py cat. Your program should use sys.exit to exit with an error message:\nCommand-line argument is not a number\n\nRun your program with python bitcoin.py 1. Your program should output the price of a single Bitcoin to four decimal places, using , as a thousands separator.\nRun your program with python bitcoin.py 2. Your program should output the price of two Bitcoin to four decimal places, using , as a thousands separator.\nRun your program with python bitcoin.py 2.5. Your program should output the price of 2.5 Bitcoin to four decimal places, using , as a thousands separator."
  },
  {
    "objectID": "problems/pset_4/4.7_bitcoin_price_index.html#hints",
    "href": "problems/pset_4/4.7_bitcoin_price_index.html#hints",
    "title": "Bitcoin Price Index",
    "section": "",
    "text": "Recall that the sys module comes with argv, per docs.python.org/3/library/sys.html#sys.argv.\nNote that the requests module comes with quite a few methods, per requests.readthedocs.io/en/latest, among which are get, per requests.readthedocs.io/en/latest/user/quickstart.html#make-a-request, and json, per requests.readthedocs.io/en/latest/user/quickstart.html#json-response-content. You can install it with:\npip install requests\n\nNote that CoinCap‚Äôs API returns a JSON response like:\n{\n  \"data\": {\n    \"id\": \"bitcoin\",\n    \"rank\": \"1\",\n    \"symbol\": \"BTC\",\n    \"name\": \"Bitcoin\",\n    \"supply\": \"19823321.0000000000000000\",\n    \"maxSupply\": \"21000000.0000000000000000\",\n    \"marketCapUsd\": \"1939613325892.4607145113457500\",\n    \"volumeUsd24Hr\": \"12341417371.3505338276601668\",\n    \"priceUsd\": \"97845.0243474572557500\",\n    \"changePercent24Hr\": \"1.4324165997531723\",\n    \"vwap24Hr\": \"96203.8859537212418977\",\n    \"explorer\": \"https://blockchain.info/\"\n  },\n  \"timestamp\": 1739399343596\n}\n\nRecall that you can format USD to four decimal places with a thousands separator with code like:\nprint(f\"${amount:,.4f}\")"
  },
  {
    "objectID": "problems/pset_4/4.7_bitcoin_price_index.html#before-you-begin",
    "href": "problems/pset_4/4.7_bitcoin_price_index.html#before-you-begin",
    "title": "Bitcoin Price Index",
    "section": "",
    "text": "Create a CoinCap account at CoinCap Sign Up and obtain an API key by clicking the ‚ÄúAdd New Key‚Äù button in your CoinCap Dashboard. You will need to use this API key in your program. You can read more about the API usage in the CoinCap API documentation.\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir bitcoin\n\nto make a folder called bitcoin in your codespace.\nThen execute\ncd bitcoin\n\nto change directories into that folder. You should now see your terminal prompt as bitcoin/ $. You can now execute\ncode bitcoin.py\n\nto make a file called bitcoin.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.7_bitcoin_price_index.html#how-to-test",
    "href": "problems/pset_4/4.7_bitcoin_price_index.html#how-to-test",
    "title": "Bitcoin Price Index",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python bitcoin.py. Your program should use sys.exit to exit with an error message:\nMissing command-line argument   \n\nRun your program with python bitcoin.py cat. Your program should use sys.exit to exit with an error message:\nCommand-line argument is not a number\n\nRun your program with python bitcoin.py 1. Your program should output the price of a single Bitcoin to four decimal places, using , as a thousands separator.\nRun your program with python bitcoin.py 2. Your program should output the price of two Bitcoin to four decimal places, using , as a thousands separator.\nRun your program with python bitcoin.py 2.5. Your program should output the price of 2.5 Bitcoin to four decimal places, using , as a thousands separator."
  },
  {
    "objectID": "problems/pset_4/4.5_guessing_game.html",
    "href": "problems/pset_4/4.5_guessing_game.html",
    "title": "Guessing Game",
    "section": "",
    "text": "I‚Äôm thinking of a number between 1 and 100‚Ä¶\nWhat is it?\nIt‚Äôs 50! But what if it were more random?\nIn a file called game.py, implement a program that:\n\nPrompts the user for a level, (n). If the user does not input a positive integer, the program should prompt again.\nRandomly generates an integer between 1 and (n), inclusive, using the random module.\nPrompts the user to guess that integer. If the guess is not a positive integer, the program should prompt the user again.\n\nIf the guess is smaller than that integer, the program should output Too small! and prompt the user again.\nIf the guess is larger than that integer, the program should output Too large! and prompt the user again.\nIf the guess is the same as that integer, the program should output Just right! and exit.\n\n\n\n\n\nNote that the random module comes with quite a few functions, per docs.python.org/3/library/random.html. Of particular interest, perhaps, are the functions specialized for returning integers, such as randint and randrange.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir game\n\nto make a folder called game in your codespace.\nThen execute\ncd game\n\nto change directories into that folder. You should now see your terminal prompt as game/ $. You can now execute\ncode game.py\n\nto make a file called game.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python game.py. Type cat at a prompt that says Level: and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python game.py. Type -1 at a prompt that says Level: and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Your program should now be ready to accept guesses:\nGuess:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type cat. Your program should reprompt you:\nGuess:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type -1. Your program should reprompt you:\nGuess:\n\nRun your program with python game.py. Type 1 at a prompt that says Level: and press Enter. Then type 1. Your program should output:\nJust right!\n\nThere‚Äôs only one possible number the answer could be!\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type 100. Your program should output:\nToo large!\n\nLooks like you‚Äôre guessing outside the range you specified.\nRun your program with python game.py. Type 10000 at a prompt that says Level: and press Enter. Then type 1. Your program should output:\nToo small!\n\nMost likely, anyways: you might get lucky and see Just right!. But it would certainly be odd for you to see Just right! every time. And certainly you shouldn‚Äôt see Too large!."
  },
  {
    "objectID": "problems/pset_4/4.5_guessing_game.html#hints",
    "href": "problems/pset_4/4.5_guessing_game.html#hints",
    "title": "Guessing Game",
    "section": "",
    "text": "Note that the random module comes with quite a few functions, per docs.python.org/3/library/random.html. Of particular interest, perhaps, are the functions specialized for returning integers, such as randint and randrange."
  },
  {
    "objectID": "problems/pset_4/4.5_guessing_game.html#before-you-begin",
    "href": "problems/pset_4/4.5_guessing_game.html#before-you-begin",
    "title": "Guessing Game",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir game\n\nto make a folder called game in your codespace.\nThen execute\ncd game\n\nto change directories into that folder. You should now see your terminal prompt as game/ $. You can now execute\ncode game.py\n\nto make a file called game.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.5_guessing_game.html#how-to-test",
    "href": "problems/pset_4/4.5_guessing_game.html#how-to-test",
    "title": "Guessing Game",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python game.py. Type cat at a prompt that says Level: and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python game.py. Type -1 at a prompt that says Level: and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Your program should now be ready to accept guesses:\nGuess:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type cat. Your program should reprompt you:\nGuess:\n\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type -1. Your program should reprompt you:\nGuess:\n\nRun your program with python game.py. Type 1 at a prompt that says Level: and press Enter. Then type 1. Your program should output:\nJust right!\n\nThere‚Äôs only one possible number the answer could be!\nRun your program with python game.py. Type 10 at a prompt that says Level: and press Enter. Then type 100. Your program should output:\nToo large!\n\nLooks like you‚Äôre guessing outside the range you specified.\nRun your program with python game.py. Type 10000 at a prompt that says Level: and press Enter. Then type 1. Your program should output:\nToo small!\n\nMost likely, anyways: you might get lucky and see Just right!. But it would certainly be odd for you to see Just right! every time. And certainly you shouldn‚Äôt see Too large!."
  },
  {
    "objectID": "problems/pset_4/4.3_frank_ian_and_glens_letters.html",
    "href": "problems/pset_4/4.3_frank_ian_and_glens_letters.html",
    "title": "Frank, Ian and Glen‚Äôs Letters",
    "section": "",
    "text": "FIGlet, named after Frank, Ian, and Glen‚Äôs letters, is a program from the early 1990s for making large letters out of ordinary text, a form of ASCII art:\n _ _ _          _   _     _\n| (_) | _____  | |_| |__ (_)___\n| | | |/ / _ \\ | __| '_ \\| / __|\n| | |   &lt;  __/ | |_| | | | \\__ \\\n|_|_|_|\\_\\___|  \\__|_| |_|_|___/\n\nAmong the fonts supported by FIGlet are those at figlet.org/examples.html.\nFIGlet has since been ported to Python as a module called pyfiglet.\nIn a file called figlet.py, implement a program that:\n\nExpects zero or two command-line arguments:\n\nZero if the user would like to output text in a random font.\nTwo if the user would like to output text in a specific font, in which case the first of the two should be -f or --font, and the second of the two should be the name of the font.\n\nPrompts the user for a str of text.\nOutputs that text in the desired font.\n\nIf the user provides two command-line arguments and the first is not -f or --font or the second is not the name of a font, the program should exit via sys.exit with an error message.\n\n\n\nYou can install pyfiglet with:\npip install pyfiglet\n\nThe documentation for pyfiglet isn‚Äôt very clear, but you can use the module as follows:\nfrom pyfiglet import Figlet\n\nfiglet = Figlet()\n\nYou can then get a list of available fonts with code like this:\nfiglet.getFonts()\n\nYou can set the font with code like this, wherein f is the font‚Äôs name as a str:\nfiglet.setFont(font=f)\n\nAnd you can output text in that font with code like this, wherein s is that text as a str:\nprint(figlet.renderText(s))\n\nNote that the random module comes with quite a few functions, per docs.python.org/3/library/random.html.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir figlet\n\nto make a folder called figlet in your codespace.\nThen execute\ncd figlet\n\nto change directories into that folder. You should now see your terminal prompt as figlet/ $. You can now execute\ncode figlet.py\n\nto make a file called figlet.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python figlet.py test. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -a slant. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -f invalid_font. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -f slant. Type CS50. Your program should print the following:\n   ___________ __________ \n  / ____/ ___// ____/ __ \\\n / /    \\__ \\/___ \\/ / / /\n/ /___ ___/ /___/ / /_/ / \n\\____//____/_____/\\____/  \n\nRun your program with python figlet.py -f rectangles. Type Hello, world. Your program should print the following:\n _____     _ _                        _   _ \n|  |  |___| | |___      _ _ _ ___ ___| |_| |\n|     | -_| | | . |_   | | | | . |  _| | . |\n|__|__|___|_|_|___| |  |_____|___|_| |_|___|\n                  |_|                       \n\nRun your program with python figlet.py -f alphabet. Type Moo. Your program should print the following:\nM   M         \nMM MM         \nM M M ooo ooo \nM   M o o o o \nM   M ooo ooo"
  },
  {
    "objectID": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#hints",
    "href": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#hints",
    "title": "Frank, Ian and Glen‚Äôs Letters",
    "section": "",
    "text": "You can install pyfiglet with:\npip install pyfiglet\n\nThe documentation for pyfiglet isn‚Äôt very clear, but you can use the module as follows:\nfrom pyfiglet import Figlet\n\nfiglet = Figlet()\n\nYou can then get a list of available fonts with code like this:\nfiglet.getFonts()\n\nYou can set the font with code like this, wherein f is the font‚Äôs name as a str:\nfiglet.setFont(font=f)\n\nAnd you can output text in that font with code like this, wherein s is that text as a str:\nprint(figlet.renderText(s))\n\nNote that the random module comes with quite a few functions, per docs.python.org/3/library/random.html."
  },
  {
    "objectID": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#before-you-begin",
    "href": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#before-you-begin",
    "title": "Frank, Ian and Glen‚Äôs Letters",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir figlet\n\nto make a folder called figlet in your codespace.\nThen execute\ncd figlet\n\nto change directories into that folder. You should now see your terminal prompt as figlet/ $. You can now execute\ncode figlet.py\n\nto make a file called figlet.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#how-to-test",
    "href": "problems/pset_4/4.3_frank_ian_and_glens_letters.html#how-to-test",
    "title": "Frank, Ian and Glen‚Äôs Letters",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python figlet.py test. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -a slant. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -f invalid_font. Your program should exit via sys.exit and print an error message:\nInvalid usage\n\nRun your program with python figlet.py -f slant. Type CS50. Your program should print the following:\n   ___________ __________ \n  / ____/ ___// ____/ __ \\\n / /    \\__ \\/___ \\/ / / /\n/ /___ ___/ /___/ / /_/ / \n\\____//____/_____/\\____/  \n\nRun your program with python figlet.py -f rectangles. Type Hello, world. Your program should print the following:\n _____     _ _                        _   _ \n|  |  |___| | |___      _ _ _ ___ ___| |_| |\n|     | -_| | | . |_   | | | | . |  _| | . |\n|__|__|___|_|_|___| |  |_____|___|_| |_|___|\n                  |_|                       \n\nRun your program with python figlet.py -f alphabet. Type Moo. Your program should print the following:\nM   M         \nMM MM         \nM M M ooo ooo \nM   M o o o o \nM   M ooo ooo"
  },
  {
    "objectID": "problems/pset_3/pset_3.html",
    "href": "problems/pset_3/pset_3.html",
    "title": "Problem Set week 3",
    "section": "",
    "text": "Complete the following problems\n\nFuel Gauge\nFelipe‚Äôs Taqueria\nGrocery List\nOutdated",
    "crumbs": [
      "Problem Sets",
      "Problem Set 03 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_3/pset_3.html#what-to-do",
    "href": "problems/pset_3/pset_3.html#what-to-do",
    "title": "Problem Set week 3",
    "section": "",
    "text": "Complete the following problems\n\nFuel Gauge\nFelipe‚Äôs Taqueria\nGrocery List\nOutdated",
    "crumbs": [
      "Problem Sets",
      "Problem Set 03 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_3/3.4_grocery_list.html",
    "href": "problems/pset_3/3.4_grocery_list.html",
    "title": "Grocery List",
    "section": "",
    "text": "Suppose that you‚Äôre in the habit of making a list of items you need from the grocery store.\nIn a file called grocery.py, implement a program that prompts the user for items, one per line, until the user inputs control-d (which is a common way of ending one‚Äôs input to a program). Then output the user‚Äôs grocery list in all uppercase, sorted alphabetically by item, prefixing each line with the number of times the user inputted that item. No need to pluralize the items. Treat the user‚Äôs input case-insensitively.\n\n\n\nNote that you can detect when the user has inputted control-d by catching an EOFError with code like:\ntry:\n    item = input()\nexcept EOFError:\n    ...\n\nOdds are you‚Äôll want to store your grocery list as a dict.\nNote that a dict comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#mapping-types-dict, among them get, and supports operations like:\nd[key]\n\nand\nif key in d:\n    ...\n\nwherein d is a dict and key is a str.\nBe sure to avoid or catch any KeyError.\nNote that you can sort a dictionary‚Äôs keys alphabetically by passing that dictionary as an argument to sorted.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir grocery\n\nto make a folder called grocery in your codespace.\nThen execute\ncd grocery\n\nto change directories into that folder. You should now see your terminal prompt as grocery/ $. You can now execute\ncode grocery.py\n\nto make a file called grocery.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python grocery.py. Type mango and press Enter, then type strawberry and press Enter, followed by control-d.¬†Your program should output:\n1 MANGO\n1 STRAWBERRY\n\nRun your program with python grocery.py. Type milk and press Enter, then type milk again and press Enter, followed by control-d.¬†Your program should output:\n2 MILK\n\nRun your program with python grocery.py. Type tortilla and press Enter, then type sweet potato and press Enter, followed by control-d.¬†Your program should output:\n1 SWEET POTATO\n1 TORTILLA"
  },
  {
    "objectID": "problems/pset_3/3.4_grocery_list.html#hints",
    "href": "problems/pset_3/3.4_grocery_list.html#hints",
    "title": "Grocery List",
    "section": "",
    "text": "Note that you can detect when the user has inputted control-d by catching an EOFError with code like:\ntry:\n    item = input()\nexcept EOFError:\n    ...\n\nOdds are you‚Äôll want to store your grocery list as a dict.\nNote that a dict comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#mapping-types-dict, among them get, and supports operations like:\nd[key]\n\nand\nif key in d:\n    ...\n\nwherein d is a dict and key is a str.\nBe sure to avoid or catch any KeyError.\nNote that you can sort a dictionary‚Äôs keys alphabetically by passing that dictionary as an argument to sorted."
  },
  {
    "objectID": "problems/pset_3/3.4_grocery_list.html#before-you-begin",
    "href": "problems/pset_3/3.4_grocery_list.html#before-you-begin",
    "title": "Grocery List",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir grocery\n\nto make a folder called grocery in your codespace.\nThen execute\ncd grocery\n\nto change directories into that folder. You should now see your terminal prompt as grocery/ $. You can now execute\ncode grocery.py\n\nto make a file called grocery.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_3/3.4_grocery_list.html#how-to-test",
    "href": "problems/pset_3/3.4_grocery_list.html#how-to-test",
    "title": "Grocery List",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python grocery.py. Type mango and press Enter, then type strawberry and press Enter, followed by control-d.¬†Your program should output:\n1 MANGO\n1 STRAWBERRY\n\nRun your program with python grocery.py. Type milk and press Enter, then type milk again and press Enter, followed by control-d.¬†Your program should output:\n2 MILK\n\nRun your program with python grocery.py. Type tortilla and press Enter, then type sweet potato and press Enter, followed by control-d.¬†Your program should output:\n1 SWEET POTATO\n1 TORTILLA"
  },
  {
    "objectID": "problems/pset_3/3.2_fuel_gauge.html",
    "href": "problems/pset_3/3.2_fuel_gauge.html",
    "title": "Fuel Gauge",
    "section": "",
    "text": "Source: amazon.com/dp/B09C4FL56G\nFuel gauges indicate, often with fractions, just how much fuel is in a tank. For instance 1/4 indicates that a tank is 25% full, 1/2 indicates that a tank is 50% full, and 3/4 indicates that a tank is 75% full.\nIn a file called fuel.py, implement a program that prompts the user for a fraction, formatted as X/Y, wherein each of X and Y is a positive integer, and then outputs, as a percentage rounded to the nearest integer, how much fuel is in the tank. If, though, 1% or less remains, output E instead to indicate that the tank is essentially empty. And if 99% or more remains, output F instead to indicate that the tank is essentially full.\nIf, though, X or Y is not an integer, X is greater than Y, or Y is 0, instead prompt the user again. (It is not necessary for Y to be 4.) Be sure to catch any exceptions like ValueError or ZeroDivisionError.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split.\nNote that you can handle two exceptions separately with code like:\ntry:\n    ...\nexcept ValueError:\n    ...\nexcept ZeroDivisionError:\n    ...\n\nOr you can handle two exceptions together with code like:\ntry:\n    ...\nexcept (ValueError, ZeroDivisionError):\n    ...\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir fuel\n\nto make a folder called fuel in your codespace.\nThen execute\ncd fuel\n\nto change directories into that folder. You should now see your terminal prompt as fuel/ $. You can now execute\ncode fuel.py\n\nto make a file called fuel.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python fuel.py. Type 3/4 and press Enter. Your program should output:\n75% \n\nRun your program with python fuel.py. Type 1/4 and press Enter. Your program should output:\n25%\n\nRun your program with python fuel.py. Type 4/4 and press Enter. Your program should output:\nF\n\nRun your program with python fuel.py. Type 0/4 and press Enter. Your program should output:\nE\n\nRun your program with python fuel.py. Type 4/0 and press Enter. Your program should handle a ZeroDivisionError and prompt the user again.\nRun your program with python fuel.py. Type three/four and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type 1.5/3 and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type -3/4 and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type 5/4 and press Enter. Your program should prompt the user again."
  },
  {
    "objectID": "problems/pset_3/3.2_fuel_gauge.html#hints",
    "href": "problems/pset_3/3.2_fuel_gauge.html#hints",
    "title": "Fuel Gauge",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split.\nNote that you can handle two exceptions separately with code like:\ntry:\n    ...\nexcept ValueError:\n    ...\nexcept ZeroDivisionError:\n    ...\n\nOr you can handle two exceptions together with code like:\ntry:\n    ...\nexcept (ValueError, ZeroDivisionError):\n    ..."
  },
  {
    "objectID": "problems/pset_3/3.2_fuel_gauge.html#before-you-begin",
    "href": "problems/pset_3/3.2_fuel_gauge.html#before-you-begin",
    "title": "Fuel Gauge",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir fuel\n\nto make a folder called fuel in your codespace.\nThen execute\ncd fuel\n\nto change directories into that folder. You should now see your terminal prompt as fuel/ $. You can now execute\ncode fuel.py\n\nto make a file called fuel.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_3/3.2_fuel_gauge.html#how-to-test",
    "href": "problems/pset_3/3.2_fuel_gauge.html#how-to-test",
    "title": "Fuel Gauge",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python fuel.py. Type 3/4 and press Enter. Your program should output:\n75% \n\nRun your program with python fuel.py. Type 1/4 and press Enter. Your program should output:\n25%\n\nRun your program with python fuel.py. Type 4/4 and press Enter. Your program should output:\nF\n\nRun your program with python fuel.py. Type 0/4 and press Enter. Your program should output:\nE\n\nRun your program with python fuel.py. Type 4/0 and press Enter. Your program should handle a ZeroDivisionError and prompt the user again.\nRun your program with python fuel.py. Type three/four and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type 1.5/3 and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type -3/4 and press Enter. Your program should handle a ValueError and prompt the user again.\nRun your program with python fuel.py. Type 5/4 and press Enter. Your program should prompt the user again."
  },
  {
    "objectID": "problems/pset_2/2.6_nutrition_facts.html",
    "href": "problems/pset_2/2.6_nutrition_facts.html",
    "title": "Nutrition Facts",
    "section": "",
    "text": "The U.S. Food & Drug Adminstration (FDA) offers downloadable/printable posters that ‚Äúshow nutrition information for the 20 most frequently consumed raw fruits ‚Ä¶ in the United States. Retail stores are welcome to download the posters, print, display and/or distribute them to consumers in close proximity to the relevant foods in the stores.‚Äù\nIn a file called nutrition.py, implement a program that prompts consumers users to input a fruit (case-insensitively) and then outputs the number of calories in one portion of that fruit, per the FDA‚Äôs poster for fruits, which is also available as text. Capitalization aside, assume that users will input fruits exactly as written in the poster (e.g., strawberries, not strawberry). Ignore any input that isn‚Äôt a fruit.\n\n\n\nRather than use a conditional with 20 Boolean expressions, one for each fruit, better to use a dict to associate a fruit with its calories!\nIf k is a str and d is a dict, you can check whether k is a key in d with code like:\nif k in d:\n    ...\n\nTake care to output the fruit‚Äôs calories, not calories from fat!\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir nutrition\n\nto make a folder called nutrition in your codespace.\nThen execute\ncd nutrition\n\nto change directories into that folder. You should now see your terminal prompt as nutrition/ $. You can now execute\ncode nutrition.py\n\nto make a file called nutrition.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python nutrition.py. Type Apple and press Enter. Your program should output:\nCalories: 130   \n\nRun your program with python nutrition.py. Type Avocado and press Enter. Your program should output:\nCalories: 50\n\nRun your program with python nutrition.py. Type Sweet Cherries and press Enter. Your program should output\nCalories: 100\n\nRun your program with python nutrition.py. Type Tomato and press Enter. Your program should output nothing.\n\nBe sure to try other fruits and vary the casing of your input. Your program should behave as expected, case-insensitively."
  },
  {
    "objectID": "problems/pset_2/2.6_nutrition_facts.html#hints",
    "href": "problems/pset_2/2.6_nutrition_facts.html#hints",
    "title": "Nutrition Facts",
    "section": "",
    "text": "Rather than use a conditional with 20 Boolean expressions, one for each fruit, better to use a dict to associate a fruit with its calories!\nIf k is a str and d is a dict, you can check whether k is a key in d with code like:\nif k in d:\n    ...\n\nTake care to output the fruit‚Äôs calories, not calories from fat!"
  },
  {
    "objectID": "problems/pset_2/2.6_nutrition_facts.html#before-you-begin",
    "href": "problems/pset_2/2.6_nutrition_facts.html#before-you-begin",
    "title": "Nutrition Facts",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir nutrition\n\nto make a folder called nutrition in your codespace.\nThen execute\ncd nutrition\n\nto change directories into that folder. You should now see your terminal prompt as nutrition/ $. You can now execute\ncode nutrition.py\n\nto make a file called nutrition.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_2/2.6_nutrition_facts.html#how-to-test",
    "href": "problems/pset_2/2.6_nutrition_facts.html#how-to-test",
    "title": "Nutrition Facts",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python nutrition.py. Type Apple and press Enter. Your program should output:\nCalories: 130   \n\nRun your program with python nutrition.py. Type Avocado and press Enter. Your program should output:\nCalories: 50\n\nRun your program with python nutrition.py. Type Sweet Cherries and press Enter. Your program should output\nCalories: 100\n\nRun your program with python nutrition.py. Type Tomato and press Enter. Your program should output nothing.\n\nBe sure to try other fruits and vary the casing of your input. Your program should behave as expected, case-insensitively."
  },
  {
    "objectID": "problems/pset_2/2.4_just_setting_up_my_twttr.html",
    "href": "problems/pset_2/2.4_just_setting_up_my_twttr.html",
    "title": "Just setting up my twttr",
    "section": "",
    "text": "just setting up my twttr\n‚Äî jack‚ö°Ô∏è (@jack) March 21, 2006\n\nWhen texting or tweeting, it‚Äôs not uncommon to shorten words to save time or space, as by omitting vowels, much like Twitter was originally called twttr. In a file called twttr.py, implement a program that prompts the user for a str of text and then outputs that same text but with all vowels (A, E, I, O, and U) omitted, whether inputted in uppercase or lowercase.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is ‚Äúiterable,‚Äù which means you can iterate over each of its characters in a loop. For instance, if s is a str, you could print each of its characters, one at a time, with code like:\nfor c in s:\n    print(c, end=\"\")\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir twttr\n\nto make a folder called twttr in your codespace.\nThen execute\ncd twttr\n\nto change directories into that folder. You should now see your terminal prompt as twttr/ $. You can now execute\ncode twttr.py\n\nto make a file called twttr.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python twttr.py. Type Twitter and press Enter. Your program should output:\nTwttr   \n\nRun your program with python twttr.py. Type What's your name? and press Enter. Your program should output:\nWht's yr nm?\n\nRun your program with python twttr.py. Type CS50 and press Enter. Your program should output\nCS50"
  },
  {
    "objectID": "problems/pset_2/2.4_just_setting_up_my_twttr.html#hints",
    "href": "problems/pset_2/2.4_just_setting_up_my_twttr.html#hints",
    "title": "Just setting up my twttr",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is ‚Äúiterable,‚Äù which means you can iterate over each of its characters in a loop. For instance, if s is a str, you could print each of its characters, one at a time, with code like:\nfor c in s:\n    print(c, end=\"\")"
  },
  {
    "objectID": "problems/pset_2/2.4_just_setting_up_my_twttr.html#before-you-begin",
    "href": "problems/pset_2/2.4_just_setting_up_my_twttr.html#before-you-begin",
    "title": "Just setting up my twttr",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir twttr\n\nto make a folder called twttr in your codespace.\nThen execute\ncd twttr\n\nto change directories into that folder. You should now see your terminal prompt as twttr/ $. You can now execute\ncode twttr.py\n\nto make a file called twttr.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_2/2.4_just_setting_up_my_twttr.html#how-to-test",
    "href": "problems/pset_2/2.4_just_setting_up_my_twttr.html#how-to-test",
    "title": "Just setting up my twttr",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python twttr.py. Type Twitter and press Enter. Your program should output:\nTwttr   \n\nRun your program with python twttr.py. Type What's your name? and press Enter. Your program should output:\nWht's yr nm?\n\nRun your program with python twttr.py. Type CS50 and press Enter. Your program should output\nCS50"
  },
  {
    "objectID": "problems/pset_2/2.2_camelcase.html",
    "href": "problems/pset_2/2.2_camelcase.html",
    "title": "camelCase",
    "section": "",
    "text": "camel\n\n\nSource: en.wikipedia.org/wiki/Camel_case\nIn some languages, it‚Äôs common to use camel case (otherwise known as ‚Äúmixed case‚Äù) for variables‚Äô names when those names comprise multiple words, whereby the first letter of the first word is lowercase but the first letter of each subsequent word is uppercase. For instance, whereas a variable for a user‚Äôs name might be called name, a variable for a user‚Äôs first name might be called firstName, and a variable for a user‚Äôs preferred first name (e.g., nickname) might be called preferredFirstName.\nPython, by contrast, recommends snake case, whereby words are instead separated by underscores (_), with all letters in lowercase. For instance, those same variables would be called name, first_name, and preferred_first_name, respectively, in Python.\nIn a file called camel.py, implement a program that prompts the user for the name of a variable in camel case and outputs the corresponding name in snake case. Assume that the user‚Äôs input will indeed be in camel case.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is ‚Äúiterable,‚Äù which means you can iterate over each of its characters in a loop. For instance, if s is a str, you could print each of its characters, one at a time, with code like:\nfor c in s:\n    print(c, end=\"\")\n\n\n\n\n\nOpen your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir camel\n\nto make a folder called camel in your codespace.\nThen execute\ncd camel\n\nto change directories into that folder. You should now see your terminal prompt as camel/ $. You can now execute\ncode camel.py\n\nto make a file called camel.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python camel.py. Type name and press Enter. Your program should output:\nname   \n\nRun your program with python camel.py. Type firstName and press Enter. Your program should output:\nfirst_name\n\nRun your program with python camel.py. Type preferredFirstName and press Enter. Your program should output\npreferred_first_name"
  },
  {
    "objectID": "problems/pset_2/2.2_camelcase.html#hints",
    "href": "problems/pset_2/2.2_camelcase.html#hints",
    "title": "camelCase",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is ‚Äúiterable,‚Äù which means you can iterate over each of its characters in a loop. For instance, if s is a str, you could print each of its characters, one at a time, with code like:\nfor c in s:\n    print(c, end=\"\")"
  },
  {
    "objectID": "problems/pset_2/2.2_camelcase.html#before-you-begin",
    "href": "problems/pset_2/2.2_camelcase.html#before-you-begin",
    "title": "camelCase",
    "section": "",
    "text": "Open your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir camel\n\nto make a folder called camel in your codespace.\nThen execute\ncd camel\n\nto change directories into that folder. You should now see your terminal prompt as camel/ $. You can now execute\ncode camel.py\n\nto make a file called camel.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_2/2.2_camelcase.html#how-to-test",
    "href": "problems/pset_2/2.2_camelcase.html#how-to-test",
    "title": "camelCase",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python camel.py. Type name and press Enter. Your program should output:\nname   \n\nRun your program with python camel.py. Type firstName and press Enter. Your program should output:\nfirst_name\n\nRun your program with python camel.py. Type preferredFirstName and press Enter. Your program should output\npreferred_first_name"
  },
  {
    "objectID": "problems/pset_1/1.6_meal_time.html",
    "href": "problems/pset_1/1.6_meal_time.html",
    "title": "Meal Time",
    "section": "",
    "text": "Suppose that you‚Äôre in a country where it‚Äôs customary to eat breakfast between 7:00 and 8:00, lunch between 12:00 and 13:00, and dinner between 18:00 and 19:00. Wouldn‚Äôt it be nice if you had a program that could tell you what to eat when?\nIn meal.py, implement a program that prompts the user for a time and outputs whether it‚Äôs breakfast time, lunch time, or dinner time. If it‚Äôs not time for a meal, don‚Äôt output anything at all. Assume that the user‚Äôs input will be formatted in 24-hour time as #:## or ##:##. And assume that each meal‚Äôs time range is inclusive. For instance, whether it‚Äôs 7:00, 7:01, 7:59, or 8:00, or anytime in between, it‚Äôs time for breakfast.\nStructure your program per the below, wherein convert is a function (that can be called by main) that converts time, a str in 24-hour format, to the corresponding number of hours as a float. For instance, given a time like \"7:30\" (i.e., 7 hours and 30 minutes), convert should return 7.5 (i.e., 7.5 hours).\ndef main():\n    ...\n\n\ndef convert(time):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split, which separates a str into a sequence of values, all of which can be assigned to variables at once. For instance, if time is a str like \"7:30\", then\nhours, minutes = time.split(\":\")\n\nwill assign \"7\" to hours and \"30\" to minutes.\nKeep in mind that there are 60 minutes in 1 hour.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir meal\n\nto make a folder called meal in your codespace.\nThen execute\ncd meal\n\nto change directories into that folder. You should now see your terminal prompt as meal/ $. You can now execute\ncode meal.py\n\nto make a file called meal.py where you‚Äôll write your program.\n\n\n\nIf up for a challenge, optionally add support for 12-hour times, allowing the user to input times in these formats too:\n\n#:## a.m. and ##:## a.m.\n#:## p.m. and ##:## p.m.\n\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python meal.py. Type 7:00 and press Enter. Your program should output:\nbreakfast time   \n\nRun your program with python meal.py. Type 7:30 and press Enter. Your program should output:\nbreakfast time\n\nRun your program with python meal.py. Type 12:42 and press Enter. Your program should output\nlunch time\n\nRun your program with python meal.py. Type 18:32 and press Enter. Your program should output\ndinner time\n\nRun your program with python meal.py. Type 11:11 and press Enter. Your program should output nothing."
  },
  {
    "objectID": "problems/pset_1/1.6_meal_time.html#hints",
    "href": "problems/pset_1/1.6_meal_time.html#hints",
    "title": "Meal Time",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split, which separates a str into a sequence of values, all of which can be assigned to variables at once. For instance, if time is a str like \"7:30\", then\nhours, minutes = time.split(\":\")\n\nwill assign \"7\" to hours and \"30\" to minutes.\nKeep in mind that there are 60 minutes in 1 hour."
  },
  {
    "objectID": "problems/pset_1/1.6_meal_time.html#before-you-begin",
    "href": "problems/pset_1/1.6_meal_time.html#before-you-begin",
    "title": "Meal Time",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir meal\n\nto make a folder called meal in your codespace.\nThen execute\ncd meal\n\nto change directories into that folder. You should now see your terminal prompt as meal/ $. You can now execute\ncode meal.py\n\nto make a file called meal.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_1/1.6_meal_time.html#challenge",
    "href": "problems/pset_1/1.6_meal_time.html#challenge",
    "title": "Meal Time",
    "section": "",
    "text": "If up for a challenge, optionally add support for 12-hour times, allowing the user to input times in these formats too:\n\n#:## a.m. and ##:## a.m.\n#:## p.m. and ##:## p.m."
  },
  {
    "objectID": "problems/pset_1/1.6_meal_time.html#how-to-test",
    "href": "problems/pset_1/1.6_meal_time.html#how-to-test",
    "title": "Meal Time",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python meal.py. Type 7:00 and press Enter. Your program should output:\nbreakfast time   \n\nRun your program with python meal.py. Type 7:30 and press Enter. Your program should output:\nbreakfast time\n\nRun your program with python meal.py. Type 12:42 and press Enter. Your program should output\nlunch time\n\nRun your program with python meal.py. Type 18:32 and press Enter. Your program should output\ndinner time\n\nRun your program with python meal.py. Type 11:11 and press Enter. Your program should output nothing."
  },
  {
    "objectID": "problems/pset_1/1.4_file_extensions.html",
    "href": "problems/pset_1/1.4_file_extensions.html",
    "title": "File Extensions",
    "section": "",
    "text": "Even though Windows and macOS sometimes hide them, most files have file extensions, a suffix that starts with a period (.) at the end of their name. For instance, file names for GIFs end with .gif, and file names for JPEGs end with .jpg or .jpeg. When you double-click on a file to open it, your computer uses its file extension to determine which program to launch.\nWeb browsers, by contrast, rely on media types, formerly known as MIME types, to determine how to display files that live on the web. When you download a file from a web server, that server sends an HTTP header, along with the file itself, indicating the file‚Äôs media type. For instance, the media type for a GIF is image/gif, and the media type for a JPEG is image/jpeg. To determine the media type for a file, a web server typically looks at the file‚Äôs extension, mapping one to the other.\nSee developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types for common types.\nIn a file called extensions.py, implement a program that prompts the user for the name of a file and then outputs that file‚Äôs media type if the file‚Äôs name ends, case-insensitively, in any of these suffixes:\n\n.gif\n.jpg\n.jpeg\n.png\n.pdf\n.txt\n.zip\n\nIf the file‚Äôs name ends with some other suffix or has no suffix at all, output application/octet-stream instead, which is a common default.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir extensions\n\nto make a folder called extensions in your codespace.\nThen execute\ncd extensions\n\nto change directories into that folder. You should now see your terminal prompt as extensions/ $. You can now execute\ncode extensions.py\n\nto make a file called extensions.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python extensions.py. Type happy.jpg and press Enter. Your program should output:\nimage/jpeg   \n\nRun your program with python extensions.py. Type document.pdf and press Enter. Your program should output:\napplication/pdf\n\n\nBe sure to test each of the other file formats, vary the casing of your input, and ‚Äúaccidentally‚Äù add spaces on either side of your input before pressing enter. Your program should behave as expected, case- and space-insensitively."
  },
  {
    "objectID": "problems/pset_1/1.4_file_extensions.html#hints",
    "href": "problems/pset_1/1.4_file_extensions.html#hints",
    "title": "File Extensions",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods."
  },
  {
    "objectID": "problems/pset_1/1.4_file_extensions.html#before-you-begin",
    "href": "problems/pset_1/1.4_file_extensions.html#before-you-begin",
    "title": "File Extensions",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir extensions\n\nto make a folder called extensions in your codespace.\nThen execute\ncd extensions\n\nto change directories into that folder. You should now see your terminal prompt as extensions/ $. You can now execute\ncode extensions.py\n\nto make a file called extensions.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_1/1.4_file_extensions.html#how-to-test",
    "href": "problems/pset_1/1.4_file_extensions.html#how-to-test",
    "title": "File Extensions",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python extensions.py. Type happy.jpg and press Enter. Your program should output:\nimage/jpeg   \n\nRun your program with python extensions.py. Type document.pdf and press Enter. Your program should output:\napplication/pdf\n\n\nBe sure to test each of the other file formats, vary the casing of your input, and ‚Äúaccidentally‚Äù add spaces on either side of your input before pressing enter. Your program should behave as expected, case- and space-insensitively."
  },
  {
    "objectID": "problems/pset_1/1.2_deep_thought.html",
    "href": "problems/pset_1/1.2_deep_thought.html",
    "title": "Deep Thought",
    "section": "",
    "text": "‚ÄúAll right,‚Äù said the computer, and settled into silence again. The two men fidgeted. The tension was unbearable.\n‚ÄúYou‚Äôre really not going to like it,‚Äù observed Deep Thought.\n‚ÄúTell us!‚Äù\n‚ÄúAll right,‚Äù said Deep Thought. ‚ÄúThe Answer to the Great Question‚Ä¶‚Äù\n‚ÄúYes‚Ä¶!‚Äù\n‚ÄúOf Life, the Universe and Everything‚Ä¶‚Äù said Deep Thought.\n‚ÄúYes‚Ä¶!‚Äù\n‚ÄúIs‚Ä¶‚Äù said Deep Thought, and paused.\n‚ÄúYes‚Ä¶!‚Äù\n‚ÄúIs‚Ä¶‚Äù\n‚ÄúYes‚Ä¶!!!‚Ä¶?‚Äù\n‚ÄúForty-two,‚Äù said Deep Thought, with infinite majesty and calm.‚Äù\n‚Äî The Hitchhiker‚Äôs Guide to the Galaxy, Douglas Adams\n\nIn deep.py, implement a program that prompts the user for the answer to the Great Question of Life, the Universe and Everything, outputting Yes if the user inputs 42 or (case-insensitively) forty-two or forty two. Otherwise output No.\n\n\n\nNo need to convert the user‚Äôs input to an int if you check for equality with \"42\", a str, rather than 42, an int!\nIt‚Äôs okay if your output or the user‚Äôs wraps onto multiple lines.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir deep\n\nto make a folder called deep in your codespace.\nThen execute\ncd deep\n\nto change directories into that folder. You should now see your terminal prompt as deep/ $. You can now execute\ncode deep.py\n\nto make a file called deep.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python deep.py. Type 42 and press Enter. Your program should output:\nYes \n\nRun your program with python deep.py. Type Forty Two and press Enter. Your program should output:\nYes\n\nRun your program with python deep.py. Type forty-two and press Enter. Your program should output\nYes\n\nRun your program with python deep.py. Type 50 and press Enter. Your program should output\nNo\n\n\nBe sure to vary the casing of your input and ‚Äúaccidentally‚Äù add spaces on either side of your input before pressing enter. Your program should behave as expected, case- and space-insensitively."
  },
  {
    "objectID": "problems/pset_1/1.2_deep_thought.html#hints",
    "href": "problems/pset_1/1.2_deep_thought.html#hints",
    "title": "Deep Thought",
    "section": "",
    "text": "No need to convert the user‚Äôs input to an int if you check for equality with \"42\", a str, rather than 42, an int!\nIt‚Äôs okay if your output or the user‚Äôs wraps onto multiple lines."
  },
  {
    "objectID": "problems/pset_1/1.2_deep_thought.html#before-you-begin",
    "href": "problems/pset_1/1.2_deep_thought.html#before-you-begin",
    "title": "Deep Thought",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir deep\n\nto make a folder called deep in your codespace.\nThen execute\ncd deep\n\nto change directories into that folder. You should now see your terminal prompt as deep/ $. You can now execute\ncode deep.py\n\nto make a file called deep.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_1/1.2_deep_thought.html#how-to-test",
    "href": "problems/pset_1/1.2_deep_thought.html#how-to-test",
    "title": "Deep Thought",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python deep.py. Type 42 and press Enter. Your program should output:\nYes \n\nRun your program with python deep.py. Type Forty Two and press Enter. Your program should output:\nYes\n\nRun your program with python deep.py. Type forty-two and press Enter. Your program should output\nYes\n\nRun your program with python deep.py. Type 50 and press Enter. Your program should output\nNo\n\n\nBe sure to vary the casing of your input and ‚Äúaccidentally‚Äù add spaces on either side of your input before pressing enter. Your program should behave as expected, case- and space-insensitively."
  },
  {
    "objectID": "problems/pset_0/0.6_tip_calculator.html",
    "href": "problems/pset_0/0.6_tip_calculator.html",
    "title": "Tip Calculator",
    "section": "",
    "text": "And now for my Wizard tip calculator.\n‚Äî Morty Seinfeld\n\nIn the United States, it‚Äôs customary to leave a tip for your server after dining in a restaurant, typically an amount equal to 15% or more of your meal‚Äôs cost. Not to worry, though, we‚Äôve written a tip calculator for you, below!\ndef main():\n    dollars = dollars_to_float(input(\"How much was the meal? \"))\n    percent = percent_to_float(input(\"What percentage would you like to tip? \"))\n    tip = dollars * percent\n    print(f\"Leave ${tip:.2f}\")\n\n\ndef dollars_to_float(d):\n    # TODO\n\n\ndef percent_to_float(p):\n    # TODO\n\n\nmain()\n\nWell, we‚Äôve written most of a tip calculator for you. Unfortunately, we didn‚Äôt have time to implement two functions:\n\ndollars_to_float, which should accept a str as input (formatted as $##.##, wherein each # is a decimal digit), remove the leading $, and return the amount as a float. For instance, given $50.00 as input, it should return 50.0.\npercent_to_float, which should accept a str as input (formatted as ##%, wherein each # is a decimal digit), remove the trailing %, and return the percentage as a float. For instance, given 15% as input, it should return 0.15.\n\nAssume that the user will input values in the expected formats.\n\n\n\nRecall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that float can convert a str to a float, per docs.python.org/3/library/functions.html#float.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir tip\n\nto make a folder called tip in your codespace.\nThen execute\ncd tip\n\nto change directories into that folder. You should now see your terminal prompt as tip/ $. You can now execute\ncode tip.py\n\nto make a file called tip.py. Copy and paste the code above into a file, and complete the implementations of dollars_to_float and percent_to_float, replacing each TODO with one or more lines of your own code.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python tip.py. Type $50.00 and press Enter. Then, type 15% and press Enter. Your program should output:\nLeave $7.50    \n\nRun your program with python tip.py. Type $100.00 and press Enter. Then, type 18% and press Enter. Your program should output:\nLeave $18.00\n\nRun your program with python tip.py. Type $15.00 and press Enter. Then, type 25% and press Enter. Your program should output\nLeave $3.75"
  },
  {
    "objectID": "problems/pset_0/0.6_tip_calculator.html#hints",
    "href": "problems/pset_0/0.6_tip_calculator.html#hints",
    "title": "Tip Calculator",
    "section": "",
    "text": "Recall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that float can convert a str to a float, per docs.python.org/3/library/functions.html#float.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods."
  },
  {
    "objectID": "problems/pset_0/0.6_tip_calculator.html#before-you-begin",
    "href": "problems/pset_0/0.6_tip_calculator.html#before-you-begin",
    "title": "Tip Calculator",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir tip\n\nto make a folder called tip in your codespace.\nThen execute\ncd tip\n\nto change directories into that folder. You should now see your terminal prompt as tip/ $. You can now execute\ncode tip.py\n\nto make a file called tip.py. Copy and paste the code above into a file, and complete the implementations of dollars_to_float and percent_to_float, replacing each TODO with one or more lines of your own code."
  },
  {
    "objectID": "problems/pset_0/0.6_tip_calculator.html#how-to-test",
    "href": "problems/pset_0/0.6_tip_calculator.html#how-to-test",
    "title": "Tip Calculator",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python tip.py. Type $50.00 and press Enter. Then, type 15% and press Enter. Your program should output:\nLeave $7.50    \n\nRun your program with python tip.py. Type $100.00 and press Enter. Then, type 18% and press Enter. Your program should output:\nLeave $18.00\n\nRun your program with python tip.py. Type $15.00 and press Enter. Then, type 25% and press Enter. Your program should output\nLeave $3.75"
  },
  {
    "objectID": "problems/pset_0/0.4_making_faces.html",
    "href": "problems/pset_0/0.4_making_faces.html",
    "title": "Making Faces",
    "section": "",
    "text": "Before there were emoji, there were emoticons, whereby text like :) was a happy face and text like :( was a sad face. Nowadays, programs tend to convert emoticons to emoji automatically!\nIn a file called faces.py, implement a function called convert that accepts a str as input and returns that same input with any :) converted to üôÇ (otherwise known as a slightly smiling face) and any :( converted to üôÅ (otherwise known as a slightly frowning face). All other text should be returned unchanged.\nThen, in that same file, implement a function called main that prompts the user for input, calls convert on that input, and prints the result. You‚Äôre welcome, but not required, to prompt the user explicitly, as by passing a str of your own as an argument to input. Be sure to call main at the bottom of your file.\n\n\n\nRecall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nAn emoji is actually just a character, so you can quote it like any str, a la \"üòê\". And you can copy and paste the emoji from this page into your own code as needed.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir faces\n\nto make a folder called faces in your codespace.\nThen execute\ncd faces\n\nto change directories into that folder. You should now see your terminal prompt as faces/ $. You can now execute\ncode faces.py\n\nto make a file called faces.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python faces.py. Type Hello :) and press Enter. Your program should output:\nHello üôÇ\n\nRun your program with python faces.py. Type Goodbye :( and press Enter. Your program should output:\nGoodbye üôÅ\n\nRun your program with python faces.py. Type Hello :) Goodbye :( and press Enter. Your program should output\nHello üôÇ Goodbye üôÅ"
  },
  {
    "objectID": "problems/pset_0/0.4_making_faces.html#hints",
    "href": "problems/pset_0/0.4_making_faces.html#hints",
    "title": "Making Faces",
    "section": "",
    "text": "Recall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nAn emoji is actually just a character, so you can quote it like any str, a la \"üòê\". And you can copy and paste the emoji from this page into your own code as needed."
  },
  {
    "objectID": "problems/pset_0/0.4_making_faces.html#before-you-begin",
    "href": "problems/pset_0/0.4_making_faces.html#before-you-begin",
    "title": "Making Faces",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir faces\n\nto make a folder called faces in your codespace.\nThen execute\ncd faces\n\nto change directories into that folder. You should now see your terminal prompt as faces/ $. You can now execute\ncode faces.py\n\nto make a file called faces.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_0/0.4_making_faces.html#how-to-test",
    "href": "problems/pset_0/0.4_making_faces.html#how-to-test",
    "title": "Making Faces",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python faces.py. Type Hello :) and press Enter. Your program should output:\nHello üôÇ\n\nRun your program with python faces.py. Type Goodbye :( and press Enter. Your program should output:\nGoodbye üôÅ\n\nRun your program with python faces.py. Type Hello :) Goodbye :( and press Enter. Your program should output\nHello üôÇ Goodbye üôÅ"
  },
  {
    "objectID": "problems/pset_0/0.2_indoor_voice.html",
    "href": "problems/pset_0/0.2_indoor_voice.html",
    "title": "Indoor Voice",
    "section": "",
    "text": "WRITING IN ALL CAPS IS LIKE YELLING.\nBest to use your ‚Äúindoor voice‚Äù sometimes, writing entirely in lowercase.\nIn a file called indoor.py, implement a program in Python that prompts the user for input and then outputs that same input in lowercase. Punctuation and whitespace should be outputted unchanged. You‚Äôre welcome, but not required, to prompt the user explicitly, as by passing a str of your own as an argument to input.\n\n\n\nRecall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir indoor\n\nto make a folder called indoor in your codespace.\nThen execute\ncd indoor\n\nto change directories into that folder. You should now see your terminal prompt as indoor/ $. You can now execute\ncode indoor.py\n\nto make a file called indoor.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually. At the indoor/ $ prompt in your terminal: :\n\nRun your program with python indoor.py. Type HELLO and press Enter. Your program should output hello.\nRun your program with python indoor.py. Type THIS IS GREAT and press Enter. Your program should output this is great.\nRun your program with python indoor.py. Type 50 and press Enter. Your program should output 50.\n\nIf you run into an error saying your file cannot be opened, retrace your steps to be sure that you are inside your indoor folder and have saved your indoor.py file there. Remember how?\nBut be sure to test whether your code works!"
  },
  {
    "objectID": "problems/pset_0/0.2_indoor_voice.html#hints",
    "href": "problems/pset_0/0.2_indoor_voice.html#hints",
    "title": "Indoor Voice",
    "section": "",
    "text": "Recall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods."
  },
  {
    "objectID": "problems/pset_0/0.2_indoor_voice.html#before-you-begin",
    "href": "problems/pset_0/0.2_indoor_voice.html#before-you-begin",
    "title": "Indoor Voice",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir indoor\n\nto make a folder called indoor in your codespace.\nThen execute\ncd indoor\n\nto change directories into that folder. You should now see your terminal prompt as indoor/ $. You can now execute\ncode indoor.py\n\nto make a file called indoor.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_0/0.2_indoor_voice.html#how-to-test",
    "href": "problems/pset_0/0.2_indoor_voice.html#how-to-test",
    "title": "Indoor Voice",
    "section": "",
    "text": "Here‚Äôs how to test your code manually. At the indoor/ $ prompt in your terminal: :\n\nRun your program with python indoor.py. Type HELLO and press Enter. Your program should output hello.\nRun your program with python indoor.py. Type THIS IS GREAT and press Enter. Your program should output this is great.\nRun your program with python indoor.py. Type 50 and press Enter. Your program should output 50.\n\nIf you run into an error saying your file cannot be opened, retrace your steps to be sure that you are inside your indoor folder and have saved your indoor.py file there. Remember how?\nBut be sure to test whether your code works!"
  },
  {
    "objectID": "notes/notes_9.html",
    "href": "notes/notes_9.html",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "Core idea: Prompt engineering is interface design for AI tools. You are not ‚Äúasking a question‚Äù ‚Äî you are specifying an input contract (context + constraints + success criteria) so the output is testable.\n\n\n\nThis week builds a practical toolkit for getting reliable work out of coding assistants.\n\n9.1 Understanding prompt engineering: why prompts fail, and what ‚Äúbetter prompts‚Äù look like\n9.2 Anatomy of a prompt: context, instructions, examples, and expected format\n9.3 Crafting the ultimate prompt: using the model to improve your own prompts\n9.4 Fundamental prompt types: zero-shot, few-shot, open-ended, constrained, structured\n9.5 Advanced prompt types: chain-of-thought, recursive prompting, context manipulation, refinement, output control\n9.6 Prompt techniques for programmers: how this becomes a daily workflow habit\n\n\n\n\n\n\n‚ÄúInstead of getting generic responses, strong prompts can greatly enhance the quality, accuracy, and usefulness of AI-generated code and documents.‚Äù\n\n\n‚ÄúSome parts of prompt engineering may seem natural‚Äîlike how we learned to improve our search engine questions over time.‚Äù\n\n\n‚ÄúLet‚Äôs explore how to create better prompts to get the best results, save time, and increase productivity.‚Äù\n\n\n‚ÄúContext is the backbone of any good prompt.‚Äù\n\n\n‚ÄúProvide concrete examples to illustrate desired output.‚Äù\n\n\n‚ÄúZero-shot prompts are very basic and concise.‚Äù\n\n\n‚ÄúFew-shot prompting lets models generate from just a few examples.‚Äù\n\n\n‚ÄúThese types of prompts limit the scope of the model‚Äôs response.‚Äù\n\n\n\n\n\n\nprompt: the input you send the model; in practice it‚Äôs a specification of what you want.\ncontext: background info the model needs to interpret the task (code, data shape, constraints).\nconstraints: boundaries you set (language, complexity, libraries, performance, security rules).\nfew-shot: showing a couple of examples so the model copies the pattern.\nstructured prompt: a prompt that forces the output into a predictable structure (JSON, table, sections).\noutput control: techniques that reduce randomness by restricting response shape.\n\n\n\n\n\n\nThese images were extracted from the Week 09 PDF and are used inline below.\n\n\n\n\n\nPrompt engineering is not ‚Äútricking‚Äù the model. It‚Äôs about reducing ambiguity.\n\n\nCoding tasks are brittle:\n\nsmall mistakes cause crashes\nmissing constraints produce insecure or inefficient code\na ‚Äúmostly correct‚Äù solution can still be useless\n\nWhen prompts fail, it‚Äôs usually one of these reasons:\n\nUnclear task (what action do you want?)\nMissing context (what codebase? what inputs?)\nNo success criteria (how do we judge ‚Äúgood‚Äù?)\nNo output format (what should the response look like?)\nNo constraints (libraries? style? performance?)\n\n\n\n\n\nA classic failure is:\n\nPrompt: ‚ÄúFix this code‚Äù\nOutput: generic advice, or wrong assumptions\n\nInstead, you want a prompt that provides:\n\nthe exact error\nthe code\nthe expected behaviour\nwhat you already tried\nhow you want the answer returned\n\n\n\n\n\n\nA good prompt is a communication bundle.\nThink of it as four parts:\n\nContext ‚Äî what the model needs to know\nInstructions ‚Äî what to do\nExamples ‚Äî patterns to follow\nFormat contract ‚Äî the exact structure of the response\n\n\n\n\nContext can be:\n\nthe code you‚Äôre working on\nthe data format / schema\nenvironment details (OS, Python version)\nconstraints: libraries allowed, complexity limits\n\nRule of thumb: if a human dev would ask for it before helping you, the model needs it too.\n\n\n\nGood instruction starts with a clear verb:\n\n‚Äúrefactor‚Äù\n‚Äúdebug‚Äù\n‚Äúgenerate tests‚Äù\n‚Äúexplain‚Äù\n‚Äúconvert‚Äù\n\nBad instruction is vague:\n\n‚Äúhelp me‚Äù\n‚Äúimprove this‚Äù\n\n\n\n\nFew-shot prompting is basically pattern copying.\nIf you want a specific style:\n\nshow 1‚Äì2 examples\nkeep them short\nkeep formatting consistent\n\n\n\n\nIf you don‚Äôt specify format, the model will:\n\nramble\nmix explanation and code\ninvent file structures\n\nSo you specify:\n\n‚Äúreturn JSON only‚Äù\n‚Äúreturn only Python code‚Äù\n‚Äúreturn a markdown checklist‚Äù\n\n\n\n\n\n\nThis section introduces a powerful move:\n‚úÖ Use an LLM to improve your prompt before using it for the real task.\nInstead of:\n\n‚ÄúWrite an API request tutorial‚Äù\n\nYou ask the model:\n\n‚ÄúImprove this prompt so it produces the best possible tutorial.‚Äù\n\n\n\n\nUse this when you want a high-quality response.\nraw_prompt = \"Give me instructions on how to send an HTTP request to an API and handle errors.\"\n\nrefiner = f\"\"\"\nYou are an expert prompt engineer.\n\nImprove the prompt below by:\n- adding missing context questions\n- adding constraints\n- specifying output format\n\nPROMPT TO IMPROVE:\n{raw_prompt}\n\nReturn the improved prompt only.\n\"\"\"\n\nprint(refiner)\nWhat you‚Äôre doing:\n\nturning fuzzy intent into a structured request\nforcing the model to ask missing questions\n\n\n\n\n\n\nThis week introduces several ‚Äúprompt families‚Äù.\n\n\nZero-shot = no examples.\nExample:\n\n‚ÄúWrite a Python function to validate emails.‚Äù\n\nBest when:\n\nthe task is common\nthe output shape is simple\n\nRisk:\n\nthe model guesses assumptions\n\nzero_shot = \"Write a Python function that validates an email address.\"\nprint(zero_shot)\n\n\n\nFew-shot = provide examples.\nBest when:\n\nyou care about formatting\nyou want a consistent style\n\nfew_shot = \"\"\"\nYou are a Python developer.\n\nExample 1:\ndef double(x):\n    return x * 2\n\nExample 2:\ndef square(x):\n    return x ** 2\n\nNow write a function:\ndef cube(x):\n\"\"\"\nprint(few_shot)\n\n\n\nOpen-ended = exploration.\nBest for:\n\ncomparing tools\nbrainstorming designs\ngenerating options\n\nBad for:\n\nprecise code requirements\n\n\n\n\nConstrained prompts are strict.\nExamples:\n\n‚ÄúList exactly three built-in Python data structures.‚Äù\n‚ÄúReturn only code.‚Äù\n\n\nconstrained = \"List exactly three built-in Python data structures.\"\nprint(constrained)\n\n\n\nIterative prompting = conversation loop.\nYou:\n\nask\nevaluate\nrefine\n\nThis behaves like debugging.\nprompt_v1 = \"Explain why this test is failing.\"\nprompt_v2 = \"Explain why this pytest test is failing. Use bullet points and include the fixed code.\"\nprint(prompt_v1)\nprint(prompt_v2)\n\n\n\nStructured prompts enforce a schema.\nExample:\n\n‚ÄúReturn JSON with keys: files, changes, reasons‚Äù\n\nThis is huge for engineering teams.\nstructured = \"\"\"\nReturn JSON only.\n\nSchema:\n{\"files\": [{\"path\": \"...\", \"change\": \"...\", \"reason\": \"...\"}]}\n\nTask: Propose refactor changes for a small Python script.\n\"\"\"\nprint(structured)\n\n\n\n\n\nThese techniques are about increasing reliability.\n\n\nIn this week, chain-of-thought means:\n\nencourage step-by-step reasoning\nreduce ‚Äújumping to conclusions‚Äù\n\nUse carefully: the model may sound confident even when wrong.\n\n\n\n\nRecursive prompting = prompt ‚Üí output ‚Üí prompt again.\nExample workflow:\n\ngenerate draft\ncritique draft\nrevise draft\n\nThis is similar to:\n\ncode review loops\niterative refactoring\n\n\n\n\nContext manipulation = changing what the model sees.\nExamples:\n\ninclude only the relevant file (not the whole repo)\nprovide a minimal failing example\nredact secrets and irrelevant text\n\n\n\n\nInstruction refinement = tuning wording.\nSmall changes matter:\n\n‚Äúexplain‚Äù vs ‚Äúteach‚Äù\n‚Äúbrief‚Äù vs ‚Äúdetailed‚Äù\n‚Äúcode only‚Äù vs ‚Äúcode + rationale‚Äù\n\n\n\n\n\nOutput control = forcing response format.\nThis is key when you need:\n\ndocumentation\ncommit messages\nstructured change requests\n\n\n\n\n\n\nThis part is where this week becomes ‚Äúreal world‚Äù.\n\n\nThink:\n\nprompt = function signature\ncontext = arguments\nconstraints = preconditions\noutput format = return type\n\n\n\n\nprompt = \"\"\"\nYou are a senior Python developer.\n\nTask: {task}\nContext: {context}\nConstraints: {constraints}\nOutput format: {format}\n\nReturn only the output format requested.\n\"\"\"\n\nfilled = prompt.format(\n    task=\"Write pytest tests for apply_discount(price, discount)\",\n    context=\"discount must be between 0 and 1; negative should raise ValueError\",\n    constraints=\"Use pytest; include edge cases; no extra commentary\",\n    format=\"Python code\"\n)\n\nprint(filled)\nWhy this works:\n\nclear role\nexplicit requirements\npredictable output\n\n\n\n\n\n\n\n\n\nBad prompt:\n\n‚ÄúFix this code‚Äù\n\nBetter prompt:\n\ninclude error\ninclude expected behaviour\nrequest specific output\n\n\n\n\nIf you want documentation:\n\nspecify audience\nspecify sections\nspecify formatting\n\n\n\n\n\nStrong prompts include:\n\nwhat to test\nedge cases\nexpected failures\n\n\n\n\n\n\n\n\n\nIt doesn‚Äôt.\nIf it can interpret your prompt two ways, it will choose one randomly.\n\n\n\nAI output must be validated:\n\nrun the code\nwrite tests\nreview logic\n\n\n\n\nToo much irrelevant context reduces quality.\nUse:\n\nminimal failing examples\nfocused snippets\n\n\n\n\n\n\n\n\nPrompts are specs, not questions\nContext prevents guessing\nConstraints reduce nonsense\nExamples control style\nOutput control makes responses testable\nIteration is normal ‚Äî treat it like debugging\n\n\n\n\n\n\nRewrite a bad prompt into a structured prompt.\nAdd one constraint that prevents security issues.\nAdd an output format that makes the result testable.\nAdd one example to enforce consistent style.\n\n\n\n\n\n\nline count: 507\nnumber of code blocks: 7\nnumber of micro-quotes: 8\nnumber of images referenced: 10",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#week-map-what-were-actually-learning",
    "href": "notes/notes_9.html#week-map-what-were-actually-learning",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "This week builds a practical toolkit for getting reliable work out of coding assistants.\n\n9.1 Understanding prompt engineering: why prompts fail, and what ‚Äúbetter prompts‚Äù look like\n9.2 Anatomy of a prompt: context, instructions, examples, and expected format\n9.3 Crafting the ultimate prompt: using the model to improve your own prompts\n9.4 Fundamental prompt types: zero-shot, few-shot, open-ended, constrained, structured\n9.5 Advanced prompt types: chain-of-thought, recursive prompting, context manipulation, refinement, output control\n9.6 Prompt techniques for programmers: how this becomes a daily workflow habit",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#micro-quotes-from-this-week-short-placed-where-relevant",
    "href": "notes/notes_9.html#micro-quotes-from-this-week-short-placed-where-relevant",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "‚ÄúInstead of getting generic responses, strong prompts can greatly enhance the quality, accuracy, and usefulness of AI-generated code and documents.‚Äù\n\n\n‚ÄúSome parts of prompt engineering may seem natural‚Äîlike how we learned to improve our search engine questions over time.‚Äù\n\n\n‚ÄúLet‚Äôs explore how to create better prompts to get the best results, save time, and increase productivity.‚Äù\n\n\n‚ÄúContext is the backbone of any good prompt.‚Äù\n\n\n‚ÄúProvide concrete examples to illustrate desired output.‚Äù\n\n\n‚ÄúZero-shot prompts are very basic and concise.‚Äù\n\n\n‚ÄúFew-shot prompting lets models generate from just a few examples.‚Äù\n\n\n‚ÄúThese types of prompts limit the scope of the model‚Äôs response.‚Äù",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#key-terms-bold-on-first-use",
    "href": "notes/notes_9.html#key-terms-bold-on-first-use",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "prompt: the input you send the model; in practice it‚Äôs a specification of what you want.\ncontext: background info the model needs to interpret the task (code, data shape, constraints).\nconstraints: boundaries you set (language, complexity, libraries, performance, security rules).\nfew-shot: showing a couple of examples so the model copies the pattern.\nstructured prompt: a prompt that forces the output into a predictable structure (JSON, table, sections).\noutput control: techniques that reduce randomness by restricting response shape.",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#figures-used-in-these-notes-10-max-placed-where-they-matter",
    "href": "notes/notes_9.html#figures-used-in-these-notes-10-max-placed-where-they-matter",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "These images were extracted from the Week 09 PDF and are used inline below.",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#understanding-prompt-engineering",
    "href": "notes/notes_9.html#understanding-prompt-engineering",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "Prompt engineering is not ‚Äútricking‚Äù the model. It‚Äôs about reducing ambiguity.\n\n\nCoding tasks are brittle:\n\nsmall mistakes cause crashes\nmissing constraints produce insecure or inefficient code\na ‚Äúmostly correct‚Äù solution can still be useless\n\nWhen prompts fail, it‚Äôs usually one of these reasons:\n\nUnclear task (what action do you want?)\nMissing context (what codebase? what inputs?)\nNo success criteria (how do we judge ‚Äúgood‚Äù?)\nNo output format (what should the response look like?)\nNo constraints (libraries? style? performance?)\n\n\n\n\n\nA classic failure is:\n\nPrompt: ‚ÄúFix this code‚Äù\nOutput: generic advice, or wrong assumptions\n\nInstead, you want a prompt that provides:\n\nthe exact error\nthe code\nthe expected behaviour\nwhat you already tried\nhow you want the answer returned",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#anatomy-of-a-prompt",
    "href": "notes/notes_9.html#anatomy-of-a-prompt",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "A good prompt is a communication bundle.\nThink of it as four parts:\n\nContext ‚Äî what the model needs to know\nInstructions ‚Äî what to do\nExamples ‚Äî patterns to follow\nFormat contract ‚Äî the exact structure of the response\n\n\n\n\nContext can be:\n\nthe code you‚Äôre working on\nthe data format / schema\nenvironment details (OS, Python version)\nconstraints: libraries allowed, complexity limits\n\nRule of thumb: if a human dev would ask for it before helping you, the model needs it too.\n\n\n\nGood instruction starts with a clear verb:\n\n‚Äúrefactor‚Äù\n‚Äúdebug‚Äù\n‚Äúgenerate tests‚Äù\n‚Äúexplain‚Äù\n‚Äúconvert‚Äù\n\nBad instruction is vague:\n\n‚Äúhelp me‚Äù\n‚Äúimprove this‚Äù\n\n\n\n\nFew-shot prompting is basically pattern copying.\nIf you want a specific style:\n\nshow 1‚Äì2 examples\nkeep them short\nkeep formatting consistent\n\n\n\n\nIf you don‚Äôt specify format, the model will:\n\nramble\nmix explanation and code\ninvent file structures\n\nSo you specify:\n\n‚Äúreturn JSON only‚Äù\n‚Äúreturn only Python code‚Äù\n‚Äúreturn a markdown checklist‚Äù",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#crafting-the-ultimate-prompt",
    "href": "notes/notes_9.html#crafting-the-ultimate-prompt",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "This section introduces a powerful move:\n‚úÖ Use an LLM to improve your prompt before using it for the real task.\nInstead of:\n\n‚ÄúWrite an API request tutorial‚Äù\n\nYou ask the model:\n\n‚ÄúImprove this prompt so it produces the best possible tutorial.‚Äù\n\n\n\n\nUse this when you want a high-quality response.\nraw_prompt = \"Give me instructions on how to send an HTTP request to an API and handle errors.\"\n\nrefiner = f\"\"\"\nYou are an expert prompt engineer.\n\nImprove the prompt below by:\n- adding missing context questions\n- adding constraints\n- specifying output format\n\nPROMPT TO IMPROVE:\n{raw_prompt}\n\nReturn the improved prompt only.\n\"\"\"\n\nprint(refiner)\nWhat you‚Äôre doing:\n\nturning fuzzy intent into a structured request\nforcing the model to ask missing questions",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#fundamental-prompt-types",
    "href": "notes/notes_9.html#fundamental-prompt-types",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "This week introduces several ‚Äúprompt families‚Äù.\n\n\nZero-shot = no examples.\nExample:\n\n‚ÄúWrite a Python function to validate emails.‚Äù\n\nBest when:\n\nthe task is common\nthe output shape is simple\n\nRisk:\n\nthe model guesses assumptions\n\nzero_shot = \"Write a Python function that validates an email address.\"\nprint(zero_shot)\n\n\n\nFew-shot = provide examples.\nBest when:\n\nyou care about formatting\nyou want a consistent style\n\nfew_shot = \"\"\"\nYou are a Python developer.\n\nExample 1:\ndef double(x):\n    return x * 2\n\nExample 2:\ndef square(x):\n    return x ** 2\n\nNow write a function:\ndef cube(x):\n\"\"\"\nprint(few_shot)\n\n\n\nOpen-ended = exploration.\nBest for:\n\ncomparing tools\nbrainstorming designs\ngenerating options\n\nBad for:\n\nprecise code requirements\n\n\n\n\nConstrained prompts are strict.\nExamples:\n\n‚ÄúList exactly three built-in Python data structures.‚Äù\n‚ÄúReturn only code.‚Äù\n\n\nconstrained = \"List exactly three built-in Python data structures.\"\nprint(constrained)\n\n\n\nIterative prompting = conversation loop.\nYou:\n\nask\nevaluate\nrefine\n\nThis behaves like debugging.\nprompt_v1 = \"Explain why this test is failing.\"\nprompt_v2 = \"Explain why this pytest test is failing. Use bullet points and include the fixed code.\"\nprint(prompt_v1)\nprint(prompt_v2)\n\n\n\nStructured prompts enforce a schema.\nExample:\n\n‚ÄúReturn JSON with keys: files, changes, reasons‚Äù\n\nThis is huge for engineering teams.\nstructured = \"\"\"\nReturn JSON only.\n\nSchema:\n{\"files\": [{\"path\": \"...\", \"change\": \"...\", \"reason\": \"...\"}]}\n\nTask: Propose refactor changes for a small Python script.\n\"\"\"\nprint(structured)",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#advanced-prompt-types",
    "href": "notes/notes_9.html#advanced-prompt-types",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "These techniques are about increasing reliability.\n\n\nIn this week, chain-of-thought means:\n\nencourage step-by-step reasoning\nreduce ‚Äújumping to conclusions‚Äù\n\nUse carefully: the model may sound confident even when wrong.\n\n\n\n\nRecursive prompting = prompt ‚Üí output ‚Üí prompt again.\nExample workflow:\n\ngenerate draft\ncritique draft\nrevise draft\n\nThis is similar to:\n\ncode review loops\niterative refactoring\n\n\n\n\nContext manipulation = changing what the model sees.\nExamples:\n\ninclude only the relevant file (not the whole repo)\nprovide a minimal failing example\nredact secrets and irrelevant text\n\n\n\n\nInstruction refinement = tuning wording.\nSmall changes matter:\n\n‚Äúexplain‚Äù vs ‚Äúteach‚Äù\n‚Äúbrief‚Äù vs ‚Äúdetailed‚Äù\n‚Äúcode only‚Äù vs ‚Äúcode + rationale‚Äù\n\n\n\n\n\nOutput control = forcing response format.\nThis is key when you need:\n\ndocumentation\ncommit messages\nstructured change requests",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#prompt-techniques-for-programmers",
    "href": "notes/notes_9.html#prompt-techniques-for-programmers",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "This part is where this week becomes ‚Äúreal world‚Äù.\n\n\nThink:\n\nprompt = function signature\ncontext = arguments\nconstraints = preconditions\noutput format = return type\n\n\n\n\nprompt = \"\"\"\nYou are a senior Python developer.\n\nTask: {task}\nContext: {context}\nConstraints: {constraints}\nOutput format: {format}\n\nReturn only the output format requested.\n\"\"\"\n\nfilled = prompt.format(\n    task=\"Write pytest tests for apply_discount(price, discount)\",\n    context=\"discount must be between 0 and 1; negative should raise ValueError\",\n    constraints=\"Use pytest; include edge cases; no extra commentary\",\n    format=\"Python code\"\n)\n\nprint(filled)\nWhy this works:\n\nclear role\nexplicit requirements\npredictable output",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#worked-examples-week-aligned",
    "href": "notes/notes_9.html#worked-examples-week-aligned",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "Bad prompt:\n\n‚ÄúFix this code‚Äù\n\nBetter prompt:\n\ninclude error\ninclude expected behaviour\nrequest specific output\n\n\n\n\nIf you want documentation:\n\nspecify audience\nspecify sections\nspecify formatting\n\n\n\n\n\nStrong prompts include:\n\nwhat to test\nedge cases\nexpected failures",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#pitfalls-and-anti-patterns",
    "href": "notes/notes_9.html#pitfalls-and-anti-patterns",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "It doesn‚Äôt.\nIf it can interpret your prompt two ways, it will choose one randomly.\n\n\n\nAI output must be validated:\n\nrun the code\nwrite tests\nreview logic\n\n\n\n\nToo much irrelevant context reduces quality.\nUse:\n\nminimal failing examples\nfocused snippets",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#summary-what-you-should-actually-remember",
    "href": "notes/notes_9.html#summary-what-you-should-actually-remember",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "Prompts are specs, not questions\nContext prevents guessing\nConstraints reduce nonsense\nExamples control style\nOutput control makes responses testable\nIteration is normal ‚Äî treat it like debugging",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#quick-self-check-5-minutes",
    "href": "notes/notes_9.html#quick-self-check-5-minutes",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "Rewrite a bad prompt into a structured prompt.\nAdd one constraint that prevents security issues.\nAdd an output format that makes the result testable.\nAdd one example to enforce consistent style.",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_9.html#verification-report-week-9",
    "href": "notes/notes_9.html#verification-report-week-9",
    "title": "Week 09 ‚Äî Prompt engineering",
    "section": "",
    "text": "line count: 507\nnumber of code blocks: 7\nnumber of micro-quotes: 8\nnumber of images referenced: 10",
    "crumbs": [
      "Notes",
      "Notes 09 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html",
    "href": "notes/notes_7.html",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "Micro-quotes: ‚ÄúEven seasoned developers can find UI design tough, and generative AI tools help tremendously.‚Äù ‚ÄúAI tools provide a big boost for developers who aren‚Äôt great at UI.‚Äù ‚ÄúFirst, we need to build a great prompt for this.‚Äù ‚Äú7.1 Getting our strategy from our AI tools Before we approach these tools, we should think carefully about our prompt.‚Äù ‚ÄúIf we say ‚Äúgenerate a frontend for my application‚Äù without enough information, the guidance will be too vague.‚Äù ‚ÄúThere is a time and a place for brief prompts.‚Äù\n\n\n\nThis week switches focus from backend logic to the part users actually touch: the user interface (UI). The aim is to use chat-based generative AI (especially ChatGPT) as a pair designer + pair developer to:\n\npropose a UI strategy (pages around 179‚Äì181)\nwrite structured prompts that produce targeted UI guidance and code\nconvert wireframes and flows into Flask templates + components\nadd responsive HTML/CSS elements without being a frontend expert\n\nThis week is very workflow heavy: it is less ‚Äúwhat is a transformer?‚Äù and more ‚Äúhow do we get from backend routes to a usable application screen?‚Äù\n\n\n\nWe will use these week-specific ideas repeatedly:\n\nWireframe ‚Äî a sketch (boxes + labels) of what the UI should contain and roughly how it should be laid out.\nFlask templates ‚Äî HTML files rendered by Flask (often using Jinja2), letting you combine content + layout + Python variables.\nJinja2 ‚Äî the templating language Flask uses to inject variables/loops/conditionals into HTML.\nResponsive design ‚Äî designing pages so they work on different screen sizes (mobile, tablet, desktop).\nPrompt scaffolding ‚Äî structuring a prompt into sections (objective, constraints, inputs, outputs) so the AI returns usable results.\n\n\n\n\nThese are images embedded in the PDF pages for Week 07. Not all are equally useful (some are icons/background elements), but they are extracted and downloadable.\n\n\n\n\n\n\n\n\n\nA key idea early in this week: do strategy first, then code second. The point is that you can waste a lot of time prompting for code before you have agreed what the UI is supposed to do and feel like.\n\n\n\nIf you ask for ‚Äúa frontend‚Äù without specifics, the AI returns generic boilerplate.\nStrategy prompts help you decide: pages, navigation, user flow, components, and naming.\nYou get a UI that matches your backend data model instead of fighting it later.\n\n\n\n\nThis week demonstrates writing a prompt with explicit blocks:\n\nRole (who the AI should act as)\nObjective (what the UI needs to achieve)\nContext (what already exists: backend routes, DB, etc.)\nConstraints (Flask templates, mobile-friendly, accessible)\nDeliverables (pages list, wireframe descriptions, template structure, CSS suggestions)\n\n\n‚ÄúIf we say‚Äùgenerate a frontend for my application‚Äù without enough information, the guidance will be too vague.‚Äù\n\n\n\n\n\nBelow is a ‚Äúprompt builder‚Äù approach: you store prompt sections as strings and assemble them. This makes prompts easier to iterate and reuse.\n#| label: ui-prompt-scaffold\n#| eval: false\nrole = \"Act as a professional Python developer specialising in Flask and UX.\"\nobjective = \"Design a front end for a database-driven Flask quiz application.\"\ncontext = \"Backend exists with routes for login, quizzes, and results.\"\nconstraints = \"Use Flask templates (Jinja2). Keep it responsive and accessible.\"\ndeliverables = \"Return: (1) page list, (2) nav structure, (3) template folder structure, (4) CSS starter.\"\n\nprompt = \"\n\n\".join([role, objective, context, constraints, deliverables])\nprint(prompt)\n\n\n\nThis week frames UI work as a user journey: what does the user do first, next, and last?\nA practical approach is to list screens as verbs: Log in, Choose a quiz, Answer questions, See results.\nOnce screens exist, you map navigation: where can the user go from each screen?\nThis is where AI is helpful: it can suggest missing pages (e.g., error states, empty-state screens).\n\n\n\nThis week emphasises organising your project so templates don‚Äôt become a mess.\nIn Flask, a common pattern is a templates/ folder and a static/ folder.\nTemplates contain HTML/Jinja; static contains CSS, JavaScript, and images.\nAI can draft a sensible baseline structure, but you must keep it consistent.\nIf your templates are inconsistent (different nav bars per page), your UI will feel broken.\n\n\n\nA wireframe is not pretty ‚Äî it is a constraint tool.\nYou describe boxes: header, sidebar, main content, footer.\nThis week shows using AI to turn a description into HTML skeleton.\nWhen prompting: specify grid/layout system (Flexbox, CSS grid, Bootstrap) or you‚Äôll get random HTML.\nBe explicit about which elements repeat across pages (navbar, footer).\n\n\n\nThis week‚Äôs promise: you can achieve modern UI behaviour without deep frontend knowledge.\nResponsive design usually means: a single codebase that adapts to screen width.\nPractical knobs: max-width, min-width, breakpoints, and flexible grids.\nAI is good at generating starter CSS, but you need to test in the browser.\nCommon failure: the UI looks fine on desktop but unusable on mobile.\n\n\n\nStatic HTML is easy. The challenge is making pages dynamic.\nThis week expects you to connect templates to Flask route variables.\nIn Jinja2 you often loop over data: quizzes, questions, or results.\nAI can generate the loop structure quickly, but you must match variable names to your actual Python.\nAlways confirm: what does the route pass into the template?\n\n\n\nAs your UI grows, duplication becomes the enemy.\nIn Flask/Jinja, you can create a base template and extend it.\nThis week‚Äôs workflow benefits from: a base layout, then child pages.\nAI can scaffold a base.html with blocks (content, scripts).\nPitfall: students forget to keep blocks consistent and pages break silently.\n\n\n\nWeek 07 is not a testing week, but UI work still needs verification.\nAt minimum: confirm routes render, form submissions work, and nav links don‚Äôt 404.\nAI can help generate checklists for manual testing.\nIf you have time, write a tiny smoke test using Flask‚Äôs test client.\n\n\n\nThis matches this week‚Äôs theme of converting backend data into pages.\n{% extends \"base.html\" %}\n{% block content %}\n&lt;h1&gt;Available quizzes&lt;/h1&gt;\n&lt;ul&gt;\n  {% for quiz in quizzes %}\n    &lt;li&gt;&lt;a href=\"/quiz/{{ quiz.id }}\"&gt;{{ quiz.title }}&lt;/a&gt;&lt;/li&gt;\n  {% endfor %}\n&lt;/ul&gt;\n{% endblock %}\n\n\n\nbody { max-width: 960px; margin: 0 auto; padding: 1rem; }\nnav a { margin-right: 1rem; }\n@media (max-width: 600px) {\n  body { padding: 0.5rem; }\n  nav a { display: block; margin: 0.25rem 0; }\n}\n\n\n\n\nWeek 07 uses ChatGPT to move from ‚Äúbackend works‚Äù to ‚Äúusers can actually use it‚Äù.\nThe skill is not magic HTML generation: it‚Äôs prompt scaffolding + iteration.\nWireframes + flows keep AI output grounded.\nFlask templates + Jinja2 are the bridge between Python data and the UI.\nResponsive design is essential: test on multiple screen sizes early.\n\n\n\n\n\nI can write a ‚Äústrategy prompt‚Äù before asking for UI code.\nI can list UI screens for a Flask app and map navigation between them.\nI can scaffold templates/static folders for a maintainable frontend.\nI can implement a base template + child templates with Jinja2 blocks.\nI can add basic responsive CSS and verify it in a browser.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#what-this-week-is-doing-big-picture",
    "href": "notes/notes_7.html#what-this-week-is-doing-big-picture",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "This week switches focus from backend logic to the part users actually touch: the user interface (UI). The aim is to use chat-based generative AI (especially ChatGPT) as a pair designer + pair developer to:\n\npropose a UI strategy (pages around 179‚Äì181)\nwrite structured prompts that produce targeted UI guidance and code\nconvert wireframes and flows into Flask templates + components\nadd responsive HTML/CSS elements without being a frontend expert\n\nThis week is very workflow heavy: it is less ‚Äúwhat is a transformer?‚Äù and more ‚Äúhow do we get from backend routes to a usable application screen?‚Äù",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#key-terms-bolded-the-first-time",
    "href": "notes/notes_7.html#key-terms-bolded-the-first-time",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "We will use these week-specific ideas repeatedly:\n\nWireframe ‚Äî a sketch (boxes + labels) of what the UI should contain and roughly how it should be laid out.\nFlask templates ‚Äî HTML files rendered by Flask (often using Jinja2), letting you combine content + layout + Python variables.\nJinja2 ‚Äî the templating language Flask uses to inject variables/loops/conditionals into HTML.\nResponsive design ‚Äî designing pages so they work on different screen sizes (mobile, tablet, desktop).\nPrompt scaffolding ‚Äî structuring a prompt into sections (objective, constraints, inputs, outputs) so the AI returns usable results.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#figures-extracted-from-the-pdf",
    "href": "notes/notes_7.html#figures-extracted-from-the-pdf",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "These are images embedded in the PDF pages for Week 07. Not all are equally useful (some are icons/background elements), but they are extracted and downloadable.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#getting-our-strategy-from-our-ai-tools",
    "href": "notes/notes_7.html#getting-our-strategy-from-our-ai-tools",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "A key idea early in this week: do strategy first, then code second. The point is that you can waste a lot of time prompting for code before you have agreed what the UI is supposed to do and feel like.\n\n\n\nIf you ask for ‚Äúa frontend‚Äù without specifics, the AI returns generic boilerplate.\nStrategy prompts help you decide: pages, navigation, user flow, components, and naming.\nYou get a UI that matches your backend data model instead of fighting it later.\n\n\n\n\nThis week demonstrates writing a prompt with explicit blocks:\n\nRole (who the AI should act as)\nObjective (what the UI needs to achieve)\nContext (what already exists: backend routes, DB, etc.)\nConstraints (Flask templates, mobile-friendly, accessible)\nDeliverables (pages list, wireframe descriptions, template structure, CSS suggestions)\n\n\n‚ÄúIf we say‚Äùgenerate a frontend for my application‚Äù without enough information, the guidance will be too vague.‚Äù",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#worked-example-prompting-for-a-ui-plan-quarto-runnable-code",
    "href": "notes/notes_7.html#worked-example-prompting-for-a-ui-plan-quarto-runnable-code",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "Below is a ‚Äúprompt builder‚Äù approach: you store prompt sections as strings and assemble them. This makes prompts easier to iterate and reuse.\n#| label: ui-prompt-scaffold\n#| eval: false\nrole = \"Act as a professional Python developer specialising in Flask and UX.\"\nobjective = \"Design a front end for a database-driven Flask quiz application.\"\ncontext = \"Backend exists with routes for login, quizzes, and results.\"\nconstraints = \"Use Flask templates (Jinja2). Keep it responsive and accessible.\"\ndeliverables = \"Return: (1) page list, (2) nav structure, (3) template folder structure, (4) CSS starter.\"\n\nprompt = \"\n\n\".join([role, objective, context, constraints, deliverables])\nprint(prompt)",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#from-flows-to-pages-what-screens-does-the-user-need",
    "href": "notes/notes_7.html#from-flows-to-pages-what-screens-does-the-user-need",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "This week frames UI work as a user journey: what does the user do first, next, and last?\nA practical approach is to list screens as verbs: Log in, Choose a quiz, Answer questions, See results.\nOnce screens exist, you map navigation: where can the user go from each screen?\nThis is where AI is helpful: it can suggest missing pages (e.g., error states, empty-state screens).",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#translating-requirements-into-template-structure",
    "href": "notes/notes_7.html#translating-requirements-into-template-structure",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "This week emphasises organising your project so templates don‚Äôt become a mess.\nIn Flask, a common pattern is a templates/ folder and a static/ folder.\nTemplates contain HTML/Jinja; static contains CSS, JavaScript, and images.\nAI can draft a sensible baseline structure, but you must keep it consistent.\nIf your templates are inconsistent (different nav bars per page), your UI will feel broken.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#wireframes-how-to-ask-the-ai-for-layout-help",
    "href": "notes/notes_7.html#wireframes-how-to-ask-the-ai-for-layout-help",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "A wireframe is not pretty ‚Äî it is a constraint tool.\nYou describe boxes: header, sidebar, main content, footer.\nThis week shows using AI to turn a description into HTML skeleton.\nWhen prompting: specify grid/layout system (Flexbox, CSS grid, Bootstrap) or you‚Äôll get random HTML.\nBe explicit about which elements repeat across pages (navbar, footer).",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#responsive-design-basics-what-this-week-wants-you-to-learn",
    "href": "notes/notes_7.html#responsive-design-basics-what-this-week-wants-you-to-learn",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "This week‚Äôs promise: you can achieve modern UI behaviour without deep frontend knowledge.\nResponsive design usually means: a single codebase that adapts to screen width.\nPractical knobs: max-width, min-width, breakpoints, and flexible grids.\nAI is good at generating starter CSS, but you need to test in the browser.\nCommon failure: the UI looks fine on desktop but unusable on mobile.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#jinja2-integration-ui-that-actually-connects-to-backend-data",
    "href": "notes/notes_7.html#jinja2-integration-ui-that-actually-connects-to-backend-data",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "Static HTML is easy. The challenge is making pages dynamic.\nThis week expects you to connect templates to Flask route variables.\nIn Jinja2 you often loop over data: quizzes, questions, or results.\nAI can generate the loop structure quickly, but you must match variable names to your actual Python.\nAlways confirm: what does the route pass into the template?",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#building-components-avoiding-copypaste-templates",
    "href": "notes/notes_7.html#building-components-avoiding-copypaste-templates",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "As your UI grows, duplication becomes the enemy.\nIn Flask/Jinja, you can create a base template and extend it.\nThis week‚Äôs workflow benefits from: a base layout, then child pages.\nAI can scaffold a base.html with blocks (content, scripts).\nPitfall: students forget to keep blocks consistent and pages break silently.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#testing-ui-logic-lightweight-sanity-checks",
    "href": "notes/notes_7.html#testing-ui-logic-lightweight-sanity-checks",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "Week 07 is not a testing week, but UI work still needs verification.\nAt minimum: confirm routes render, form submissions work, and nav links don‚Äôt 404.\nAI can help generate checklists for manual testing.\nIf you have time, write a tiny smoke test using Flask‚Äôs test client.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#code-example-simple-jinja2-loop-for-quiz-list",
    "href": "notes/notes_7.html#code-example-simple-jinja2-loop-for-quiz-list",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "This matches this week‚Äôs theme of converting backend data into pages.\n{% extends \"base.html\" %}\n{% block content %}\n&lt;h1&gt;Available quizzes&lt;/h1&gt;\n&lt;ul&gt;\n  {% for quiz in quizzes %}\n    &lt;li&gt;&lt;a href=\"/quiz/{{ quiz.id }}\"&gt;{{ quiz.title }}&lt;/a&gt;&lt;/li&gt;\n  {% endfor %}\n&lt;/ul&gt;\n{% endblock %}",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#code-example-minimal-responsive-css-skeleton",
    "href": "notes/notes_7.html#code-example-minimal-responsive-css-skeleton",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "body { max-width: 960px; margin: 0 auto; padding: 1rem; }\nnav a { margin-right: 1rem; }\n@media (max-width: 600px) {\n  body { padding: 0.5rem; }\n  nav a { display: block; margin: 0.25rem 0; }\n}",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#summing-up",
    "href": "notes/notes_7.html#summing-up",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "Week 07 uses ChatGPT to move from ‚Äúbackend works‚Äù to ‚Äúusers can actually use it‚Äù.\nThe skill is not magic HTML generation: it‚Äôs prompt scaffolding + iteration.\nWireframes + flows keep AI output grounded.\nFlask templates + Jinja2 are the bridge between Python data and the UI.\nResponsive design is essential: test on multiple screen sizes early.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_7.html#quick-checklist-week-skills",
    "href": "notes/notes_7.html#quick-checklist-week-skills",
    "title": "Week 07 ‚Äî Building user interfaces with ChatGPT",
    "section": "",
    "text": "I can write a ‚Äústrategy prompt‚Äù before asking for UI code.\nI can list UI screens for a Flask app and map navigation between them.\nI can scaffold templates/static folders for a maintainable frontend.\nI can implement a base template + child templates with Jinja2 blocks.\nI can add basic responsive CSS and verify it in a browser.",
    "crumbs": [
      "Notes",
      "Notes 07 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html",
    "href": "notes/notes_5.html",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "Using Blackbox AI to generate base code\nApplication development with generative AI tools\nSetting up the development environment\nDeveloping core features\nCreating the database\nConnecting to our database\nCalling our database from the frontend\nRefactoring our Questions class\nModifying our entry point (App.py)\nPulling a set of questions\nCreating a test session in the database\nCreating code for the test session\nGenerating a question set\nVerifying our test session was created\nConclusion\nFigures extracted from Week 05\n\n\n\n\nThis week builds the next slice of the HAM radio practice-exam app using Blackbox AI as your ‚Äúcode draft engine‚Äù.\nThis week‚Äôs theme is not ‚Äúlet AI build everything.‚Äù It‚Äôs co-development: you steer architecture; AI accelerates implementation.\n\nA good sentence to keep in mind from this week:\n\n‚ÄúThe goal is to demonstrate effective cooperation between human expertise and AI.‚Äù\n\n\n\n\nBlackbox AI ‚Äî a coding assistant used here to generate base implementations quickly, especially for repetitive web-app scaffolding.\nPersistent session ‚Äî a user state that survives across requests (in Flask, commonly via signed cookies + server-side data decisions).\nSeparation of concerns ‚Äî keeping responsibilities split (routes vs data access vs domain logic), so fixes don‚Äôt ripple everywhere.\nQuestion set ‚Äî a reproducible list of question IDs that defines an exam attempt (so the test can be resumed/graded).\nTest session ‚Äî a database record that tracks a user‚Äôs progress through a question set (position, answers, score).\n\n\n\n\n\n\nThe author frames AI tools as a multiplier: you still need to decide what the system is and where things live (files/modules/classes).\nA practical mental model: treat the assistant like a very fast junior developer‚Äîgreat at drafting, weak at reading your mind.\n\nFrom this week‚Äôs ‚Äúwhat this covers‚Äù list, one line basically describes the architectural bar:\n\n‚Äú¬° Maintain separation of concerns‚ÄîEven fast development benefits from clean architecture.‚Äù\n\nWhat that means in practice:\n\nYou can accept AI-generated code as a starting point, but you should refactor it into your architecture.\nWhen the AI suggests putting everything into one file, you should resist. This week is about improving structure while moving fast.\n\n\n\n\nPrompts are interfaces. If your prompt is vague, the ‚ÄúAPI response‚Äù (generated code) will be unpredictable.\nIf your prompt is too rigid, you‚Äôll spend more time fighting the output than writing code yourself.\nThe sweet spot is a well-scoped prompt that includes context + constraints + expected behaviour.\n\nTwo short reminders from this week:\n\n‚ÄúThis prompt will tell Blackbox what we want it to do and give specificity.‚Äù\n‚ÄúTreat the comment as a prompt.‚Äù\n\n\n\n\n\n\nThis week assumes you already have a working Flask project from earlier weeks.\nYou‚Äôre now adding state: question sets and test sessions need to persist across pages and across time.\n\nMinimum local setup (student-friendly):\n\nCreate a virtual environment and install Flask.\nDecide where your database file lives (for a student project, a local SQLite file is fine).\nEnsure your project has a clear module boundary between routes and data access.\n\nA minimal runnable Flask skeleton:\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef index():\n    return {\"status\": \"ok\"}\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\n\n\n\nThis week‚Äôs development plan is incremental: add the database layer, wire it to the UI, then improve architecture.\nThis is where ‚Äúseparation of concerns‚Äù stops being an academic phrase and becomes a survival tool.\n\n\n\nThe author‚Äôs first instinct is direct:\n\n‚ÄúI start with the database.‚Äù\n\nWhy start here?\n\nWeb apps are stateful experiences built on stateless HTTP. If you don‚Äôt persist state, you‚Äôll rebuild it on every request (painful).\nA database is the simplest shared memory for user progress (even if you later swap SQLite for Postgres).\n\nAnother sentence in this week explains the concrete requirement:\n\n‚ÄúNow I just need to create a table that will store these IDs and some session data for our students.‚Äù\n\n\n\n\nquestion_sets: store a reproducible list of question IDs for an exam attempt.\ntest_sessions: store progress through a question set (index, answers, score).\n\nRunnable SQLite setup (creates tables):\nimport sqlite3\n\nDB_PATH = \"week05_demo.sqlite\"\n\nschema_sql = \"\"\"\nCREATE TABLE IF NOT EXISTS question_sets (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n  question_ids TEXT NOT NULL\n);\n\nCREATE TABLE IF NOT EXISTS test_sessions (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  question_set_id INTEGER NOT NULL,\n  current_index INTEGER DEFAULT 0,\n  score INTEGER DEFAULT 0,\n  created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n  FOREIGN KEY(question_set_id) REFERENCES question_sets(id)\n);\n\"\"\"\n\nwith sqlite3.connect(DB_PATH) as conn:\n    conn.executescript(schema_sql)\n\nprint(\"OK: tables created in\", DB_PATH)\n\n\n\n\nThis week uses SQLite for simplicity. The key engineering decision is where to put connection logic.\n\nGood: db.py (or database.py) owns connection creation, and other modules import helper functions.\nRisky: every route creates its own SQL strings and connections inline (hard to test, hard to debug).\n\nA minimal ‚Äúdb helper‚Äù module pattern:\n# db.py\nimport sqlite3\nfrom pathlib import Path\n\nDB_PATH = Path(\"week05_demo.sqlite\")\n\ndef get_conn():\n    conn = sqlite3.connect(DB_PATH)\n    conn.row_factory = sqlite3.Row\n    return conn\n\n\n\n\nThe UI needs to request ‚Äúthe next question‚Äù and submit ‚Äúan answer‚Äù.\nThe backend needs to read/write the current test session (progress, scoring).\n\nA minimal pattern: use routes as thin controllers; keep SQL out of the route when possible.\n\n\n\n\nAs features grow, a ‚ÄúQuestions‚Äù class tends to become a dumping ground.\nRefactoring here is about separating: (1) question bank access, (2) question selection, (3) rendering/formatting.\n\n\n\n\n\nEntry points tend to accumulate imports, global objects, and configuration.\nThis week nudges you toward clarity: keep initialization in one place, but push functionality into modules.\n\n\n\n\n\nA question set is your ‚Äúfrozen exam‚Äù. Once created, you should be able to reproduce it exactly.\nThis prevents the classic bug where refreshing the page gives a different test.\n\n\n\n\n\nA test session is a record that points to a question set + stores progress.\nThis is also where session cookies + DB state meet: cookie identifies the browser; DB stores the durable progress.\n\nA student-friendly session cookie setup in Flask:\nfrom flask import Flask, session\n\napp = Flask(__name__)\napp.secret_key = \"dev-only-change-me\"  # in real apps, use env vars\n\n@app.get(\"/set\")\ndef set_value():\n    session[\"user_id\"] = 123\n    return {\"ok\": True}\n\n@app.get(\"/get\")\ndef get_value():\n    return {\"user_id\": session.get(\"user_id\")}\n\n\n\n\nThis week‚Äôs practical point: let AI draft the route handlers, but you must ensure they call your data layer cleanly.\nKeep the contract obvious: create_session(question_set_id) -&gt; session_id and get_session(session_id) -&gt; record.\n\n\n\n\n\nGenerating here means: selecting question IDs (not generating new questions).\nYou want deterministic reproducibility: store the IDs you chose.\n\n\n\n\n\nVerification is not optional. AI makes it easy to write code that ‚Äúlooks right‚Äù but fails at runtime.\nCheck: DB rows exist, foreign keys match, and the UI can resume where it left off.\n\nA tiny verification query (runnable):\nimport sqlite3\n\nDB_PATH = \"week05_demo.sqlite\"\nwith sqlite3.connect(DB_PATH) as conn:\n    qs = conn.execute(\"SELECT COUNT(*) FROM question_sets\").fetchone()[0]\n    ts = conn.execute(\"SELECT COUNT(*) FROM test_sessions\").fetchone()[0]\n\nprint({\"question_sets\": qs, \"test_sessions\": ts})\n\n\n\n\n\nThis week is a case study in using Blackbox AI for speed while still enforcing architecture.\nThe most important engineering idea is separation of concerns: routes orchestrate, domain logic decides, data layer persists.\nThe product outcome is a test experience that can persist progress across pages: question sets + test sessions.\n\n\n\n\nThe following images were extracted from the Week 05 materials.\n                                                                                               \n\n\n\n\nMixing layers: SQL and HTML string-building inside routes leads to fragile code.\nHidden state: relying only on cookies without DB persistence breaks resuming tests.\nUnverified assumptions: AI may invent library functions or routes that do not exist.\nOver-trusting generated code: always run, print, and inspect DB rows early.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#using-blackbox-ai-to-generate-base-code",
    "href": "notes/notes_5.html#using-blackbox-ai-to-generate-base-code",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "This week builds the next slice of the HAM radio practice-exam app using Blackbox AI as your ‚Äúcode draft engine‚Äù.\nThis week‚Äôs theme is not ‚Äúlet AI build everything.‚Äù It‚Äôs co-development: you steer architecture; AI accelerates implementation.\n\nA good sentence to keep in mind from this week:\n\n‚ÄúThe goal is to demonstrate effective cooperation between human expertise and AI.‚Äù\n\n\n\n\nBlackbox AI ‚Äî a coding assistant used here to generate base implementations quickly, especially for repetitive web-app scaffolding.\nPersistent session ‚Äî a user state that survives across requests (in Flask, commonly via signed cookies + server-side data decisions).\nSeparation of concerns ‚Äî keeping responsibilities split (routes vs data access vs domain logic), so fixes don‚Äôt ripple everywhere.\nQuestion set ‚Äî a reproducible list of question IDs that defines an exam attempt (so the test can be resumed/graded).\nTest session ‚Äî a database record that tracks a user‚Äôs progress through a question set (position, answers, score).",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#application-development-with-generative-ai-tools",
    "href": "notes/notes_5.html#application-development-with-generative-ai-tools",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "The author frames AI tools as a multiplier: you still need to decide what the system is and where things live (files/modules/classes).\nA practical mental model: treat the assistant like a very fast junior developer‚Äîgreat at drafting, weak at reading your mind.\n\nFrom this week‚Äôs ‚Äúwhat this covers‚Äù list, one line basically describes the architectural bar:\n\n‚Äú¬° Maintain separation of concerns‚ÄîEven fast development benefits from clean architecture.‚Äù\n\nWhat that means in practice:\n\nYou can accept AI-generated code as a starting point, but you should refactor it into your architecture.\nWhen the AI suggests putting everything into one file, you should resist. This week is about improving structure while moving fast.\n\n\n\n\nPrompts are interfaces. If your prompt is vague, the ‚ÄúAPI response‚Äù (generated code) will be unpredictable.\nIf your prompt is too rigid, you‚Äôll spend more time fighting the output than writing code yourself.\nThe sweet spot is a well-scoped prompt that includes context + constraints + expected behaviour.\n\nTwo short reminders from this week:\n\n‚ÄúThis prompt will tell Blackbox what we want it to do and give specificity.‚Äù\n‚ÄúTreat the comment as a prompt.‚Äù",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#setting-up-the-development-environment",
    "href": "notes/notes_5.html#setting-up-the-development-environment",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "This week assumes you already have a working Flask project from earlier weeks.\nYou‚Äôre now adding state: question sets and test sessions need to persist across pages and across time.\n\nMinimum local setup (student-friendly):\n\nCreate a virtual environment and install Flask.\nDecide where your database file lives (for a student project, a local SQLite file is fine).\nEnsure your project has a clear module boundary between routes and data access.\n\nA minimal runnable Flask skeleton:\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef index():\n    return {\"status\": \"ok\"}\n\nif __name__ == \"__main__\":\n    app.run(debug=True)",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#developing-core-features",
    "href": "notes/notes_5.html#developing-core-features",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "This week‚Äôs development plan is incremental: add the database layer, wire it to the UI, then improve architecture.\nThis is where ‚Äúseparation of concerns‚Äù stops being an academic phrase and becomes a survival tool.\n\n\n\nThe author‚Äôs first instinct is direct:\n\n‚ÄúI start with the database.‚Äù\n\nWhy start here?\n\nWeb apps are stateful experiences built on stateless HTTP. If you don‚Äôt persist state, you‚Äôll rebuild it on every request (painful).\nA database is the simplest shared memory for user progress (even if you later swap SQLite for Postgres).\n\nAnother sentence in this week explains the concrete requirement:\n\n‚ÄúNow I just need to create a table that will store these IDs and some session data for our students.‚Äù\n\n\n\n\nquestion_sets: store a reproducible list of question IDs for an exam attempt.\ntest_sessions: store progress through a question set (index, answers, score).\n\nRunnable SQLite setup (creates tables):\nimport sqlite3\n\nDB_PATH = \"week05_demo.sqlite\"\n\nschema_sql = \"\"\"\nCREATE TABLE IF NOT EXISTS question_sets (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n  question_ids TEXT NOT NULL\n);\n\nCREATE TABLE IF NOT EXISTS test_sessions (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  question_set_id INTEGER NOT NULL,\n  current_index INTEGER DEFAULT 0,\n  score INTEGER DEFAULT 0,\n  created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n  FOREIGN KEY(question_set_id) REFERENCES question_sets(id)\n);\n\"\"\"\n\nwith sqlite3.connect(DB_PATH) as conn:\n    conn.executescript(schema_sql)\n\nprint(\"OK: tables created in\", DB_PATH)\n\n\n\n\nThis week uses SQLite for simplicity. The key engineering decision is where to put connection logic.\n\nGood: db.py (or database.py) owns connection creation, and other modules import helper functions.\nRisky: every route creates its own SQL strings and connections inline (hard to test, hard to debug).\n\nA minimal ‚Äúdb helper‚Äù module pattern:\n# db.py\nimport sqlite3\nfrom pathlib import Path\n\nDB_PATH = Path(\"week05_demo.sqlite\")\n\ndef get_conn():\n    conn = sqlite3.connect(DB_PATH)\n    conn.row_factory = sqlite3.Row\n    return conn\n\n\n\n\nThe UI needs to request ‚Äúthe next question‚Äù and submit ‚Äúan answer‚Äù.\nThe backend needs to read/write the current test session (progress, scoring).\n\nA minimal pattern: use routes as thin controllers; keep SQL out of the route when possible.\n\n\n\n\nAs features grow, a ‚ÄúQuestions‚Äù class tends to become a dumping ground.\nRefactoring here is about separating: (1) question bank access, (2) question selection, (3) rendering/formatting.\n\n\n\n\n\nEntry points tend to accumulate imports, global objects, and configuration.\nThis week nudges you toward clarity: keep initialization in one place, but push functionality into modules.\n\n\n\n\n\nA question set is your ‚Äúfrozen exam‚Äù. Once created, you should be able to reproduce it exactly.\nThis prevents the classic bug where refreshing the page gives a different test.\n\n\n\n\n\nA test session is a record that points to a question set + stores progress.\nThis is also where session cookies + DB state meet: cookie identifies the browser; DB stores the durable progress.\n\nA student-friendly session cookie setup in Flask:\nfrom flask import Flask, session\n\napp = Flask(__name__)\napp.secret_key = \"dev-only-change-me\"  # in real apps, use env vars\n\n@app.get(\"/set\")\ndef set_value():\n    session[\"user_id\"] = 123\n    return {\"ok\": True}\n\n@app.get(\"/get\")\ndef get_value():\n    return {\"user_id\": session.get(\"user_id\")}\n\n\n\n\nThis week‚Äôs practical point: let AI draft the route handlers, but you must ensure they call your data layer cleanly.\nKeep the contract obvious: create_session(question_set_id) -&gt; session_id and get_session(session_id) -&gt; record.\n\n\n\n\n\nGenerating here means: selecting question IDs (not generating new questions).\nYou want deterministic reproducibility: store the IDs you chose.\n\n\n\n\n\nVerification is not optional. AI makes it easy to write code that ‚Äúlooks right‚Äù but fails at runtime.\nCheck: DB rows exist, foreign keys match, and the UI can resume where it left off.\n\nA tiny verification query (runnable):\nimport sqlite3\n\nDB_PATH = \"week05_demo.sqlite\"\nwith sqlite3.connect(DB_PATH) as conn:\n    qs = conn.execute(\"SELECT COUNT(*) FROM question_sets\").fetchone()[0]\n    ts = conn.execute(\"SELECT COUNT(*) FROM test_sessions\").fetchone()[0]\n\nprint({\"question_sets\": qs, \"test_sessions\": ts})",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#conclusion",
    "href": "notes/notes_5.html#conclusion",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "This week is a case study in using Blackbox AI for speed while still enforcing architecture.\nThe most important engineering idea is separation of concerns: routes orchestrate, domain logic decides, data layer persists.\nThe product outcome is a test experience that can persist progress across pages: question sets + test sessions.",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#figures-extracted-from-week-05",
    "href": "notes/notes_5.html#figures-extracted-from-week-05",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "The following images were extracted from the Week 05 materials.",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_5.html#extra-notes-common-failure-modes",
    "href": "notes/notes_5.html#extra-notes-common-failure-modes",
    "title": "Week 05 ‚Äî Application development with Blackbox AI",
    "section": "",
    "text": "Mixing layers: SQL and HTML string-building inside routes leads to fragile code.\nHidden state: relying only on cookies without DB persistence breaks resuming tests.\nUnverified assumptions: AI may invent library functions or routes that do not exist.\nOver-trusting generated code: always run, print, and inspect DB rows early.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.\nPractice: write one small prompt per function (create session, load session, save answer) and test each independently.",
    "crumbs": [
      "Notes",
      "Notes 05 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html",
    "href": "notes/notes_3.html",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Week focus: turning vague intent into reliable, testable prompt instructions.\n\n\n\n\n1. Why prompting is a design skill\n2. Prompt anatomy\n3. From vague to specific\n4. Constraints, rubrics, and acceptance tests\n5. Few-shot examples\n6. Output formats that don‚Äôt break\n7. Iteration loop\n8. Failure modes + debugging prompts\n9. Prompt patterns you can reuse\n10. Summary\n\n\n\n\n \n\n\n\n\nPrompting is not ‚Äúasking nicely‚Äù. In the real world, you use prompts to specify behaviour under constraints:\n\nyou want repeatable outputs\nyou want outputs that are checkable\nyou want the model to use the right information\nyou want it to behave sensibly when information is missing\n\nA useful mindset: a prompt is closer to a function signature than a conversation.\n\n\n\n‚ÄúA prompt is a program in natural language.‚Äù\n\n\n\n\nExplain the task (what success looks like)\nConstrain the output (how the response must be shaped)\n\n\n\n\n\n\n\nA practical prompt usually contains these parts (not always in this order):\n\nRole: ‚ÄúYou are a ‚Ä¶‚Äù (useful when behaviour matters)\nGoal: what to produce\nContext: what the model should know or assume\nInputs: what you are providing (data, text, code, constraints)\nRules: explicit do/don‚Äôt constraints\nOutput format: JSON, Markdown, table, bullet list, etc\nQuality bar: rubric / checklist / tests\n\n\n\n\nRole prompting: framing the model‚Äôs perspective and responsibilities.\nConstraints: explicit limits that prevent unwanted behaviour or formats.\nFew-shot prompting: teaching by giving examples of desired input‚Üíoutput.\nRubric: a checklist the model should satisfy.\nOutput schema: a formal structure the output must follow (e.g., JSON).\n\n\n\n\nBad (vague):\nWrite a good explanation of SQL joins.\nBetter (engineered):\nYou are a first-year teaching assistant.\nExplain SQL joins to beginners using:\n- exactly 3 join types (INNER, LEFT, FULL)\n- one simple table example\n- one common mistake per join type\nOutput as markdown with headings and a final summary.\n\n\n\n\n\nMost student prompts fail because they skip specification. You can convert vague intent into a usable prompt by answering:\n\nWhat is the deliverable? (an explanation / a plan / code / critique)\nWho is the audience?\nWhat constraints exist? (length, style, tools, time)\nWhat does success look like? (rubric / checklist)\nWhat should never happen? (anti-requirements)\n\n\n\n\n‚ÄúBe specific about what you want and what you don‚Äôt want.‚Äù\n\n\n\n\nTake the vague prompt:\nHelp me debug my Python.\nRewrite it into something testable:\nYou are a Python tutor. I will paste code and an error message.\n1) Explain what the error means in plain language\n2) Identify the exact line likely causing it\n3) Provide a fixed version of the code\n4) Add one print/debug statement that proves the fix works\nKeep changes minimal.\n\n\n\n\n\nIf you want outputs you can trust, you need a quality gate. This can be:\n\nA short rubric (‚Äúmust include X, avoid Y‚Äù)\nAn acceptance test (unit tests, schema validation)\nA format requirement (JSON schema, markdown headings)\n\n\n\n\n‚ÄúMake the output easy to verify.‚Äù\n\n\n\n\n# A tiny ‚Äúacceptance test‚Äù for AI-written text outputs\ndef contains_required_phrases(text: str, required: list[str]) -&gt; bool:\n    return all(phrase.lower() in text.lower() for phrase in required)\n\nsample = \"This answer covers INNER JOIN, LEFT JOIN and FULL JOIN.\"\nprint(contains_required_phrases(sample, [\"INNER JOIN\", \"LEFT JOIN\", \"FULL JOIN\"]))\n\n\n\n\n\nFew-shot prompting is when you show the model examples of the behaviour you want. This is especially powerful when you want consistent style or formatting.\n\n\n\nWhen outputs must match a ‚Äúhouse style‚Äù\nWhen the task is ambiguous (many valid interpretations)\nWhen you care about edge-cases\n\n\n\n\n\n‚ÄúExamples reduce ambiguity.‚Äù\n\n\n\n\nTask: Convert short notes into a structured study card.\nFormat:\n- Term\n- Definition\n- Example\n- Common mistake\n\nExample input:\n\"SQL LEFT JOIN keeps all rows from the left table\"\nExample output:\nTerm: LEFT JOIN\nDefinition: Returns all rows from left table plus matching right rows.\nExample: ...\nCommon mistake: Confusing with INNER JOIN.\n\nNow do the same for: \"FULL JOIN keeps all rows from both\"\n\n\n\n\n\nIn real workflows, AI output often becomes input to something else: - a script - a web app - a report - a database\nThat means formatting matters. If you don‚Äôt force structure, you‚Äôll get ‚Äúpretty‚Äù output that is unusable.\n\n\n\n‚ÄúAsk for the output format you need.‚Äù\n\n\n\n\nimport json\n\nraw = \"\"\"{\n  \"title\": \"Study card\",\n  \"points\": [\"one\", \"two\"]\n}\"\"\"\ndata = json.loads(raw)\nprint(data[\"title\"], data[\"points\"])\n\n\n\n\n\nPrompting is iterative. A common loop is:\n\nDraft prompt\nRun it on a few cases\nDiagnose failure modes\nAdd constraints / examples\nRe-run\n\n\n\n\n‚ÄúIterate on prompts like you iterate on code.‚Äù\n\n\n\n\nPROMPT_V1 = \"Summarise this article.\"\nPROMPT_V2 = \"Summarise this article in 5 bullets for first-year students.\"\nPROMPT_V3 = PROMPT_V2 + \" Include one limitation and one question.\"\n\nfor i, p in enumerate([PROMPT_V1, PROMPT_V2, PROMPT_V3], start=1):\n    print(f\"v{i}: {p}\")\n\n\n\n\n\nCommon failure modes in early prompting:\n\nOverly broad instructions ‚Üí generic output\nMissing constraints ‚Üí wrong format, wrong length\nUnclear audience ‚Üí tone mismatch\nNo examples ‚Üí inconsistent style\nNo rubric ‚Üí ‚Äúsounds good‚Äù but incomplete\n\n\n\nYou produced an answer that failed these requirements:\n- (list failures)\nExplain why it failed and produce a corrected version.\nThen provide a checklist to prevent the same failure next time.\n\n\n\n\n\nBelow are reusable patterns you can copy into real work.\n\n\nDo the task. Then verify your output against this checklist:\n- ...\nIf anything fails, fix and re-check.\n\n\n\nExplain this concept simply. Then ask me 5 questions, increasing difficulty.\nGive answers at the end.\n\n\n\nGive 3 options. For each, include: benefits, drawbacks, best use-case.\nFinish with a recommendation for a beginner.\n\n\n\n\n\n\nPrompting is best treated as specification and design.\nGood prompts include constraints, a format, and a quality gate.\nFew-shot examples reduce ambiguity and increase consistency.\nIteration is normal: test, debug, refine.\nOutputs should be structured so they can be verified and reused.\n\n\n\n\n\n\n\n\nWe begin with an intent that a human understands but a model can misinterpret.\nExample intent: Make this explanation better.\nThe phrase better is underspecified: better for who, in what way, with what constraints?\nIf you leave this vague, the model may change style, length, or even meaning.\n\n\n\n\n\nDecide who the output is for (audience).\nFor week 3, our audience is first-year university students.\nPurpose might be: quick revision notes, lecture handout, or tutorial support.\nAudience + purpose affect tone, vocabulary, and example choice.\n\n\n\n\n\nConstraints prevent ‚Äòcreative drift‚Äô.\nCommon constraints: word count, formatting, required sections, no jargon.\nConstraints also help the model prioritise: if space is limited, it must focus.\n\n\n\n\n\nA rubric is a checklist your output should pass.\nRubrics are powerful because they are explicit, testable, and reusable.\nExample rubric: must include 1 analogy, 1 code example, 3 bullet takeaways.\n\n\n\n\n\nIf the output must feed another tool, specify a strict format.\nExamples: JSON, Markdown headings, CSV, YAML front matter.\nIn Quarto notes, Markdown + headings is usually enough.\n\n\n\n\n\nIf you care about style, show the model the style.\nOne example pair can dramatically increase consistency.\nToo many examples can bloat the prompt, so start small.\n\n\n\n\n\nWhen output fails, don‚Äôt just re-run: diagnose.\nAsk: which instruction was ignored? Was it ambiguous? Was it missing?\nThen modify the prompt so the failure becomes impossible or unlikely.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#contents",
    "href": "notes/notes_3.html#contents",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "1. Why prompting is a design skill\n2. Prompt anatomy\n3. From vague to specific\n4. Constraints, rubrics, and acceptance tests\n5. Few-shot examples\n6. Output formats that don‚Äôt break\n7. Iteration loop\n8. Failure modes + debugging prompts\n9. Prompt patterns you can reuse\n10. Summary",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#why-prompting-is-a-design-skill",
    "href": "notes/notes_3.html#why-prompting-is-a-design-skill",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Prompting is not ‚Äúasking nicely‚Äù. In the real world, you use prompts to specify behaviour under constraints:\n\nyou want repeatable outputs\nyou want outputs that are checkable\nyou want the model to use the right information\nyou want it to behave sensibly when information is missing\n\nA useful mindset: a prompt is closer to a function signature than a conversation.\n\n\n\n‚ÄúA prompt is a program in natural language.‚Äù\n\n\n\n\nExplain the task (what success looks like)\nConstrain the output (how the response must be shaped)",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#prompt-anatomy",
    "href": "notes/notes_3.html#prompt-anatomy",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "A practical prompt usually contains these parts (not always in this order):\n\nRole: ‚ÄúYou are a ‚Ä¶‚Äù (useful when behaviour matters)\nGoal: what to produce\nContext: what the model should know or assume\nInputs: what you are providing (data, text, code, constraints)\nRules: explicit do/don‚Äôt constraints\nOutput format: JSON, Markdown, table, bullet list, etc\nQuality bar: rubric / checklist / tests\n\n\n\n\nRole prompting: framing the model‚Äôs perspective and responsibilities.\nConstraints: explicit limits that prevent unwanted behaviour or formats.\nFew-shot prompting: teaching by giving examples of desired input‚Üíoutput.\nRubric: a checklist the model should satisfy.\nOutput schema: a formal structure the output must follow (e.g., JSON).\n\n\n\n\nBad (vague):\nWrite a good explanation of SQL joins.\nBetter (engineered):\nYou are a first-year teaching assistant.\nExplain SQL joins to beginners using:\n- exactly 3 join types (INNER, LEFT, FULL)\n- one simple table example\n- one common mistake per join type\nOutput as markdown with headings and a final summary.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#from-vague-to-specific",
    "href": "notes/notes_3.html#from-vague-to-specific",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Most student prompts fail because they skip specification. You can convert vague intent into a usable prompt by answering:\n\nWhat is the deliverable? (an explanation / a plan / code / critique)\nWho is the audience?\nWhat constraints exist? (length, style, tools, time)\nWhat does success look like? (rubric / checklist)\nWhat should never happen? (anti-requirements)\n\n\n\n\n‚ÄúBe specific about what you want and what you don‚Äôt want.‚Äù\n\n\n\n\nTake the vague prompt:\nHelp me debug my Python.\nRewrite it into something testable:\nYou are a Python tutor. I will paste code and an error message.\n1) Explain what the error means in plain language\n2) Identify the exact line likely causing it\n3) Provide a fixed version of the code\n4) Add one print/debug statement that proves the fix works\nKeep changes minimal.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#constraints-rubrics-and-acceptance-tests",
    "href": "notes/notes_3.html#constraints-rubrics-and-acceptance-tests",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "If you want outputs you can trust, you need a quality gate. This can be:\n\nA short rubric (‚Äúmust include X, avoid Y‚Äù)\nAn acceptance test (unit tests, schema validation)\nA format requirement (JSON schema, markdown headings)\n\n\n\n\n‚ÄúMake the output easy to verify.‚Äù\n\n\n\n\n# A tiny ‚Äúacceptance test‚Äù for AI-written text outputs\ndef contains_required_phrases(text: str, required: list[str]) -&gt; bool:\n    return all(phrase.lower() in text.lower() for phrase in required)\n\nsample = \"This answer covers INNER JOIN, LEFT JOIN and FULL JOIN.\"\nprint(contains_required_phrases(sample, [\"INNER JOIN\", \"LEFT JOIN\", \"FULL JOIN\"]))",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#few-shot-examples",
    "href": "notes/notes_3.html#few-shot-examples",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Few-shot prompting is when you show the model examples of the behaviour you want. This is especially powerful when you want consistent style or formatting.\n\n\n\nWhen outputs must match a ‚Äúhouse style‚Äù\nWhen the task is ambiguous (many valid interpretations)\nWhen you care about edge-cases\n\n\n\n\n\n‚ÄúExamples reduce ambiguity.‚Äù\n\n\n\n\nTask: Convert short notes into a structured study card.\nFormat:\n- Term\n- Definition\n- Example\n- Common mistake\n\nExample input:\n\"SQL LEFT JOIN keeps all rows from the left table\"\nExample output:\nTerm: LEFT JOIN\nDefinition: Returns all rows from left table plus matching right rows.\nExample: ...\nCommon mistake: Confusing with INNER JOIN.\n\nNow do the same for: \"FULL JOIN keeps all rows from both\"",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#output-formats-that-dont-break",
    "href": "notes/notes_3.html#output-formats-that-dont-break",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "In real workflows, AI output often becomes input to something else: - a script - a web app - a report - a database\nThat means formatting matters. If you don‚Äôt force structure, you‚Äôll get ‚Äúpretty‚Äù output that is unusable.\n\n\n\n‚ÄúAsk for the output format you need.‚Äù\n\n\n\n\nimport json\n\nraw = \"\"\"{\n  \"title\": \"Study card\",\n  \"points\": [\"one\", \"two\"]\n}\"\"\"\ndata = json.loads(raw)\nprint(data[\"title\"], data[\"points\"])",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#iteration-loop",
    "href": "notes/notes_3.html#iteration-loop",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Prompting is iterative. A common loop is:\n\nDraft prompt\nRun it on a few cases\nDiagnose failure modes\nAdd constraints / examples\nRe-run\n\n\n\n\n‚ÄúIterate on prompts like you iterate on code.‚Äù\n\n\n\n\nPROMPT_V1 = \"Summarise this article.\"\nPROMPT_V2 = \"Summarise this article in 5 bullets for first-year students.\"\nPROMPT_V3 = PROMPT_V2 + \" Include one limitation and one question.\"\n\nfor i, p in enumerate([PROMPT_V1, PROMPT_V2, PROMPT_V3], start=1):\n    print(f\"v{i}: {p}\")",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#failure-modes-debugging-prompts",
    "href": "notes/notes_3.html#failure-modes-debugging-prompts",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Common failure modes in early prompting:\n\nOverly broad instructions ‚Üí generic output\nMissing constraints ‚Üí wrong format, wrong length\nUnclear audience ‚Üí tone mismatch\nNo examples ‚Üí inconsistent style\nNo rubric ‚Üí ‚Äúsounds good‚Äù but incomplete\n\n\n\nYou produced an answer that failed these requirements:\n- (list failures)\nExplain why it failed and produce a corrected version.\nThen provide a checklist to prevent the same failure next time.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#prompt-patterns-you-can-reuse",
    "href": "notes/notes_3.html#prompt-patterns-you-can-reuse",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Below are reusable patterns you can copy into real work.\n\n\nDo the task. Then verify your output against this checklist:\n- ...\nIf anything fails, fix and re-check.\n\n\n\nExplain this concept simply. Then ask me 5 questions, increasing difficulty.\nGive answers at the end.\n\n\n\nGive 3 options. For each, include: benefits, drawbacks, best use-case.\nFinish with a recommendation for a beginner.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#summary",
    "href": "notes/notes_3.html#summary",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "Prompting is best treated as specification and design.\nGood prompts include constraints, a format, and a quality gate.\nFew-shot examples reduce ambiguity and increase consistency.\nIteration is normal: test, debug, refine.\nOutputs should be structured so they can be verified and reused.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_3.html#appendix-a-worked-walkthrough-building-a-prompt-step-by-step",
    "href": "notes/notes_3.html#appendix-a-worked-walkthrough-building-a-prompt-step-by-step",
    "title": "Week 03 ‚Äî Designing Your First Prompt",
    "section": "",
    "text": "We begin with an intent that a human understands but a model can misinterpret.\nExample intent: Make this explanation better.\nThe phrase better is underspecified: better for who, in what way, with what constraints?\nIf you leave this vague, the model may change style, length, or even meaning.\n\n\n\n\n\nDecide who the output is for (audience).\nFor week 3, our audience is first-year university students.\nPurpose might be: quick revision notes, lecture handout, or tutorial support.\nAudience + purpose affect tone, vocabulary, and example choice.\n\n\n\n\n\nConstraints prevent ‚Äòcreative drift‚Äô.\nCommon constraints: word count, formatting, required sections, no jargon.\nConstraints also help the model prioritise: if space is limited, it must focus.\n\n\n\n\n\nA rubric is a checklist your output should pass.\nRubrics are powerful because they are explicit, testable, and reusable.\nExample rubric: must include 1 analogy, 1 code example, 3 bullet takeaways.\n\n\n\n\n\nIf the output must feed another tool, specify a strict format.\nExamples: JSON, Markdown headings, CSV, YAML front matter.\nIn Quarto notes, Markdown + headings is usually enough.\n\n\n\n\n\nIf you care about style, show the model the style.\nOne example pair can dramatically increase consistency.\nToo many examples can bloat the prompt, so start small.\n\n\n\n\n\nWhen output fails, don‚Äôt just re-run: diagnose.\nAsk: which instruction was ignored? Was it ambiguous? Was it missing?\nThen modify the prompt so the failure becomes impossible or unlikely.",
    "crumbs": [
      "Notes",
      "Notes 03 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html",
    "href": "notes/notes_10.html",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúVibe coding‚Äù is a workflow, not a magic trick.\n\nThese notes follow Week 10 and show how Cursor changes the way you write software, why it works, and the pitfalls that catch beginners.\n\n\nWeek 10 moves from ‚Äúcoding with AI as a helper‚Äù to a conversational programming workflow where your editor + model become a co-author.\nYou‚Äôll see:\n\nHow Cursor differs from ‚Äújust ChatGPT in a browser‚Äù\nWhat vibe coding means in practice (and what it does not mean)\nHow to prompt for a whole working program and then iterate safely\nHow to use Cursor‚Äôs modes (chat, edit, autocomplete) deliberately\nHow to keep control: debugging, tests, and small edits instead of chaos\n\nReal-world framing: this is the difference between ‚Äúasking AI questions‚Äù and shipping software with AI in the loop.\n\n\n\n\n‚ÄúAt one end of the spectrum‚Ä¶‚Äù\n\nThe phrase ‚Äúvibe coding‚Äù is basically: you steer by intent and feedback, not by writing every line from scratch.\n\n\n\nYou start by describing behavior (what the program should do) rather than implementation (how it does it).\nThe AI proposes code.\nYou run it, observe, and then refine the prompt (or apply edits) until it behaves.\n\nThat feedback loop is the ‚Äúvibe‚Äù.\n\n\n\n\nLLMs are strong at first drafts and pattern-matching.\nEditors like Cursor provide context (your whole repo), so the model can be more precise.\nYou can move faster when you accept that drafts are disposable.\n\n\n\n\n\nNot ‚Äúno thinking‚Äù.\nNot ‚Äútrust the model blindly‚Äù.\nNot ‚Äúskip debugging‚Äù.\n\nIf you do that, you get brittle code and mysterious failures.\n\n\n\n\nOver-scoping: asking for ‚Äúbuild the whole app‚Äù without constraints.\nUnder-specifying: vague goals produce vague programs.\nContext leakage: if your project contains confusing files, the model can copy the wrong patterns.\n\n\n\n\n\n\nUse this figure to remember the mental model:\n\nDescribe intent\n\nGenerate a draft\n\nRun it\n\nDebug + refine\n\nRepeat until correct\n\n\n\n\n\n‚ÄúWhat is Cursor, and why is it different?‚Äù\n\nCursor is an IDE designed to make AI part of the editing loop. The big difference is context + actions:\n\nIt sees your open files, selections, and (optionally) the entire project.\nIt can apply edits directly (not just suggest them).\nIt supports modes that match real programming tasks.\n\nIn other words, it‚Äôs not ‚Äúchatting about code‚Äù ‚Äî it‚Äôs editing code with chat.\n\n\n\nYou can ask for changes in-place (e.g., ‚Äúrefactor this function‚Äù).\nYou can request multi-file modifications (e.g., ‚Äúadd a new module + tests‚Äù).\nYou can iterate with smaller deltas, which makes reviewing easier.\n\n\n\n\n\nCursor can make too many edits if your prompt is broad.\nAlways review diffs like you would a teammate PR.\n\n\n\n\n\n\n\n\nA typical Cursor workspace gives you:\n\nEditor: where the truth lives (the code you run)\nChat panel: ask for explanations, changes, scaffolding\nInline suggestions: ‚Äúautocomplete on steroids‚Äù\nCommand palette actions: apply or rewrite sections quickly\n\nTeaching point: students must learn that the editor is the source of truth ‚Äî not the chat transcript.\n\n\n\n\n‚ÄúProject-wide context‚Ä¶‚Äù\n\nCursor becomes powerful when it understands your project:\n\nFolder structure\nDependencies\nNaming conventions\n‚ÄúHow we do things here‚Äù\n\nThis is where good software engineering meets AI.\n\n\nEven with Cursor, models still have limited context windows. So the art is:\n\nOnly include what matters\nSummarize what‚Äôs irrelevant\nAvoid dumping huge logs without focus\n\n\n\n\nIf the AI keeps making the same mistake, your context is missing something.\nFix it by adding:\n\nconstraints (‚Äúdo not change public API‚Äù)\nexamples (‚Äúhere is one correct pattern in this repo‚Äù)\na test (‚Äúthis must pass‚Äù)\n\n\n\n\n\nWeek 10 demonstrates vibe coding by building a small game (a simple working program you can run).\nThis is a great teaching pattern because:\n\nSmall apps expose real engineering problems quickly: I/O, state, loops, UI feedback\nStudents can run + test without needing deployment\nIteration is visible\n\n\n\nYou want early success:\n\na window opens\nsomething responds\nthe loop runs\n\nThen you polish.\n\n\n\n\n\n‚ÄúThe initial prompt to build our game‚Äù\n\nThis is the moment students usually mess up by being vague.\nA strong initial prompt contains:\n\ngoal (what game?)\nplatform (Python? Pygame? terminal?)\nconstraints (keep it simple, one file)\nexpected behavior (controls, win condition)\noutput format (code only, plus run instructions)\n\n\n\nYou are an expert Python developer.\n\nBuild a simple Pong-style game in Python using pygame.\n\nConstraints:\n- Single file: game.py\n- Keep it beginner friendly (clear functions, comments)\n- WASD controls for left paddle, arrow keys for right paddle\n- Score displayed at top\n- Press Q to quit\n\nOutput:\n- Provide the complete code for game.py\n- Then provide exact run steps (pip + python)\n\n\n\n\nIt creates a format contract: the model knows what to output.\nIt defines inputs (controls), outputs (score), and stop condition (quit).\nIt sets the difficulty level (beginner friendly).\n\n\n\n\n\n\n‚ÄúCursor basics‚Äù\n\nCursor gives you multiple ways to use AI, and mixing them up causes pain.\n\n\nUse for:\n\ndesign discussion (‚Äúwhat approach should we take?‚Äù)\ndebugging (‚Äúhere‚Äôs the stack trace, what does it mean?‚Äù)\nplanning (‚Äúbreak this into steps‚Äù)\n\n\n\n\nUse for:\n\ntargeted rewrites (‚Äúsimplify this function‚Äù)\ntransformations (‚Äúconvert to dataclass‚Äù)\nlocal refactors (‚Äúrename variables consistently‚Äù)\n\n\n\n\nUse for:\n\nwriting boilerplate quickly\nfinishing predictable patterns\nstaying in flow\n\nTeaching tip: chat is best when you don‚Äôt know what to do, edit is best when you know what you want changed.\n\n\n\n\n\n‚ÄúGiving feedback‚Äù\n\nFeedback is the steering wheel of vibe coding.\nGood feedback is:\n\nspecific (‚Äúthe paddle is moving too fast‚Äù)\ntestable (‚Äúball should bounce at the same angle‚Äù)\nconstrained (‚Äúonly change movement speed constants‚Äù)\n\nBad feedback is:\n\nemotional (‚Äúthis is broken‚Äù)\nvague (‚Äúmake it better‚Äù)\n\n\n\n\nWhat did I expect?\nWhat happened instead?\nWhere in the code does that behavior live?\nWhat is the smallest change that could fix it?\n\n\n\n\n\nThe temptation is to paste everything. Don‚Äôt.\nPaste only:\n\nthe failing function\nthe error message\nthe minimal reproduction steps\n\nExample:\nBug report:\n- When I press W, the paddle moves diagonally.\n\nRepro:\n1. Run game.py\n2. Press W for 2 seconds\n\nExpected:\n- Paddle moves up only.\n\nActual:\n- Paddle moves up + right.\n\nHere is the movement code (lines 41-68):\n[paste snippet]\nThis gives the model a ‚Äúdebug ticket‚Äù it can solve.\n\n\n\n\n\n\nTask\nBest Cursor mode\nWhy\n\n\n\n\n‚ÄúExplain this error‚Äù\nChat\nreasoning + teaching\n\n\n‚ÄúRewrite this function‚Äù\nEdit\ndirect transformation\n\n\n‚ÄúAdd docstrings‚Äù\nEdit\nrepetitive change\n\n\n‚ÄúFinish this for-loop‚Äù\nAutocomplete\npredictable\n\n\n‚ÄúDesign a module layout‚Äù\nChat\nbrainstorming\n\n\n\n\n\n\n\n‚ÄúModel selection‚Äù\n\nDifferent models behave differently:\n\nsome are faster, but more shallow\nsome reason better, but slower\nsome follow formatting better\n\nStudents should learn:\n\nuse the ‚Äúsmart‚Äù model for big architectural tasks\nuse the ‚Äúfast‚Äù model for repetitive refactors\n\n\n\n\n\n‚ÄúMAX mode‚Äù\n\nMAX mode is useful when:\n\nthe codebase is large\nthe change is cross-cutting\nyou need the model to ‚Äúhold more context‚Äù\n\nBut it can also lead to over-editing.\nRule: MAX mode is for design + sweeping edits, not for ‚Äúchange one line‚Äù.\n\n\n\n\n‚ÄúResults from the first prompt‚Äù\n\nYour first generated program will usually be:\n\nrunnable (if you gave good constraints)\nugly (variable names, structure)\nmissing polish (pause, restart, menus)\n\nThat‚Äôs normal.\nWhat matters is: we have something to iterate on.\n\n\n\n\nThis week reminds you to treat environment setup as part of development.\n\n\npython -m venv .venv\n# mac/linux:\nsource .venv/bin/activate\n# windows:\n# .venv\\Scripts\\activate\n\npip install pygame\npython game.py\n\n\n\n\nWrong Python interpreter selected in the IDE\nMissing virtual environment activation\nPygame not installed in the active env\n\nTeaching tip: make students prove which python they are using:\npython -c \"import sys; print(sys.executable)\"\npython -c \"import pygame; print(pygame.__version__)\"\n\n\n\n\n\n‚ÄúMaking changes to our game‚Äù\n\nVibe coding works best with small, reviewable changes.\nExamples of small changes:\n\nchange paddle speed constant\nadd a pause key\ncap frame rate\ntweak collision detection\n\nExamples of risky changes:\n\n‚Äúrewrite the whole game architecture‚Äù\n‚Äúswitch to a different framework‚Äù\n‚Äúadd multiplayer networking‚Äù\n\n\n\nChange request:\n\nIn game.py, reduce paddle speed by 25%.\nOnly change the speed constant(s).\nDo not refactor anything else.\nReturn the exact diff as a unified patch.\nThat kind of constraint reduces collateral damage.\n\n\n\n\nThis week shows that iteration isn‚Äôt random ‚Äî it‚Äôs structured prompting.\nA ‚Äúsecond prompt‚Äù is usually one of:\n\nbug fix\nfeature add\nrefactor for clarity\nadd tests / validation\n\nKey skill: describe the change in terms of inputs ‚Üí behavior ‚Üí output.\n\n\n\nWhen students rely on AI, they sometimes stop debugging. That‚Äôs dangerous.\nInstead:\n\nuse AI to accelerate debugging, not replace it\ndemand explanations\nadd prints / logs\nshrink the problem\n\n\n\nBad:\nFix my code\nGood:\nI'm getting this error when I run game.py:\n\nTraceback (most recent call last):\n  File \"game.py\", line 121, in &lt;module&gt;\n    main()\n  File \"game.py\", line 78, in main\n    ball.update()\nAttributeError: 'Ball' object has no attribute 'update'\n\nTask:\n1) Explain why this error happens\n2) Show the smallest fix\n3) Provide the corrected code for the Ball class only\n\n\n\n\n\nUse screenshots like this to talk about:\n\nframe rate (smooth motion)\ncollision boundaries\nscore placement\nreadability\n\n\n\n\n\nPractical reminder 1: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 2: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 3: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 4: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 5: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 6: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 7: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 8: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 9: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 10: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 11: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 12: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 13: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 14: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 15: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 16: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 17: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 18: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 19: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 20: Commit, run, and review diffs ‚Äî every iteration.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#what-this-week-covers-and-why-you-should-care",
    "href": "notes/notes_10.html#what-this-week-covers-and-why-you-should-care",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Week 10 moves from ‚Äúcoding with AI as a helper‚Äù to a conversational programming workflow where your editor + model become a co-author.\nYou‚Äôll see:\n\nHow Cursor differs from ‚Äújust ChatGPT in a browser‚Äù\nWhat vibe coding means in practice (and what it does not mean)\nHow to prompt for a whole working program and then iterate safely\nHow to use Cursor‚Äôs modes (chat, edit, autocomplete) deliberately\nHow to keep control: debugging, tests, and small edits instead of chaos\n\nReal-world framing: this is the difference between ‚Äúasking AI questions‚Äù and shipping software with AI in the loop.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#what-is-vibe-coding",
    "href": "notes/notes_10.html#what-is-vibe-coding",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúAt one end of the spectrum‚Ä¶‚Äù\n\nThe phrase ‚Äúvibe coding‚Äù is basically: you steer by intent and feedback, not by writing every line from scratch.\n\n\n\nYou start by describing behavior (what the program should do) rather than implementation (how it does it).\nThe AI proposes code.\nYou run it, observe, and then refine the prompt (or apply edits) until it behaves.\n\nThat feedback loop is the ‚Äúvibe‚Äù.\n\n\n\n\nLLMs are strong at first drafts and pattern-matching.\nEditors like Cursor provide context (your whole repo), so the model can be more precise.\nYou can move faster when you accept that drafts are disposable.\n\n\n\n\n\nNot ‚Äúno thinking‚Äù.\nNot ‚Äútrust the model blindly‚Äù.\nNot ‚Äúskip debugging‚Äù.\n\nIf you do that, you get brittle code and mysterious failures.\n\n\n\n\nOver-scoping: asking for ‚Äúbuild the whole app‚Äù without constraints.\nUnder-specifying: vague goals produce vague programs.\nContext leakage: if your project contains confusing files, the model can copy the wrong patterns.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#figure-the-vibe-coding-workflow-at-a-glance",
    "href": "notes/notes_10.html#figure-the-vibe-coding-workflow-at-a-glance",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Use this figure to remember the mental model:\n\nDescribe intent\n\nGenerate a draft\n\nRun it\n\nDebug + refine\n\nRepeat until correct",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#what-is-cursor-and-why-is-it-different",
    "href": "notes/notes_10.html#what-is-cursor-and-why-is-it-different",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúWhat is Cursor, and why is it different?‚Äù\n\nCursor is an IDE designed to make AI part of the editing loop. The big difference is context + actions:\n\nIt sees your open files, selections, and (optionally) the entire project.\nIt can apply edits directly (not just suggest them).\nIt supports modes that match real programming tasks.\n\nIn other words, it‚Äôs not ‚Äúchatting about code‚Äù ‚Äî it‚Äôs editing code with chat.\n\n\n\nYou can ask for changes in-place (e.g., ‚Äúrefactor this function‚Äù).\nYou can request multi-file modifications (e.g., ‚Äúadd a new module + tests‚Äù).\nYou can iterate with smaller deltas, which makes reviewing easier.\n\n\n\n\n\nCursor can make too many edits if your prompt is broad.\nAlways review diffs like you would a teammate PR.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#the-interface-what-each-panel-is-for",
    "href": "notes/notes_10.html#the-interface-what-each-panel-is-for",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "A typical Cursor workspace gives you:\n\nEditor: where the truth lives (the code you run)\nChat panel: ask for explanations, changes, scaffolding\nInline suggestions: ‚Äúautocomplete on steroids‚Äù\nCommand palette actions: apply or rewrite sections quickly\n\nTeaching point: students must learn that the editor is the source of truth ‚Äî not the chat transcript.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#project-wide-context-and-customization",
    "href": "notes/notes_10.html#project-wide-context-and-customization",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúProject-wide context‚Ä¶‚Äù\n\nCursor becomes powerful when it understands your project:\n\nFolder structure\nDependencies\nNaming conventions\n‚ÄúHow we do things here‚Äù\n\nThis is where good software engineering meets AI.\n\n\nEven with Cursor, models still have limited context windows. So the art is:\n\nOnly include what matters\nSummarize what‚Äôs irrelevant\nAvoid dumping huge logs without focus\n\n\n\n\nIf the AI keeps making the same mistake, your context is missing something.\nFix it by adding:\n\nconstraints (‚Äúdo not change public API‚Äù)\nexamples (‚Äúhere is one correct pattern in this repo‚Äù)\na test (‚Äúthis must pass‚Äù)",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#first-concept-build-something-small-then-improve-it",
    "href": "notes/notes_10.html#first-concept-build-something-small-then-improve-it",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Week 10 demonstrates vibe coding by building a small game (a simple working program you can run).\nThis is a great teaching pattern because:\n\nSmall apps expose real engineering problems quickly: I/O, state, loops, UI feedback\nStudents can run + test without needing deployment\nIteration is visible\n\n\n\nYou want early success:\n\na window opens\nsomething responds\nthe loop runs\n\nThen you polish.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#the-initial-prompt-to-build-our-game",
    "href": "notes/notes_10.html#the-initial-prompt-to-build-our-game",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúThe initial prompt to build our game‚Äù\n\nThis is the moment students usually mess up by being vague.\nA strong initial prompt contains:\n\ngoal (what game?)\nplatform (Python? Pygame? terminal?)\nconstraints (keep it simple, one file)\nexpected behavior (controls, win condition)\noutput format (code only, plus run instructions)\n\n\n\nYou are an expert Python developer.\n\nBuild a simple Pong-style game in Python using pygame.\n\nConstraints:\n- Single file: game.py\n- Keep it beginner friendly (clear functions, comments)\n- WASD controls for left paddle, arrow keys for right paddle\n- Score displayed at top\n- Press Q to quit\n\nOutput:\n- Provide the complete code for game.py\n- Then provide exact run steps (pip + python)\n\n\n\n\nIt creates a format contract: the model knows what to output.\nIt defines inputs (controls), outputs (score), and stop condition (quit).\nIt sets the difficulty level (beginner friendly).",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#cursor-basics-chat-vs-edit-vs-autocomplete",
    "href": "notes/notes_10.html#cursor-basics-chat-vs-edit-vs-autocomplete",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúCursor basics‚Äù\n\nCursor gives you multiple ways to use AI, and mixing them up causes pain.\n\n\nUse for:\n\ndesign discussion (‚Äúwhat approach should we take?‚Äù)\ndebugging (‚Äúhere‚Äôs the stack trace, what does it mean?‚Äù)\nplanning (‚Äúbreak this into steps‚Äù)\n\n\n\n\nUse for:\n\ntargeted rewrites (‚Äúsimplify this function‚Äù)\ntransformations (‚Äúconvert to dataclass‚Äù)\nlocal refactors (‚Äúrename variables consistently‚Äù)\n\n\n\n\nUse for:\n\nwriting boilerplate quickly\nfinishing predictable patterns\nstaying in flow\n\nTeaching tip: chat is best when you don‚Äôt know what to do, edit is best when you know what you want changed.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#giving-feedback-how-to-steer-the-model",
    "href": "notes/notes_10.html#giving-feedback-how-to-steer-the-model",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúGiving feedback‚Äù\n\nFeedback is the steering wheel of vibe coding.\nGood feedback is:\n\nspecific (‚Äúthe paddle is moving too fast‚Äù)\ntestable (‚Äúball should bounce at the same angle‚Äù)\nconstrained (‚Äúonly change movement speed constants‚Äù)\n\nBad feedback is:\n\nemotional (‚Äúthis is broken‚Äù)\nvague (‚Äúmake it better‚Äù)\n\n\n\n\nWhat did I expect?\nWhat happened instead?\nWhere in the code does that behavior live?\nWhat is the smallest change that could fix it?",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#adding-context-what-to-paste-into-chat",
    "href": "notes/notes_10.html#adding-context-what-to-paste-into-chat",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "The temptation is to paste everything. Don‚Äôt.\nPaste only:\n\nthe failing function\nthe error message\nthe minimal reproduction steps\n\nExample:\nBug report:\n- When I press W, the paddle moves diagonally.\n\nRepro:\n1. Run game.py\n2. Press W for 2 seconds\n\nExpected:\n- Paddle moves up only.\n\nActual:\n- Paddle moves up + right.\n\nHere is the movement code (lines 41-68):\n[paste snippet]\nThis gives the model a ‚Äúdebug ticket‚Äù it can solve.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#selecting-a-mode-decision-table",
    "href": "notes/notes_10.html#selecting-a-mode-decision-table",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Task\nBest Cursor mode\nWhy\n\n\n\n\n‚ÄúExplain this error‚Äù\nChat\nreasoning + teaching\n\n\n‚ÄúRewrite this function‚Äù\nEdit\ndirect transformation\n\n\n‚ÄúAdd docstrings‚Äù\nEdit\nrepetitive change\n\n\n‚ÄúFinish this for-loop‚Äù\nAutocomplete\npredictable\n\n\n‚ÄúDesign a module layout‚Äù\nChat\nbrainstorming",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#model-selection-speed-vs-quality",
    "href": "notes/notes_10.html#model-selection-speed-vs-quality",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúModel selection‚Äù\n\nDifferent models behave differently:\n\nsome are faster, but more shallow\nsome reason better, but slower\nsome follow formatting better\n\nStudents should learn:\n\nuse the ‚Äúsmart‚Äù model for big architectural tasks\nuse the ‚Äúfast‚Äù model for repetitive refactors",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#max-mode-when-you-need-the-heavy-hammer",
    "href": "notes/notes_10.html#max-mode-when-you-need-the-heavy-hammer",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúMAX mode‚Äù\n\nMAX mode is useful when:\n\nthe codebase is large\nthe change is cross-cutting\nyou need the model to ‚Äúhold more context‚Äù\n\nBut it can also lead to over-editing.\nRule: MAX mode is for design + sweeping edits, not for ‚Äúchange one line‚Äù.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#results-from-the-first-prompt-expect-rough-edges",
    "href": "notes/notes_10.html#results-from-the-first-prompt-expect-rough-edges",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúResults from the first prompt‚Äù\n\nYour first generated program will usually be:\n\nrunnable (if you gave good constraints)\nugly (variable names, structure)\nmissing polish (pause, restart, menus)\n\nThat‚Äôs normal.\nWhat matters is: we have something to iterate on.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#running-our-game-for-the-first-time-environment-dependencies",
    "href": "notes/notes_10.html#running-our-game-for-the-first-time-environment-dependencies",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "This week reminds you to treat environment setup as part of development.\n\n\npython -m venv .venv\n# mac/linux:\nsource .venv/bin/activate\n# windows:\n# .venv\\Scripts\\activate\n\npip install pygame\npython game.py\n\n\n\n\nWrong Python interpreter selected in the IDE\nMissing virtual environment activation\nPygame not installed in the active env\n\nTeaching tip: make students prove which python they are using:\npython -c \"import sys; print(sys.executable)\"\npython -c \"import pygame; print(pygame.__version__)\"",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#making-changes-to-our-game-small-diffs-win",
    "href": "notes/notes_10.html#making-changes-to-our-game-small-diffs-win",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "‚ÄúMaking changes to our game‚Äù\n\nVibe coding works best with small, reviewable changes.\nExamples of small changes:\n\nchange paddle speed constant\nadd a pause key\ncap frame rate\ntweak collision detection\n\nExamples of risky changes:\n\n‚Äúrewrite the whole game architecture‚Äù\n‚Äúswitch to a different framework‚Äù\n‚Äúadd multiplayer networking‚Äù\n\n\n\nChange request:\n\nIn game.py, reduce paddle speed by 25%.\nOnly change the speed constant(s).\nDo not refactor anything else.\nReturn the exact diff as a unified patch.\nThat kind of constraint reduces collateral damage.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#the-second-prompt-iteration-with-structure",
    "href": "notes/notes_10.html#the-second-prompt-iteration-with-structure",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "This week shows that iteration isn‚Äôt random ‚Äî it‚Äôs structured prompting.\nA ‚Äúsecond prompt‚Äù is usually one of:\n\nbug fix\nfeature add\nrefactor for clarity\nadd tests / validation\n\nKey skill: describe the change in terms of inputs ‚Üí behavior ‚Üí output.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#debugging-in-a-vibe-coding-workflow",
    "href": "notes/notes_10.html#debugging-in-a-vibe-coding-workflow",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "When students rely on AI, they sometimes stop debugging. That‚Äôs dangerous.\nInstead:\n\nuse AI to accelerate debugging, not replace it\ndemand explanations\nadd prints / logs\nshrink the problem\n\n\n\nBad:\nFix my code\nGood:\nI'm getting this error when I run game.py:\n\nTraceback (most recent call last):\n  File \"game.py\", line 121, in &lt;module&gt;\n    main()\n  File \"game.py\", line 78, in main\n    ball.update()\nAttributeError: 'Ball' object has no attribute 'update'\n\nTask:\n1) Explain why this error happens\n2) Show the smallest fix\n3) Provide the corrected code for the Ball class only",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#figure-example-ui-gameplay-snapshot",
    "href": "notes/notes_10.html#figure-example-ui-gameplay-snapshot",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Use screenshots like this to talk about:\n\nframe rate (smooth motion)\ncollision boundaries\nscore placement\nreadability",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_10.html#rapid-fire-practical-reminders-for-students",
    "href": "notes/notes_10.html#rapid-fire-practical-reminders-for-students",
    "title": "Week 10 ‚Äî Vibe coding with Cursor",
    "section": "",
    "text": "Practical reminder 1: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 2: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 3: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 4: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 5: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 6: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 7: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 8: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 9: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 10: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 11: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 12: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 13: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 14: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 15: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 16: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 17: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 18: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 19: Commit, run, and review diffs ‚Äî every iteration.\nPractical reminder 20: Commit, run, and review diffs ‚Äî every iteration.",
    "crumbs": [
      "Notes",
      "Notes 10 ü§ñ"
    ]
  },
  {
    "objectID": "module-syllabus.html",
    "href": "module-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Dr.¬†Ed Harris, Module Leader, Data Scientist, Statistician, and coffee enthusiast. NB Ed is away for the beginning of the Spring semester.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#your-instructors",
    "href": "module-syllabus.html#your-instructors",
    "title": "Syllabus",
    "section": "",
    "text": "Dr.¬†Ed Harris, Module Leader, Data Scientist, Statistician, and coffee enthusiast. NB Ed is away for the beginning of the Spring semester.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#learning-objectives",
    "href": "module-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\n1.¬†¬†¬† Develop and apply complex workflows using chain calls to LLMs, demonstrating an understanding of automated systems.\n2.¬†¬†¬† Construct and analyse systems where Python code interacts with both completions and new prompts, showcasing programming proficiency.\n3.¬†¬†¬† Design a customer service chatbot using learned techniques, reflecting an ability to integrate various aspects of data science technology.\n4.¬†¬†¬† Evaluate and apply prompt engineering skills in practical scenarios, including chat agent response systems and safety evaluations.\n5.¬†¬†¬† Synthesise and apply knowledge of vector databases in building applications like retrieval augmented generation (RAG) and multilingual search systems.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#meetings",
    "href": "module-syllabus.html#meetings",
    "title": "Syllabus",
    "section": "Meetings",
    "text": "Meetings\nMeetings will be held in person in Telford, Station Quarter. Spring 2025: Check your personal schedule for room, day, time.\nNotes and brief lectures will introduce the weekly topic and sometimes involve live coding demonstration of key concepts. Lectures and notes should be reviewed prior to attending each weekly session.\nFlipped classroom will be used exclusively for this module. This reverses traditional teaching by having students go through new material independently, through videos or readings, before class meetings. Then, class time is used for discussion, problem-solving, assessments, and applying ideas. This lets students work through content at their own pace and ensures that support from teachers and peers is available when tackling challenging concepts. The idea is to make learning more active, collaborative, and confidence-building. Also, it is usually more fun than traditional lectures!\nMaterial may be livestreamed or otherwise recorded for later viewing.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#online-resources",
    "href": "module-syllabus.html#online-resources",
    "title": "Syllabus",
    "section": "Online resources",
    "text": "Online resources\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the module website. This material is completely open and accessible to all without login or other barriers.\nHarper Adams module website (university enrolled students only, requires login)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#assessments",
    "href": "module-syllabus.html#assessments",
    "title": "Syllabus",
    "section": "Assessments",
    "text": "Assessments\n\nAssessment 1\nProject The Real World AI module culminates in a unique summative assessment, consisting of a group project that is both designed and executed by the students supported with supervised class work and discussion, and student support and technical staff. This project is split into two main components: a pitch presentation and the final project creation. In the pitch presentation, reminiscent of a ‚ÄòDragon‚Äôs Den‚Äô scenario, groups of students are expected to conceive and present an innovative application of large language models (LLMs) and APIs. This presentation should detail the objectives, technology use (such as vector databases and OpenAI API), methodology, and potential impact of the proposed project. Following the pitch, students collaborate to turn their concept into a reality. This phase involves prompt engineering, crafting efficient data processing systems, and ultimately producing a functional prototype or application that aligns with their initial pitch. The project is assessed on its functionality, innovation, effective use of data science technologies, and overall execution.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#readings",
    "href": "module-syllabus.html#readings",
    "title": "Syllabus",
    "section": "Readings",
    "text": "Readings\nMorgan, J. C. 2025. Coding with AI. 1st edition. Manning Publications. Shelter Island, NY.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#five-tips-for-success",
    "href": "module-syllabus.html#five-tips-for-success",
    "title": "Syllabus",
    "section": "Five tips for success",
    "text": "Five tips for success\nYour success on this module depends very much on you and the effort you put into it. Like any learning, the burden of engaging with the material is on you. The module staff and I will help you be providing you with materials and answering questions and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class.\nAsk questions. As often as you can. In class, out of class. Ask me, ask the course staff, ask your friends, ask the person sitting next to you. This will help you more than anything else. If you get a question wrong on an assessment, ask us why. If you‚Äôre not sure about the homework, let‚Äôs talk about it. If you hear something on the news that sounds related to what we discussed, share it and let‚Äôs discuss. If the reading is confusing, ask.\nDo some of the optional readings, read and share relevant Twitter/X posts, read and share relevant Hacker News articles. Consider joining or forming a reading group that meets once per week to discuss.\nDo the homework and the tutorials. The earlier you start, the better. It‚Äôs not enough to just mechanically plow through the exercises. You should ask yourself how these exercises relate to earlier material, and imagine how they might be changed (to make questions for an exam, for example.)\nDon‚Äôt procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually you won‚Äôt know where to begin asking questions. Don‚Äôt let the week end with unanswered questions. But if you find yourself falling behind and not knowing where to begin asking, ask for help, and let us help you identify a good (re)starting point.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-syllabus.html#module-policies",
    "href": "module-syllabus.html#module-policies",
    "title": "Syllabus",
    "section": "Module policies",
    "text": "Module policies\nThe essence of all work that you submit to this course must be your own. Unless otherwise specified, collaboration on assessments (e.g., assignments, labs, problem sets, projects, quizzes, or tests) is not permitted except to the extent that you may ask classmates and others for help so long as that help does not reduce to another doing your work for you. Generally speaking, when asking for help, you may show your work to others, but you may not view theirs, so long as you and they respect this policy‚Äôs other constraints.\nReasonable\n\nCommunicating with classmates about assessments in English (or some other spoken language), and properly citing those discussions.\nDiscussing the course‚Äôs material with others in order to understand it better.\nHelping a classmate identify a bug in their code, as by viewing, compiling, or running their code after you have submitted that portion of the pset yourself.\nIncorporating a few lines of code that you find online or elsewhere into your own code, provided that those lines are not themselves solutions to assigned work and that you cite the lines‚Äô origins.\nSending or showing code that you‚Äôve written to someone, possibly a classmate, so that they might help you identify and fix a bug.\nSubmitting the same or similar work to this course that you have submitted previously to this course.\nTurning to the web or elsewhere for instruction beyond the course‚Äôs own, for references, and for solutions to technical difficulties, but not for outright solutions to assigned work.\nUsing AI-based software to ask questions, but not presenting its answers as your own.\nWhiteboarding solutions with others using diagrams or pseudocode but not actual code.\nWorking with (and even paying) a tutor to help you with the course, provided the tutor does not do your work for you.\n\nNot Reasonable\n\nAccessing a solution to some assessement prior to (re-)submitting your own.\nAccessing or attempting to access, without permission, an account not your own.\nAsking a classmate to see their solution to some assessment before submitting your own.\nFailing to cite (as with comments) the origins of code or techniques that you discover outside of the course‚Äôs own lessons and integrate into your own work, even while respecting this policy‚Äôs other constraints.\nGiving or showing to a classmate a solution to an assessment when it is they, and not you, who is struggling to solve it.\nPaying or offering to pay an individual for work that you may submit as (part of) your own.\nProviding or making available solutions to assessments to anyone, whether a past, present, or prospective future student.\nSearching for or soliciting outright solutions to assessments online or elsewhere.\nSplitting an assessment‚Äôs workload with another individual and combining your work.\nSubmitting (after possibly modifying) the work of another individual beyond the few lines allowed herein.\nSubmitting the same or similar work to this course that you have submitted or will submit to another course, unless explictly allowed.\nUsing AI-based software (including ChatGPT, GitHub Copilot, the new Bing, et al.) that suggests answers or lines of code.\nViewing another‚Äôs solution to an assessment and basing your own solution on it.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "module-project.html",
    "href": "module-project.html",
    "title": "Module Project",
    "section": "",
    "text": "Info coming‚Ä¶",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "module-project.html#final-project",
    "href": "module-project.html#final-project",
    "title": "Module Project",
    "section": "",
    "text": "Info coming‚Ä¶",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "module-project.html#getting-started",
    "href": "module-project.html#getting-started",
    "title": "Module Project",
    "section": "Getting Started",
    "text": "Getting Started",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "module-project.html#how-to-submit",
    "href": "module-project.html#how-to-submit",
    "title": "Module Project",
    "section": "How to Submit",
    "text": "How to Submit",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "module-faq.html",
    "href": "module-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Yes, of course you can and should! But‚Ä¶\nThe point of the flipped classroom is to maximise the time spent in class discussing and solving problems. If you don‚Äôt watch the videos and go through the notes for that week before class, you will miss out on this and potentially fall behind while others are getting on with their problem set work during classtime.",
    "crumbs": [
      "FAQ"
    ]
  },
  {
    "objectID": "module-faq.html#flipped-classroom-can-i-still-come-to-lecture-if-i-dont-watch-the-videos-and-go-through-the-notes-for-that-week-before-class",
    "href": "module-faq.html#flipped-classroom-can-i-still-come-to-lecture-if-i-dont-watch-the-videos-and-go-through-the-notes-for-that-week-before-class",
    "title": "FAQ",
    "section": "",
    "text": "Yes, of course you can and should! But‚Ä¶\nThe point of the flipped classroom is to maximise the time spent in class discussing and solving problems. If you don‚Äôt watch the videos and go through the notes for that week before class, you will miss out on this and potentially fall behind while others are getting on with their problem set work during classtime.",
    "crumbs": [
      "FAQ"
    ]
  },
  {
    "objectID": "module-faq.html#can-i-just-code-on-my-own-computer",
    "href": "module-faq.html#can-i-just-code-on-my-own-computer",
    "title": "FAQ",
    "section": "Can I just code on my own computer?",
    "text": "Can I just code on my own computer?\nThe short answer is, heck yeah!!, with caveats.\nInstalling and configuring programming and editing software on your own computer is sometimes complicated and irritating, even for very experienced people. Configuring all the tools we will be using in The Sandbox to be exactly the same on your own computer, operating system, etc., will require advanced skills. Still, you can attempt to do it if you want to; most of the tools are open source and free and will work for most tasks. Also, we are here to help support you if you want to try.",
    "crumbs": [
      "FAQ"
    ]
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (‚ÄúPublic License‚Äù). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 ‚Äì Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter‚Äôs License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 ‚Äì Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor ‚Äì Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor ‚Äì Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter‚Äôs License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 ‚Äì License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter‚Äôs License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter‚Äôs License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter‚Äôs License You apply.\n\n\n\nSection 4 ‚Äì Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 ‚Äì Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 ‚Äì Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 ‚Äì Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 ‚Äì Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the ‚ÄúLicensor.‚Äù The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark ‚ÄúCreative Commons‚Äù or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Programming Concepts",
    "section": "",
    "text": "Code must be written for people to read, and, only incidentally, for machines to execute.\n\nWelcome!\nThis module offers an engaging introduction and an overview to programming utilising Python. Designed to accommodate both novices and those with some programming background, it covers a spectrum of fundamental concepts of coding. Key topics include reading and writing code, testing, debugging with Python-specific features. This module provides essential underpinning skills for other computer science modules. The content will be highly relevant and adaptable, enhancing employability and professional development in technology-driven industries.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "module-extras.html",
    "href": "module-extras.html",
    "title": "Extra Meetings",
    "section": "",
    "text": "HADC! is a group of people (students, researchers, and staff) who are interested in statistics and data science. We typically meet regularly to discuss practical statistics and data science topics. Check out the HADC! website for the schedule."
  },
  {
    "objectID": "module-extras.html#harper-adams-data-club-hadc",
    "href": "module-extras.html#harper-adams-data-club-hadc",
    "title": "Extra Meetings",
    "section": "",
    "text": "HADC! is a group of people (students, researchers, and staff) who are interested in statistics and data science. We typically meet regularly to discuss practical statistics and data science topics. Check out the HADC! website for the schedule."
  },
  {
    "objectID": "module-extras.html#code-club",
    "href": "module-extras.html#code-club",
    "title": "Extra Meetings",
    "section": "Code Club",
    "text": "Code Club\nThe Code Club is an outreach-based initiative that aims to help school students learn programming and data science. Our first Code Club will be held regularly (keep your eyes open for announcements). This is an opportunity for you to help mentor younger students - it is fun, rewarding, and a great way to build your CV."
  },
  {
    "objectID": "module-links.html",
    "href": "module-links.html",
    "title": "Useful links",
    "section": "",
    "text": "üîó Reference manual for Python - Probably very useful‚Ä¶\nüîó üé§ HADC! & Code Club meetings\nüîó üè¢ Harper Adams VLE site for this module (HAU enrolled students only)",
    "crumbs": [
      "Useful links"
    ]
  },
  {
    "objectID": "module-schedule.html",
    "href": "module-schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "üîó ‚ÄúThe Sandbox‚Äù coding environment (Github Codespace)\nThis schedule is an outline of the topics, with links to all content, and assignments. Note that this may be updated as the module progresses.\n\n\n\nWeek (HAU)\nTopics\nLectures\nNotes + Readings\nCode\n\n\n\n\n00 (16)\nü§ñ Gen AI Intro\nüíª\nüìï + üìí\nü§ñ\n\n\n01 (17)\nü§ñ AI-assisted Code\nüíª\nüìï + üìí\nü§ñ\n\n\n02 (18)\nü§ñ Design\nüíª\nüìï + üìí\nü§ñ\n\n\n03 (19)\nü§ñ Code an App\nüíª\nüìï + üìí\nü§ñ\n\n\n04 (20)\nü§ñ Base Code Gen\nüíª\nüìï + üìí\nü§ñ\n\n\n05 (21)\nü§ñ Backend\nüíª\nüìï + üìí\nü§ñ\n\n\n06 (22)\nü§ñ UI\nüíª\nüìï + üìí\nü§ñ\n\n\n\nüí• Mid term Break\n\n\n\n\n\n07 (23)\nü§ñ Software Testing\nüíª\nüìï + üìí\nü§ñ\n\n\n08 (24)\nü§ñ Prompt Engineering\nüíª\nüìï + üìí\nü§ñ\n\n\n09 (25)\nü§ñ Vibe Coding\nüíª\nüìï + üìí\nü§ñ\n\n\n10 (26)\nüëã Wrap up, Open lab\n\n\n\n\n\n11 (27)\nüöÄ Open lab\n\n\n\n\n\n12 (28)\nüöÄ Open lab",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "notes/notes_1.html",
    "href": "notes/notes_1.html",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "‚Äú‚Ä¶use your existing Python expertise alongside AI that understands your code context‚Ä¶‚Äù\n\n\n\n\n‚ÄúSupercharge your coding with AI‚Äù ‚ÄúNo AI expertise is required.‚Äù -Some AI Bro\n\nIn this week we introduce generative AI as a practical toolset for real software development. The goal is not to turn you into an ML creator. The goal is to help you build code solutions, with less busywork, and fewer defects.\n\n\n\nA working definition of generative AI in the context of programming work.\nA map of the developer tool landscape (general chat models vs IDE assistants vs specialist tools).\nA mental model for how LLMs work at a useful, developer-friendly level.\nA realistic view of benefits and failure modes (hallucinations, shallow tests, brittle outputs).\n\n\n\n\n\n\nThe week frames AI coding tools as an ‚Äúextra pair of hands‚Äù for experienced developers. The promise is not magic ‚Äî it‚Äôs leverage:\n\nfaster scaffolding\nfaster iteration\nearlier bug discovery\nimproved test coverage\n\n\n‚Äú‚Ä¶reduced implementation time by approximately 30%, while improving code quality‚Ä¶‚Äù\n\nThe course lens: real world means we care about:\n\npractical constraints\nmaintainability\nsecurity\ncorrectness\nteam workflows\n\n\n\n\n\n\n\nGenerative AI refers to models that produce new content (text, code, images) based on learned patterns. For coding, the relevant output types are:\n\ncode snippets (functions, classes, scripts)\nrefactors (changing structure without changing behaviour)\ntests (unit tests, fuzz tests, property-based tests)\ndocumentation (docstrings, READMEs, API docs)\n\n\n\n\nThis week highlights several practical use cases. We‚Äôll treat these as work modes you can switch between.\n\n\nThis is the ‚Äúpair programmer‚Äù mode. You describe what you want, and the tool produces starter code.\nKey reality check:\n\ngenerated code is rarely perfect\nit is often plausible\nyou must still review and test\n\n\n‚Äú‚Ä¶anticipates patterns, and generates implementation details‚Ä¶‚Äù\n\n\n\n\nTools can propose patches quickly ‚Äî especially for:\n\ncommon exceptions\nmisuse of APIs\noff-by-one errors\nmissing edge-case handling\n\nBut: AI doesn‚Äôt understand your logic. It matches patterns. If your bug is domain-specific, AI help may be weaker.\n\n\n\nAI is good at turning code into:\n\ndocstrings\nusage examples\n‚Äúhow it works‚Äù summaries\n\nThe risk is confident incorrectness. Docs can become wrong faster than code. So you should treat AI-generated docs as a draft, not truth.\n\n\n\nAI can help with:\n\nextracting helper functions\nrenaming variables for clarity\nreorganising modules\nperformance suggestions\n\nBut optimisation suggestions can be dangerous if they change semantics. Always lock behaviour first with tests.\n\n\n\nAI is useful for producing lots of tests quickly. This is a big deal because tests are often the bottleneck.\nHowever:\n\nAI tests can be shallow\nAI may test implementation details instead of behaviour\n\nSo we‚Äôll keep a rule of thumb:\n\nTest behaviour, not the code‚Äôs current shape.\n\n\n\n\n\n\n\nThis week separates tools into categories. You should be able to explain what each category is good for.\n\n\nThese include ChatGPT / Claude-style assistants. They are good for:\n\nexplaining concepts\ndrafting code in isolation\nbrainstorming designs\ngenerating documentation\n\nBut they can struggle with:\n\nlarge codebases\nproject-wide refactors\nkeeping context consistent\n\n\n\n\nThese integrate into editors (VS Code, JetBrains, etc.). They can:\n\nautocomplete in-place\nunderstand surrounding code context\nsuggest local refactors\n\n\n\n\nSome tools focus on a specific workflow:\n\ncode search + fixes\nsecurity checks\ntest generation\n\nThis week calls out tools like Cursor, Blackbox AI, and Tabnine later. Your skill as a developer is choosing the right tool for the task.\n\n‚Äú‚Ä¶practical guide to using AI tools to supercharge your coding‚Ä¶‚Äù\n\n\n\n\n\n\nThis is the part where people often get intimidated. This week‚Äôs key message is:\n\nyou don‚Äôt need the math\nyou do need the mental model\n\nWe‚Äôll focus on what helps you predict failure modes.\n\n\nThink of a large language model (LLM) as:\n\na probability engine over sequences of tokens\ntrained to predict ‚Äúwhat comes next‚Äù\n\nIt does not ‚Äúknow‚Äù facts the way humans do. It generates outputs that are statistically likely given its training.\n\n\n\nThis week describes internal steps like:\n\ninput embedding (tokens ‚Üí vectors)\ntransformer layers (attention)\noutput decoding (vectors ‚Üí tokens)\n\nWe‚Äôll capture this with a diagram.\n\n\n\n\n\nflowchart LR\n  A[Input prompt] --&gt; B[Tokenisation]\n  B --&gt; C[Embeddings]\n  C --&gt; D[Transformer layers&lt;br/&gt;attention + feedforward]\n  D --&gt; E[Next-token probabilities]\n  E --&gt; F[Sampling / decoding]\n  F --&gt; G[Output text/code]\n\n\n\n\n\n\n\n‚ÄúAn LLM is a deep learning architecture based on the Transformer model‚Ä¶‚Äù\n\n\n\n\nAttention is what allows the model to:\n\n‚Äúfocus‚Äù on relevant parts of the prompt\nrelate tokens across distance\nkeep patterns consistent (sometimes!)\n\nWhen you see a model forget instructions, it‚Äôs often because:\n\nthe prompt was too long\nthe instruction got buried\nthe model weighted other tokens as more relevant\n\n\n\n\n\n\n\n\nAn LLM is a model trained on huge amounts of text and code. It learns patterns like:\n\nhow functions are structured\nhow docs are written\nhow bugs are commonly fixed\nhow tests are typically expressed\n\n\n\n\nIt is not:\n\na compiler\na proof system\na deterministic system\na guaranteed factual source\n\nThis week hints at the most important practical issue:\n\noutputs can be fluent and wrong\n\n\n‚Äú‚Ä¶determines whether ‚Äòthis is most likely to be correct and functional source code‚Äô‚Äù\n\n\n\n\n\n\nThis is where this week is optimistic. The potential is that AI tools can shift your role upward:\n\nfrom typing code ‚Üí designing systems\nfrom debugging syntax ‚Üí validating behaviour\nfrom writing boilerplate ‚Üí reviewing structure\n\n\n\nIt usually means:\n\nfaster first drafts\nearlier working prototypes\nmore time spent on architecture\n\nBut only if you adopt a workflow that includes:\n\nreview\ntests\niteration\n\n\n\n\n\n\nMany students confuse these. This week draws a distinction:\n\n\n\nrule-based or simple statistical\nlocal suggestions\nlimited context\n\n\n\n\n\ncan produce novel combinations\ncan respond to higher-level instructions\ncan create multi-file scaffolds\n\n\n‚ÄúUnlike traditional code completion‚Ä¶ generative AI creates‚Ä¶‚Äù\n\nThe key point:\nGenerative AI is a collaborator. Code completion is a convenience feature.\n\n\n\n\n\nEven though this week is coding-focused, generative AI includes:\n\nimage generation\naudio generation\nvideo generation\n\nWhy you should care:\n\nreal products combine modalities\ndocumentation and UI work often needs imagery\n\n\n\n\n\nThis is the most ‚Äúreal world‚Äù section. It breaks software development into stages where AI can help.\n\n\nWhere AI helps:\n\nbrainstorming features\ngenerating user stories\ndrafting requirements\n\nRisk:\n\n‚Äúfeature creep‚Äù (AI happily invents scope)\n\n\n\n\nWhere AI helps:\n\nscaffolding projects\ndrafting modules\nwriting repetitive code\n\nRisk:\n\ninconsistent design decisions\nhidden complexity\n\n\n\n\nWhere AI helps:\n\nspotting style issues\nsuggesting simplifications\nidentifying missing error handling\n\nRisk:\n\nfalse confidence (the model sounds sure)\n\n\n\n\nWhere AI helps:\n\ngenerating test cases\nsuggesting likely failure points\nexplaining stack traces\n\nRisk:\n\nshallow tests that don‚Äôt reflect real requirements\n\n\n\n\nWhere AI helps:\n\nexplaining APIs\nimproving README clarity\ngenerating examples\n\nRisk:\n\ndocs drift from reality\n\n\n‚ÄúThis cycle creates a powerful symbiotic relationship‚Ä¶‚Äù\n\n\n\n\n\n\nThis week emphasises selection criteria. In real teams, you choose tools based on:\n\nintegration (does it fit your IDE/workflow?)\ncontext (does it see your project?)\nprivacy (can you send code externally?)\nquality (accuracy + helpfulness)\n\n\n\n\nDoes it understand multi-file projects?\nDoes it support test generation?\nDoes it help you refactor safely?\nDoes it provide citations or traceability?\n\n\n\n\n\n\nThis week implies several failure modes. We make them explicit because they will recur all term.\n\n\nThe model invents:\n\nnonexistent functions\nwrong APIs\nfake ‚Äúfacts‚Äù\n\nMitigation:\n\nverify against docs\nrun the code\nwrite tests\n\n\n\n\nSometimes your prompt ‚Äúaccidentally‚Äù forces a weird design. Mitigation:\n\nask for alternatives\nrequest tradeoffs\niterate\n\n\n\n\nAI-generated tests often:\n\nonly test ‚Äúhappy path‚Äù\nmirror implementation details\n\nMitigation:\n\nuse boundary cases\ntest behaviour\nadd negative tests\n\n\n\n\n\n\nThis final section is motivational. This week‚Äôs message is:\n\ndon‚Äôt fear the tools\ntreat them as assistants\nkeep your engineering discipline",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#overview",
    "href": "notes/notes_1.html#overview",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "‚ÄúSupercharge your coding with AI‚Äù ‚ÄúNo AI expertise is required.‚Äù -Some AI Bro\n\nIn this week we introduce generative AI as a practical toolset for real software development. The goal is not to turn you into an ML creator. The goal is to help you build code solutions, with less busywork, and fewer defects.\n\n\n\nA working definition of generative AI in the context of programming work.\nA map of the developer tool landscape (general chat models vs IDE assistants vs specialist tools).\nA mental model for how LLMs work at a useful, developer-friendly level.\nA realistic view of benefits and failure modes (hallucinations, shallow tests, brittle outputs).",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#why-this-matters-for-real-world-ai",
    "href": "notes/notes_1.html#why-this-matters-for-real-world-ai",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "The week frames AI coding tools as an ‚Äúextra pair of hands‚Äù for experienced developers. The promise is not magic ‚Äî it‚Äôs leverage:\n\nfaster scaffolding\nfaster iteration\nearlier bug discovery\nimproved test coverage\n\n\n‚Äú‚Ä¶reduced implementation time by approximately 30%, while improving code quality‚Ä¶‚Äù\n\nThe course lens: real world means we care about:\n\npractical constraints\nmaintainability\nsecurity\ncorrectness\nteam workflows",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#generative-ai-for-coders",
    "href": "notes/notes_1.html#generative-ai-for-coders",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "Generative AI refers to models that produce new content (text, code, images) based on learned patterns. For coding, the relevant output types are:\n\ncode snippets (functions, classes, scripts)\nrefactors (changing structure without changing behaviour)\ntests (unit tests, fuzz tests, property-based tests)\ndocumentation (docstrings, READMEs, API docs)\n\n\n\n\nThis week highlights several practical use cases. We‚Äôll treat these as work modes you can switch between.\n\n\nThis is the ‚Äúpair programmer‚Äù mode. You describe what you want, and the tool produces starter code.\nKey reality check:\n\ngenerated code is rarely perfect\nit is often plausible\nyou must still review and test\n\n\n‚Äú‚Ä¶anticipates patterns, and generates implementation details‚Ä¶‚Äù\n\n\n\n\nTools can propose patches quickly ‚Äî especially for:\n\ncommon exceptions\nmisuse of APIs\noff-by-one errors\nmissing edge-case handling\n\nBut: AI doesn‚Äôt understand your logic. It matches patterns. If your bug is domain-specific, AI help may be weaker.\n\n\n\nAI is good at turning code into:\n\ndocstrings\nusage examples\n‚Äúhow it works‚Äù summaries\n\nThe risk is confident incorrectness. Docs can become wrong faster than code. So you should treat AI-generated docs as a draft, not truth.\n\n\n\nAI can help with:\n\nextracting helper functions\nrenaming variables for clarity\nreorganising modules\nperformance suggestions\n\nBut optimisation suggestions can be dangerous if they change semantics. Always lock behaviour first with tests.\n\n\n\nAI is useful for producing lots of tests quickly. This is a big deal because tests are often the bottleneck.\nHowever:\n\nAI tests can be shallow\nAI may test implementation details instead of behaviour\n\nSo we‚Äôll keep a rule of thumb:\n\nTest behaviour, not the code‚Äôs current shape.",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#developer-tools-landscape",
    "href": "notes/notes_1.html#developer-tools-landscape",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This week separates tools into categories. You should be able to explain what each category is good for.\n\n\nThese include ChatGPT / Claude-style assistants. They are good for:\n\nexplaining concepts\ndrafting code in isolation\nbrainstorming designs\ngenerating documentation\n\nBut they can struggle with:\n\nlarge codebases\nproject-wide refactors\nkeeping context consistent\n\n\n\n\nThese integrate into editors (VS Code, JetBrains, etc.). They can:\n\nautocomplete in-place\nunderstand surrounding code context\nsuggest local refactors\n\n\n\n\nSome tools focus on a specific workflow:\n\ncode search + fixes\nsecurity checks\ntest generation\n\nThis week calls out tools like Cursor, Blackbox AI, and Tabnine later. Your skill as a developer is choosing the right tool for the task.\n\n‚Äú‚Ä¶practical guide to using AI tools to supercharge your coding‚Ä¶‚Äù",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#how-does-generative-ai-work",
    "href": "notes/notes_1.html#how-does-generative-ai-work",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This is the part where people often get intimidated. This week‚Äôs key message is:\n\nyou don‚Äôt need the math\nyou do need the mental model\n\nWe‚Äôll focus on what helps you predict failure modes.\n\n\nThink of a large language model (LLM) as:\n\na probability engine over sequences of tokens\ntrained to predict ‚Äúwhat comes next‚Äù\n\nIt does not ‚Äúknow‚Äù facts the way humans do. It generates outputs that are statistically likely given its training.\n\n\n\nThis week describes internal steps like:\n\ninput embedding (tokens ‚Üí vectors)\ntransformer layers (attention)\noutput decoding (vectors ‚Üí tokens)\n\nWe‚Äôll capture this with a diagram.\n\n\n\n\n\nflowchart LR\n  A[Input prompt] --&gt; B[Tokenisation]\n  B --&gt; C[Embeddings]\n  C --&gt; D[Transformer layers&lt;br/&gt;attention + feedforward]\n  D --&gt; E[Next-token probabilities]\n  E --&gt; F[Sampling / decoding]\n  F --&gt; G[Output text/code]\n\n\n\n\n\n\n\n‚ÄúAn LLM is a deep learning architecture based on the Transformer model‚Ä¶‚Äù\n\n\n\n\nAttention is what allows the model to:\n\n‚Äúfocus‚Äù on relevant parts of the prompt\nrelate tokens across distance\nkeep patterns consistent (sometimes!)\n\nWhen you see a model forget instructions, it‚Äôs often because:\n\nthe prompt was too long\nthe instruction got buried\nthe model weighted other tokens as more relevant",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#what-an-llm-is-and-isnt",
    "href": "notes/notes_1.html#what-an-llm-is-and-isnt",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "An LLM is a model trained on huge amounts of text and code. It learns patterns like:\n\nhow functions are structured\nhow docs are written\nhow bugs are commonly fixed\nhow tests are typically expressed\n\n\n\n\nIt is not:\n\na compiler\na proof system\na deterministic system\na guaranteed factual source\n\nThis week hints at the most important practical issue:\n\noutputs can be fluent and wrong\n\n\n‚Äú‚Ä¶determines whether ‚Äòthis is most likely to be correct and functional source code‚Äô‚Äù",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#the-potential-of-llms",
    "href": "notes/notes_1.html#the-potential-of-llms",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This is where this week is optimistic. The potential is that AI tools can shift your role upward:\n\nfrom typing code ‚Üí designing systems\nfrom debugging syntax ‚Üí validating behaviour\nfrom writing boilerplate ‚Üí reviewing structure\n\n\n\nIt usually means:\n\nfaster first drafts\nearlier working prototypes\nmore time spent on architecture\n\nBut only if you adopt a workflow that includes:\n\nreview\ntests\niteration",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#generative-ai-vs-code-completion",
    "href": "notes/notes_1.html#generative-ai-vs-code-completion",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "Many students confuse these. This week draws a distinction:\n\n\n\nrule-based or simple statistical\nlocal suggestions\nlimited context\n\n\n\n\n\ncan produce novel combinations\ncan respond to higher-level instructions\ncan create multi-file scaffolds\n\n\n‚ÄúUnlike traditional code completion‚Ä¶ generative AI creates‚Ä¶‚Äù\n\nThe key point:\nGenerative AI is a collaborator. Code completion is a convenience feature.",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#other-types-of-generative-ai-quick-map",
    "href": "notes/notes_1.html#other-types-of-generative-ai-quick-map",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "Even though this week is coding-focused, generative AI includes:\n\nimage generation\naudio generation\nvideo generation\n\nWhy you should care:\n\nreal products combine modalities\ndocumentation and UI work often needs imagery",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#project-workflow-with-ai-assistance",
    "href": "notes/notes_1.html#project-workflow-with-ai-assistance",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This is the most ‚Äúreal world‚Äù section. It breaks software development into stages where AI can help.\n\n\nWhere AI helps:\n\nbrainstorming features\ngenerating user stories\ndrafting requirements\n\nRisk:\n\n‚Äúfeature creep‚Äù (AI happily invents scope)\n\n\n\n\nWhere AI helps:\n\nscaffolding projects\ndrafting modules\nwriting repetitive code\n\nRisk:\n\ninconsistent design decisions\nhidden complexity\n\n\n\n\nWhere AI helps:\n\nspotting style issues\nsuggesting simplifications\nidentifying missing error handling\n\nRisk:\n\nfalse confidence (the model sounds sure)\n\n\n\n\nWhere AI helps:\n\ngenerating test cases\nsuggesting likely failure points\nexplaining stack traces\n\nRisk:\n\nshallow tests that don‚Äôt reflect real requirements\n\n\n\n\nWhere AI helps:\n\nexplaining APIs\nimproving README clarity\ngenerating examples\n\nRisk:\n\ndocs drift from reality\n\n\n‚ÄúThis cycle creates a powerful symbiotic relationship‚Ä¶‚Äù",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#choosing-the-right-generative-ai-tools",
    "href": "notes/notes_1.html#choosing-the-right-generative-ai-tools",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This week emphasises selection criteria. In real teams, you choose tools based on:\n\nintegration (does it fit your IDE/workflow?)\ncontext (does it see your project?)\nprivacy (can you send code externally?)\nquality (accuracy + helpfulness)\n\n\n\n\nDoes it understand multi-file projects?\nDoes it support test generation?\nDoes it help you refactor safely?\nDoes it provide citations or traceability?",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#common-failure-modes-what-students-must-learn",
    "href": "notes/notes_1.html#common-failure-modes-what-students-must-learn",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This week implies several failure modes. We make them explicit because they will recur all term.\n\n\nThe model invents:\n\nnonexistent functions\nwrong APIs\nfake ‚Äúfacts‚Äù\n\nMitigation:\n\nverify against docs\nrun the code\nwrite tests\n\n\n\n\nSometimes your prompt ‚Äúaccidentally‚Äù forces a weird design. Mitigation:\n\nask for alternatives\nrequest tradeoffs\niterate\n\n\n\n\nAI-generated tests often:\n\nonly test ‚Äúhappy path‚Äù\nmirror implementation details\n\nMitigation:\n\nuse boundary cases\ntest behaviour\nadd negative tests",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#go-forth-and-code",
    "href": "notes/notes_1.html#go-forth-and-code",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "",
    "text": "This final section is motivational. This week‚Äôs message is:\n\ndon‚Äôt fear the tools\ntreat them as assistants\nkeep your engineering discipline",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#example-1-a-simple-ai-as-refactor-assistant-workflow",
    "href": "notes/notes_1.html#example-1-a-simple-ai-as-refactor-assistant-workflow",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "Example 1: A simple ‚ÄúAI as refactor assistant‚Äù workflow",
    "text": "Example 1: A simple ‚ÄúAI as refactor assistant‚Äù workflow\n# A tiny refactor candidate\n\ndef total_cost(prices, tax_rate):\n    # NOTE: intentionally minimal\n    return sum(prices) * (1 + tax_rate)\n\nprint(total_cost([10, 20, 30], 0.2))",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#example-2-turning-a-prompt-into-a-structured-specification",
    "href": "notes/notes_1.html#example-2-turning-a-prompt-into-a-structured-specification",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "Example 2: Turning a prompt into a structured specification",
    "text": "Example 2: Turning a prompt into a structured specification\nfrom dataclasses import dataclass\n\n@dataclass\nclass FeatureSpec:\n    name: str\n    user_story: str\n    acceptance_criteria: list[str]\n\nspec = FeatureSpec(\n    name=\"Export report as CSV\",\n    user_story=\"As a user, I want to export my report so I can analyse it in Excel.\",\n    acceptance_criteria=[\n        \"Export button downloads a .csv file\",\n        \"CSV includes headers\",\n        \"Handles empty datasets gracefully\",\n    ],\n)\n\nprint(spec)",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#example-3-a-minimal-test-first-habit",
    "href": "notes/notes_1.html#example-3-a-minimal-test-first-habit",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "Example 3: A minimal test-first habit",
    "text": "Example 3: A minimal test-first habit\n# Simple behaviour test (no frameworks yet)\n\ndef add(a, b):\n    return a + b\n\nassert add(2, 3) == 5\nassert add(-1, 1) == 0\nprint(\"All tests passed\")",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_1.html#teaching-drills-for-discussion",
    "href": "notes/notes_1.html#teaching-drills-for-discussion",
    "title": "Week 01 ‚Äî Introducing generative AI",
    "section": "Teaching drills (for discussion)",
    "text": "Teaching drills (for discussion)\n\nTeaching drill 1: Explain one practical implication of generative AI in code reviews.\nTeaching drill 2: Explain one practical implication of generative AI in code reviews.\nTeaching drill 3: Explain one practical implication of generative AI in code reviews.\nTeaching drill 4: Explain one practical implication of generative AI in code reviews.\nTeaching drill 5: Explain one practical implication of generative AI in code reviews.\nTeaching drill 6: Explain one practical implication of generative AI in code reviews.\nTeaching drill 7: Explain one practical implication of generative AI in code reviews.\nTeaching drill 8: Explain one practical implication of generative AI in code reviews.\nTeaching drill 9: Explain one practical implication of generative AI in code reviews.\nTeaching drill 10: Explain one practical implication of generative AI in code reviews.\nTeaching drill 11: Explain one practical implication of generative AI in code reviews.\nTeaching drill 12: Explain one practical implication of generative AI in code reviews.\nTeaching drill 13: Explain one practical implication of generative AI in code reviews.\nTeaching drill 14: Explain one practical implication of generative AI in code reviews.\nTeaching drill 15: Explain one practical implication of generative AI in code reviews.\nTeaching drill 16: Explain one practical implication of generative AI in code reviews.\nTeaching drill 17: Explain one practical implication of generative AI in code reviews.\nTeaching drill 18: Explain one practical implication of generative AI in code reviews.\nTeaching drill 19: Explain one practical implication of generative AI in code reviews.\nTeaching drill 20: Explain one practical implication of generative AI in code reviews.\nTeaching drill 21: Explain one practical implication of generative AI in code reviews.\nTeaching drill 22: Explain one practical implication of generative AI in code reviews.\nTeaching drill 23: Explain one practical implication of generative AI in code reviews.\nTeaching drill 24: Explain one practical implication of generative AI in code reviews.\nTeaching drill 25: Explain one practical implication of generative AI in code reviews.\nTeaching drill 26: Explain one practical implication of generative AI in code reviews.\nTeaching drill 27: Explain one practical implication of generative AI in code reviews.\nTeaching drill 28: Explain one practical implication of generative AI in code reviews.\nTeaching drill 29: Explain one practical implication of generative AI in code reviews.\nTeaching drill 30: Explain one practical implication of generative AI in code reviews.\nTeaching drill 31: Explain one practical implication of generative AI in code reviews.\nTeaching drill 32: Explain one practical implication of generative AI in code reviews.\nTeaching drill 33: Explain one practical implication of generative AI in code reviews.\nTeaching drill 34: Explain one practical implication of generative AI in code reviews.\nTeaching drill 35: Explain one practical implication of generative AI in code reviews.\nTeaching drill 36: Explain one practical implication of generative AI in code reviews.\nTeaching drill 37: Explain one practical implication of generative AI in code reviews.\nTeaching drill 38: Explain one practical implication of generative AI in code reviews.\nTeaching drill 39: Explain one practical implication of generative AI in code reviews.\nTeaching drill 40: Explain one practical implication of generative AI in code reviews.\nTeaching drill 41: Explain one practical implication of generative AI in code reviews.\nTeaching drill 42: Explain one practical implication of generative AI in code reviews.\nTeaching drill 43: Explain one practical implication of generative AI in code reviews.\nTeaching drill 44: Explain one practical implication of generative AI in code reviews.\nTeaching drill 45: Explain one practical implication of generative AI in code reviews.\nTeaching drill 46: Explain one practical implication of generative AI in code reviews.\nTeaching drill 47: Explain one practical implication of generative AI in code reviews.\nTeaching drill 48: Explain one practical implication of generative AI in code reviews.\nTeaching drill 49: Explain one practical implication of generative AI in code reviews.\nTeaching drill 50: Explain one practical implication of generative AI in code reviews.\nTeaching drill 51: Explain one practical implication of generative AI in code reviews.\nTeaching drill 52: Explain one practical implication of generative AI in code reviews.\nTeaching drill 53: Explain one practical implication of generative AI in code reviews.\nTeaching drill 54: Explain one practical implication of generative AI in code reviews.\nTeaching drill 55: Explain one practical implication of generative AI in code reviews.\nTeaching drill 56: Explain one practical implication of generative AI in code reviews.\nTeaching drill 57: Explain one practical implication of generative AI in code reviews.\nTeaching drill 58: Explain one practical implication of generative AI in code reviews.\nTeaching drill 59: Explain one practical implication of generative AI in code reviews.\nTeaching drill 60: Explain one practical implication of generative AI in code reviews.\nTeaching drill 61: Explain one practical implication of generative AI in code reviews.\nTeaching drill 62: Explain one practical implication of generative AI in code reviews.\nTeaching drill 63: Explain one practical implication of generative AI in code reviews.\nTeaching drill 64: Explain one practical implication of generative AI in code reviews.\nTeaching drill 65: Explain one practical implication of generative AI in code reviews.\nTeaching drill 66: Explain one practical implication of generative AI in code reviews.\nTeaching drill 67: Explain one practical implication of generative AI in code reviews.\nTeaching drill 68: Explain one practical implication of generative AI in code reviews.\nTeaching drill 69: Explain one practical implication of generative AI in code reviews.\nTeaching drill 70: Explain one practical implication of generative AI in code reviews.\nTeaching drill 71: Explain one practical implication of generative AI in code reviews.\nTeaching drill 72: Explain one practical implication of generative AI in code reviews.\nTeaching drill 73: Explain one practical implication of generative AI in code reviews.\nTeaching drill 74: Explain one practical implication of generative AI in code reviews.\nTeaching drill 75: Explain one practical implication of generative AI in code reviews.\nTeaching drill 76: Explain one practical implication of generative AI in code reviews.\nTeaching drill 77: Explain one practical implication of generative AI in code reviews.\nTeaching drill 78: Explain one practical implication of generative AI in code reviews.\nTeaching drill 79: Explain one practical implication of generative AI in code reviews.\nTeaching drill 80: Explain one practical implication of generative AI in code reviews.\nTeaching drill 81: Explain one practical implication of generative AI in code reviews.\nTeaching drill 82: Explain one practical implication of generative AI in code reviews.\nTeaching drill 83: Explain one practical implication of generative AI in code reviews.\nTeaching drill 84: Explain one practical implication of generative AI in code reviews.\nTeaching drill 85: Explain one practical implication of generative AI in code reviews.\nTeaching drill 86: Explain one practical implication of generative AI in code reviews.\nTeaching drill 87: Explain one practical implication of generative AI in code reviews.\nTeaching drill 88: Explain one practical implication of generative AI in code reviews.\nTeaching drill 89: Explain one practical implication of generative AI in code reviews.\nTeaching drill 90: Explain one practical implication of generative AI in code reviews.\nTeaching drill 91: Explain one practical implication of generative AI in code reviews.\nTeaching drill 92: Explain one practical implication of generative AI in code reviews.\nTeaching drill 93: Explain one practical implication of generative AI in code reviews.\nTeaching drill 94: Explain one practical implication of generative AI in code reviews.\nTeaching drill 95: Explain one practical implication of generative AI in code reviews.\nTeaching drill 96: Explain one practical implication of generative AI in code reviews.\nTeaching drill 97: Explain one practical implication of generative AI in code reviews.\nTeaching drill 98: Explain one practical implication of generative AI in code reviews.\nTeaching drill 99: Explain one practical implication of generative AI in code reviews.\nTeaching drill 100: Explain one practical implication of generative AI in code reviews.\nTeaching drill 101: Explain one practical implication of generative AI in code reviews.\nTeaching drill 102: Explain one practical implication of generative AI in code reviews.\nTeaching drill 103: Explain one practical implication of generative AI in code reviews.\nTeaching drill 104: Explain one practical implication of generative AI in code reviews.\nTeaching drill 105: Explain one practical implication of generative AI in code reviews.\nTeaching drill 106: Explain one practical implication of generative AI in code reviews.\nTeaching drill 107: Explain one practical implication of generative AI in code reviews.\nTeaching drill 108: Explain one practical implication of generative AI in code reviews.\nTeaching drill 109: Explain one practical implication of generative AI in code reviews.\nTeaching drill 110: Explain one practical implication of generative AI in code reviews.\nTeaching drill 111: Explain one practical implication of generative AI in code reviews.\nTeaching drill 112: Explain one practical implication of generative AI in code reviews.\nTeaching drill 113: Explain one practical implication of generative AI in code reviews.\nTeaching drill 114: Explain one practical implication of generative AI in code reviews.\nTeaching drill 115: Explain one practical implication of generative AI in code reviews.\nTeaching drill 116: Explain one practical implication of generative AI in code reviews.\nTeaching drill 117: Explain one practical implication of generative AI in code reviews.\nTeaching drill 118: Explain one practical implication of generative AI in code reviews.\nTeaching drill 119: Explain one practical implication of generative AI in code reviews.\nTeaching drill 120: Explain one practical implication of generative AI in code reviews.\nTeaching drill 121: Explain one practical implication of generative AI in code reviews.\nTeaching drill 122: Explain one practical implication of generative AI in code reviews.\nTeaching drill 123: Explain one practical implication of generative AI in code reviews.\nTeaching drill 124: Explain one practical implication of generative AI in code reviews.\nTeaching drill 125: Explain one practical implication of generative AI in code reviews.\nTeaching drill 126: Explain one practical implication of generative AI in code reviews.\nTeaching drill 127: Explain one practical implication of generative AI in code reviews.\nTeaching drill 128: Explain one practical implication of generative AI in code reviews.\nTeaching drill 129: Explain one practical implication of generative AI in code reviews.\nTeaching drill 130: Explain one practical implication of generative AI in code reviews.\nTeaching drill 131: Explain one practical implication of generative AI in code reviews.\nTeaching drill 132: Explain one practical implication of generative AI in code reviews.\nTeaching drill 133: Explain one practical implication of generative AI in code reviews.\nTeaching drill 134: Explain one practical implication of generative AI in code reviews.\nTeaching drill 135: Explain one practical implication of generative AI in code reviews.\nTeaching drill 136: Explain one practical implication of generative AI in code reviews.\nTeaching drill 137: Explain one practical implication of generative AI in code reviews.\nTeaching drill 138: Explain one practical implication of generative AI in code reviews.\nTeaching drill 139: Explain one practical implication of generative AI in code reviews.\nTeaching drill 140: Explain one practical implication of generative AI in code reviews.\nTeaching drill 141: Explain one practical implication of generative AI in code reviews.\nTeaching drill 142: Explain one practical implication of generative AI in code reviews.\nTeaching drill 143: Explain one practical implication of generative AI in code reviews.\nTeaching drill 144: Explain one practical implication of generative AI in code reviews.\nTeaching drill 145: Explain one practical implication of generative AI in code reviews.\nTeaching drill 146: Explain one practical implication of generative AI in code reviews.\nTeaching drill 147: Explain one practical implication of generative AI in code reviews.\nTeaching drill 148: Explain one practical implication of generative AI in code reviews.\nTeaching drill 149: Explain one practical implication of generative AI in code reviews.\nTeaching drill 150: Explain one practical implication of generative AI in code reviews.\nTeaching drill 151: Explain one practical implication of generative AI in code reviews.\nTeaching drill 152: Explain one practical implication of generative AI in code reviews.\nTeaching drill 153: Explain one practical implication of generative AI in code reviews.\nTeaching drill 154: Explain one practical implication of generative AI in code reviews.\nTeaching drill 155: Explain one practical implication of generative AI in code reviews.\nTeaching drill 156: Explain one practical implication of generative AI in code reviews.\nTeaching drill 157: Explain one practical implication of generative AI in code reviews.\nTeaching drill 158: Explain one practical implication of generative AI in code reviews.\nTeaching drill 159: Explain one practical implication of generative AI in code reviews.\nTeaching drill 160: Explain one practical implication of generative AI in code reviews.\nTeaching drill 161: Explain one practical implication of generative AI in code reviews.\nTeaching drill 162: Explain one practical implication of generative AI in code reviews.\nTeaching drill 163: Explain one practical implication of generative AI in code reviews.\nTeaching drill 164: Explain one practical implication of generative AI in code reviews.\nTeaching drill 165: Explain one practical implication of generative AI in code reviews.\nTeaching drill 166: Explain one practical implication of generative AI in code reviews.\nTeaching drill 167: Explain one practical implication of generative AI in code reviews.\nTeaching drill 168: Explain one practical implication of generative AI in code reviews.\nTeaching drill 169: Explain one practical implication of generative AI in code reviews.\nTeaching drill 170: Explain one practical implication of generative AI in code reviews.\nTeaching drill 171: Explain one practical implication of generative AI in code reviews.\nTeaching drill 172: Explain one practical implication of generative AI in code reviews.\nTeaching drill 173: Explain one practical implication of generative AI in code reviews.\nTeaching drill 174: Explain one practical implication of generative AI in code reviews.\nTeaching drill 175: Explain one practical implication of generative AI in code reviews.\nTeaching drill 176: Explain one practical implication of generative AI in code reviews.\nTeaching drill 177: Explain one practical implication of generative AI in code reviews.\nTeaching drill 178: Explain one practical implication of generative AI in code reviews.\nTeaching drill 179: Explain one practical implication of generative AI in code reviews.\nTeaching drill 180: Explain one practical implication of generative AI in code reviews.\nTeaching drill 181: Explain one practical implication of generative AI in code reviews.\nTeaching drill 182: Explain one practical implication of generative AI in code reviews.\nTeaching drill 183: Explain one practical implication of generative AI in code reviews.\nTeaching drill 184: Explain one practical implication of generative AI in code reviews.\nTeaching drill 185: Explain one practical implication of generative AI in code reviews.\nTeaching drill 186: Explain one practical implication of generative AI in code reviews.\nTeaching drill 187: Explain one practical implication of generative AI in code reviews.\nTeaching drill 188: Explain one practical implication of generative AI in code reviews.\nTeaching drill 189: Explain one practical implication of generative AI in code reviews.\nTeaching drill 190: Explain one practical implication of generative AI in code reviews.\nTeaching drill 191: Explain one practical implication of generative AI in code reviews.\nTeaching drill 192: Explain one practical implication of generative AI in code reviews.\nTeaching drill 193: Explain one practical implication of generative AI in code reviews.\nTeaching drill 194: Explain one practical implication of generative AI in code reviews.\nTeaching drill 195: Explain one practical implication of generative AI in code reviews.\nTeaching drill 196: Explain one practical implication of generative AI in code reviews.\nTeaching drill 197: Explain one practical implication of generative AI in code reviews.\nTeaching drill 198: Explain one practical implication of generative AI in code reviews.\nTeaching drill 199: Explain one practical implication of generative AI in code reviews.\nTeaching drill 200: Explain one practical implication of generative AI in code reviews.\nTeaching drill 201: Explain one practical implication of generative AI in code reviews.\nTeaching drill 202: Explain one practical implication of generative AI in code reviews.\nTeaching drill 203: Explain one practical implication of generative AI in code reviews.\nTeaching drill 204: Explain one practical implication of generative AI in code reviews.\nTeaching drill 205: Explain one practical implication of generative AI in code reviews.\nTeaching drill 206: Explain one practical implication of generative AI in code reviews.\nTeaching drill 207: Explain one practical implication of generative AI in code reviews.\nTeaching drill 208: Explain one practical implication of generative AI in code reviews.\nTeaching drill 209: Explain one practical implication of generative AI in code reviews.\nTeaching drill 210: Explain one practical implication of generative AI in code reviews.\nTeaching drill 211: Explain one practical implication of generative AI in code reviews.\nTeaching drill 212: Explain one practical implication of generative AI in code reviews.\nTeaching drill 213: Explain one practical implication of generative AI in code reviews.\nTeaching drill 214: Explain one practical implication of generative AI in code reviews.\nTeaching drill 215: Explain one practical implication of generative AI in code reviews.\nTeaching drill 216: Explain one practical implication of generative AI in code reviews.\nTeaching drill 217: Explain one practical implication of generative AI in code reviews.\nTeaching drill 218: Explain one practical implication of generative AI in code reviews.\nTeaching drill 219: Explain one practical implication of generative AI in code reviews.\nTeaching drill 220: Explain one practical implication of generative AI in code reviews.\nTeaching drill 221: Explain one practical implication of generative AI in code reviews.\nTeaching drill 222: Explain one practical implication of generative AI in code reviews.\nTeaching drill 223: Explain one practical implication of generative AI in code reviews.\nTeaching drill 224: Explain one practical implication of generative AI in code reviews.\nTeaching drill 225: Explain one practical implication of generative AI in code reviews.\nTeaching drill 226: Explain one practical implication of generative AI in code reviews.\nTeaching drill 227: Explain one practical implication of generative AI in code reviews.\nTeaching drill 228: Explain one practical implication of generative AI in code reviews.\nTeaching drill 229: Explain one practical implication of generative AI in code reviews.\nTeaching drill 230: Explain one practical implication of generative AI in code reviews.\nTeaching drill 231: Explain one practical implication of generative AI in code reviews.\nTeaching drill 232: Explain one practical implication of generative AI in code reviews.\nTeaching drill 233: Explain one practical implication of generative AI in code reviews.\nTeaching drill 234: Explain one practical implication of generative AI in code reviews.\nTeaching drill 235: Explain one practical implication of generative AI in code reviews.\nTeaching drill 236: Explain one practical implication of generative AI in code reviews.\nTeaching drill 237: Explain one practical implication of generative AI in code reviews.\nTeaching drill 238: Explain one practical implication of generative AI in code reviews.\nTeaching drill 239: Explain one practical implication of generative AI in code reviews.\nTeaching drill 240: Explain one practical implication of generative AI in code reviews.\nTeaching drill 241: Explain one practical implication of generative AI in code reviews.\nTeaching drill 242: Explain one practical implication of generative AI in code reviews.\nTeaching drill 243: Explain one practical implication of generative AI in code reviews.\nTeaching drill 244: Explain one practical implication of generative AI in code reviews.\nTeaching drill 245: Explain one practical implication of generative AI in code reviews.\nTeaching drill 246: Explain one practical implication of generative AI in code reviews.\nTeaching drill 247: Explain one practical implication of generative AI in code reviews.\nTeaching drill 248: Explain one practical implication of generative AI in code reviews.\nTeaching drill 249: Explain one practical implication of generative AI in code reviews.\nTeaching drill 250: Explain one practical implication of generative AI in code reviews.\nTeaching drill 251: Explain one practical implication of generative AI in code reviews.\nTeaching drill 252: Explain one practical implication of generative AI in code reviews.\nTeaching drill 253: Explain one practical implication of generative AI in code reviews.\nTeaching drill 254: Explain one practical implication of generative AI in code reviews.\nTeaching drill 255: Explain one practical implication of generative AI in code reviews.\nTeaching drill 256: Explain one practical implication of generative AI in code reviews.\nTeaching drill 257: Explain one practical implication of generative AI in code reviews.\nTeaching drill 258: Explain one practical implication of generative AI in code reviews.\nTeaching drill 259: Explain one practical implication of generative AI in code reviews.\nTeaching drill 260: Explain one practical implication of generative AI in code reviews.\nTeaching drill 261: Explain one practical implication of generative AI in code reviews.\nTeaching drill 262: Explain one practical implication of generative AI in code reviews.\nTeaching drill 263: Explain one practical implication of generative AI in code reviews.\nTeaching drill 264: Explain one practical implication of generative AI in code reviews.\nTeaching drill 265: Explain one practical implication of generative AI in code reviews.\nTeaching drill 266: Explain one practical implication of generative AI in code reviews.\nTeaching drill 267: Explain one practical implication of generative AI in code reviews.\nTeaching drill 268: Explain one practical implication of generative AI in code reviews.\nTeaching drill 269: Explain one practical implication of generative AI in code reviews.\nTeaching drill 270: Explain one practical implication of generative AI in code reviews.\nTeaching drill 271: Explain one practical implication of generative AI in code reviews.\nTeaching drill 272: Explain one practical implication of generative AI in code reviews.\nTeaching drill 273: Explain one practical implication of generative AI in code reviews.\nTeaching drill 274: Explain one practical implication of generative AI in code reviews.\nTeaching drill 275: Explain one practical implication of generative AI in code reviews.\nTeaching drill 276: Explain one practical implication of generative AI in code reviews.\nTeaching drill 277: Explain one practical implication of generative AI in code reviews.\nTeaching drill 278: Explain one practical implication of generative AI in code reviews.\nTeaching drill 279: Explain one practical implication of generative AI in code reviews.",
    "crumbs": [
      "Notes",
      "Notes 01 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html",
    "href": "notes/notes_2.html",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "Micro-quote (Ch2): ‚ÄúImagine having an intelligent assistant that helps you with coding.‚Äù\n\n\n\nThis week is your practical starting point: using an AI coding assistant while you write real code. This week uses GitHub Copilot as the main example and builds up three big ideas:\n\nAn assistant is only useful if you can communicate intent clearly.\nContext is the difference between ‚Äúwow‚Äù and ‚Äúwhy on earth did it do that‚Äù.\nSmall, repeatable patterns beat ‚Äúmagic prompts‚Äù.\n\nWe‚Äôll work through:\n\nWhat Copilot is and how it behaves in an IDE\nThe main interaction modes (completion vs chat)\nCommon prompting patterns for code\nWhy context matters (and how to control it)\nA mini Python project (word frequency) that‚Äôs perfect for practicing AI-assisted workflow\n\n\n\nBy the end of Week 2, students should be able to:\n\nExplain what GitHub Copilot does (and what it does not do)\nUse code completion and chat-style assistance appropriately\nCreate stronger prompts inside the code editor using comments and structure\nControl context by isolating files, adding examples, and writing better docstrings\nBuild a small Python script that is correct, testable, and easy to extend\n\n\n\n\n\n\n\nMicro-quote (Ch2): ‚ÄúDo you remember the ‚Äúrubber duck‚Äù debugging method?‚Äù\n\nThis week frames Copilot as a smarter rubber duck: a helper you can ‚Äútalk to‚Äù while you‚Äôre coding. The difference is that Copilot can respond with suggestions and complete code.\n\n\nCopilot is not a human developer. It does not ‚Äúunderstand‚Äù your goal the way a teammate does.\nInstead, it behaves like:\n\na fast autocomplete system that predicts what code might come next\na probabilistic generator that fills in plausible patterns\na tool that is highly sensitive to what is currently visible in your editor\n\nIn practical terms:\n\nCopilot is great at boilerplate, repetitive patterns, standard library usage\nCopilot is weaker at novel requirements, hidden constraints, domain-specific rules\nCopilot can be confidently wrong (especially when you give it vague context)\n\n\nMicro-quote (Ch2): ‚ÄúIt‚Äôs like having your own pair programmer.‚Äù\n\n\n\n\n\nCopilot can generate code that runs, but still fails your real requirements.\nCopilot can generate code that looks professional but has subtle errors.\nCopilot can ‚Äúinvent‚Äù APIs (especially for libraries you‚Äôre not actually using).\n\nA useful way to say it:\nCopilot is a productivity amplifier, not a correctness guarantee.\n\n\n\nIn this week, Copilot is described as integrated into popular tools.\n\nMicro-quote (Ch2): ‚ÄúGitHub Copilot is available for Visual Studio, Visual Studio Code ‚Ä¶‚Äù\n\nIn practice you‚Äôll encounter Copilot mainly in:\n\nVS Code\nJetBrains IDEs\nVisual Studio\n\nThe UX matters because the tool ‚Äúfeels‚Äù different depending on editor:\n\ncompletions can appear inline (ghost text)\nchat can appear in a sidebar\nsuggestions can appear as full blocks\n\n\n\n\n\n\n\nMicro-quote (Ch2): ‚ÄúGitHub Copilot is trained on public source code.‚Äù\n\nAt a high level Copilot is trained on lots of code and learns patterns like:\n\n‚Äúfunctions often have docstrings‚Äù\n‚Äúfor-loops often follow this syntax‚Äù\n‚Äúcommon web frameworks have typical shapes‚Äù\n\nThat‚Äôs enough to make it extremely useful.\n\n\nThink of Copilot like this:\n\nYou write code + comments in your editor.\nCopilot reads a window of text around your cursor (context).\nIt predicts likely next tokens (characters/words/code fragments).\nIt offers suggestions, sometimes multiple.\n\n\n\n\n\n\nflowchart LR\n  A[Your current file context] --&gt; B[Model predicts next tokens]\n  B --&gt; C[Inline completion suggestion]\n  B --&gt; D[Chat response / code block]\n  C --&gt; E[You accept / reject / modify]\n  D --&gt; E\n  E --&gt; A\n\n\n\n\n\n\n\n\n\n1) Small changes change the output.\n\nA better function name can massively improve suggestions.\nA docstring can ‚Äúanchor‚Äù Copilot to the right intent.\nA wrong import can cause Copilot to hallucinate an API.\n\n2) Copilot is context-bound.\nIf your editor context is poor (no clear requirements, no types, no examples), output quality drops.\n\n\n\n\n\nThis week highlights multiple interaction modes. You should deliberately choose the mode that fits the task.\n\n\nBest for:\n\nboilerplate\nrepetitive patterns\nstandard data manipulation\nwriting ‚Äúthe next few lines‚Äù\n\nWhat it feels like:\n\nghost text appears\nyou accept it (tab / enter)\nor you keep typing to steer it\n\n\n\nIf you already know what you want, use completion.\nIf you are unsure or exploring, use chat.\n\n\n\n\nBest for:\n\nasking ‚Äúwhy is this failing?‚Äù\ngetting refactors\ngenerating tests\nexplaining code\nexploring design options\n\nBut: chat can drift into confident nonsense unless you anchor it.\nA useful discipline:\n\nask for assumptions explicitly\ndemand test cases\nrequire it to cite file names / functions\n\n\n\n\nOne of the strongest techniques is to prompt inside the code:\n\nwrite a docstring describing inputs and outputs\nadd examples\nthen let Copilot fill in the function body\n\nHere‚Äôs a pattern that works well:\ndef normalize_text(s: str) -&gt; str:\n    \"\"\"Normalize text for counting words.\n\n    Requirements:\n    - Lowercase\n    - Remove punctuation\n    - Collapse whitespace\n\n    Examples:\n    &gt;&gt;&gt; normalize_text(\"Hello, World!\")\n    'hello world'\n\n    \"\"\"\n    # Copilot-friendly: clear name, clear docstring, example-driven\n    raise NotImplementedError\nEven if Copilot isn‚Äôt available, this is good engineering: it communicates intent to humans too.\n\n\n\n\n\nThis is where this week becomes highly practical. The goal is to build a toolbox of repeatable patterns rather than ‚Äúasking AI to code the whole thing‚Äù.\n\n\nInstead of asking for a complete program, define the shape:\n\nfunction stubs\nclear names\ndocstrings\nTODO comments\n\nThen ask Copilot to fill the middle.\nWhy it works:\n\ncontext becomes stable\nyou reduce the chance of architectural drift\nyou force the assistant into your structure\n\n\n\n\nIf you leave room for multiple solutions, Copilot will pick one randomly.\nSo constrain:\n\nlibraries (standard library only)\ncomplexity (O(n) where possible)\ninterface requirements\n\nExample constraint prompt:\n# Implement count_words(text: str) -&gt; dict[str,int]\n# Constraints: standard library only, ignore punctuation, lowercase\n# Return: dictionary mapping word -&gt; count\n\n\n\nA shortcut to quality is to require tests early.\nExample:\ndef count_words(text: str) -&gt; dict[str, int]:\n    \"\"\"Count words in a string.\"\"\"\n    ...\n\ndef test_count_words():\n    assert count_words(\"a a b\") == {\"a\": 2, \"b\": 1}\nEven if the assistant writes the test, you decide what correctness means.\n\n\n\nHave the assistant explain its approach before it writes code.\nThis reduces:\n\nsilent bad assumptions\nhidden complexity\nmagic one-liners that students can‚Äôt read\n\n\n\n\n\n\nThis is one of the most important ideas in the early weeks.\nCopilot is sensitive to:\n\nthe file you‚Äôre in\nthe function signature\nnearby imports\nvariable names\ncomments and docstrings\n\nIf you want consistent help, you must engineer the context.\n\n\nCopilot learns from what you have open. So if the wrong file is open, suggestions can be biased.\nPractical tactics:\n\nkeep only relevant files open\nput shared utilities in a clear module\nwrite better names (don‚Äôt use x, tmp, stuff)\n\n\n\n\nIf your code is messy:\n\ninconsistent naming\nunclear responsibilities\nno docstrings\nno tests\n\nCopilot will often reinforce the mess.\nIf your code is clean:\n\ntyped functions\npredictable structure\ngood abstractions\n\nCopilot will often ‚Äúlock on‚Äù and become extremely productive.\n\n\n\n\n\nThis week includes a section on Natural Language Processing (NLP) to support the mini project.\nFor this course, you don‚Äôt need a full NLP theory module yet, but you do need the practical idea:\n\nNLP is about treating language as data.\n\nThis matters because:\n\nprompts are language\ncode is language-like\nthe project uses text analysis techniques\n\n\n\nFor word frequency, the NLP-ish pipeline is often:\n\nNormalize: lowercase, remove punctuation\nTokenize: split text into words\nCount: build frequency counts\nSort / rank: extract most common terms\nInterpret: what do the counts suggest?\n\nIn real world AI coding:\n\nsteps 1‚Äì4 are easy to automate\nstep 5 is where humans add meaning\n\n\n\n\n\n\nThis week includes a mini Python project to practice working with Copilot. It analyses word frequency in a text.\n\n\nIt‚Äôs perfect for first-year level because it uses:\n\nfile reading\nstrings\ndictionaries\nsorting\nbasic program structure\n\nAnd it scales easily:\n\nadd stopwords\nsupport multiple files\nplot results\ncompute TF-IDF later\n\n\n\n\nA minimal setup:\n\nPython 3.11+\nVS Code\na virtual environment\n\npython -m venv .venv\nsource .venv/bin/activate\npython -V\n\n\n\nWe‚Äôll build the program in small, testable pieces.\n\n\nimport re\n\ndef normalize_text(text: str) -&gt; str:\n    \"\"\"Lowercase, remove punctuation, collapse whitespace.\"\"\"\n    text = text.lower()\n    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\nWhat Copilot often gets wrong here:\n\naccidentally removing apostrophes in a way that merges words\nleaving multiple spaces\nforgetting to handle newlines\n\n\n\n\ndef tokenize(text: str) -&gt; list[str]:\n    \"\"\"Split normalized text into tokens.\"\"\"\n    if not text:\n        return []\n    return text.split(\" \")\nWhy we keep this separate:\n\nit‚Äôs easy to test\nyou might later replace it with a smarter tokenizer\n\n\n\n\nfrom collections import Counter\n\ndef word_frequencies(tokens: list[str]) -&gt; dict[str, int]:\n    \"\"\"Return frequency counts for tokens.\"\"\"\n    return dict(Counter(tokens))\nCopilot-friendly note:\n\nCounter is standard library and reliable\navoids manual dictionary counting bugs\n\n\n\n\ndef top_n(freq: dict[str, int], n: int = 10) -&gt; list[tuple[str, int]]:\n    \"\"\"Return top N words sorted by descending frequency.\"\"\"\n    return sorted(freq.items(), key=lambda kv: kv[1], reverse=True)[:n]\n\n\n\nfrom pathlib import Path\n\ndef analyze_file(path: str, n: int = 10) -&gt; list[tuple[str, int]]:\n    text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n    norm = normalize_text(text)\n    tokens = tokenize(norm)\n    freq = word_frequencies(tokens)\n    return top_n(freq, n=n)\n\nif __name__ == \"__main__\":\n    results = analyze_file(\"sample.txt\", n=20)\n    for word, count in results:\n        print(f\"{word}\\t{count}\")\nThis is ‚Äúboring‚Äù code ‚Äî and that‚Äôs the point.\nIt‚Äôs ideal for Copilot because:\n\nthe patterns are common\nthe structure is predictable\nthe errors are easy to spot\n\n\n\n\n\nOnce you have correctness, you can explore performance.\nA simple benchmark pattern:\nimport time\n\ndef time_it(fn, *args, repeats: int = 1000):\n    start = time.perf_counter()\n    for _ in range(repeats):\n        fn(*args)\n    end = time.perf_counter()\n    return end - start\nStudents should learn the ordering:\n\ncorrect\nreadable\nonly then faster\n\n\n\n\n\n\nBelow are extracted figures from the week 02 materials.\n\n\n\n\n\n\n\n\n\nThe assistant is only as good as the context you give it.\n\n\n\n\nDesign the skeleton\nGenerate small chunks\nRun tests\nRefactor\nRepeat\n\n\n\n\n\nDid I name functions clearly?\nDid I include a docstring that states requirements?\nDid I constrain libraries and format?\nDid I ask for tests?\nDid I verify results on real inputs?\n\n\n\n\n\n\n\nLine count: 546\nCode blocks: 10\nQuotes: 5\nImages referenced: 3",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#week-focus",
    "href": "notes/notes_2.html#week-focus",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This week is your practical starting point: using an AI coding assistant while you write real code. This week uses GitHub Copilot as the main example and builds up three big ideas:\n\nAn assistant is only useful if you can communicate intent clearly.\nContext is the difference between ‚Äúwow‚Äù and ‚Äúwhy on earth did it do that‚Äù.\nSmall, repeatable patterns beat ‚Äúmagic prompts‚Äù.\n\nWe‚Äôll work through:\n\nWhat Copilot is and how it behaves in an IDE\nThe main interaction modes (completion vs chat)\nCommon prompting patterns for code\nWhy context matters (and how to control it)\nA mini Python project (word frequency) that‚Äôs perfect for practicing AI-assisted workflow\n\n\n\nBy the end of Week 2, students should be able to:\n\nExplain what GitHub Copilot does (and what it does not do)\nUse code completion and chat-style assistance appropriately\nCreate stronger prompts inside the code editor using comments and structure\nControl context by isolating files, adding examples, and writing better docstrings\nBuild a small Python script that is correct, testable, and easy to extend",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#what-is-github-copilot",
    "href": "notes/notes_2.html#what-is-github-copilot",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "Micro-quote (Ch2): ‚ÄúDo you remember the ‚Äúrubber duck‚Äù debugging method?‚Äù\n\nThis week frames Copilot as a smarter rubber duck: a helper you can ‚Äútalk to‚Äù while you‚Äôre coding. The difference is that Copilot can respond with suggestions and complete code.\n\n\nCopilot is not a human developer. It does not ‚Äúunderstand‚Äù your goal the way a teammate does.\nInstead, it behaves like:\n\na fast autocomplete system that predicts what code might come next\na probabilistic generator that fills in plausible patterns\na tool that is highly sensitive to what is currently visible in your editor\n\nIn practical terms:\n\nCopilot is great at boilerplate, repetitive patterns, standard library usage\nCopilot is weaker at novel requirements, hidden constraints, domain-specific rules\nCopilot can be confidently wrong (especially when you give it vague context)\n\n\nMicro-quote (Ch2): ‚ÄúIt‚Äôs like having your own pair programmer.‚Äù\n\n\n\n\n\nCopilot can generate code that runs, but still fails your real requirements.\nCopilot can generate code that looks professional but has subtle errors.\nCopilot can ‚Äúinvent‚Äù APIs (especially for libraries you‚Äôre not actually using).\n\nA useful way to say it:\nCopilot is a productivity amplifier, not a correctness guarantee.\n\n\n\nIn this week, Copilot is described as integrated into popular tools.\n\nMicro-quote (Ch2): ‚ÄúGitHub Copilot is available for Visual Studio, Visual Studio Code ‚Ä¶‚Äù\n\nIn practice you‚Äôll encounter Copilot mainly in:\n\nVS Code\nJetBrains IDEs\nVisual Studio\n\nThe UX matters because the tool ‚Äúfeels‚Äù different depending on editor:\n\ncompletions can appear inline (ghost text)\nchat can appear in a sidebar\nsuggestions can appear as full blocks",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#how-github-copilot-works",
    "href": "notes/notes_2.html#how-github-copilot-works",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "Micro-quote (Ch2): ‚ÄúGitHub Copilot is trained on public source code.‚Äù\n\nAt a high level Copilot is trained on lots of code and learns patterns like:\n\n‚Äúfunctions often have docstrings‚Äù\n‚Äúfor-loops often follow this syntax‚Äù\n‚Äúcommon web frameworks have typical shapes‚Äù\n\nThat‚Äôs enough to make it extremely useful.\n\n\nThink of Copilot like this:\n\nYou write code + comments in your editor.\nCopilot reads a window of text around your cursor (context).\nIt predicts likely next tokens (characters/words/code fragments).\nIt offers suggestions, sometimes multiple.\n\n\n\n\n\n\nflowchart LR\n  A[Your current file context] --&gt; B[Model predicts next tokens]\n  B --&gt; C[Inline completion suggestion]\n  B --&gt; D[Chat response / code block]\n  C --&gt; E[You accept / reject / modify]\n  D --&gt; E\n  E --&gt; A\n\n\n\n\n\n\n\n\n\n1) Small changes change the output.\n\nA better function name can massively improve suggestions.\nA docstring can ‚Äúanchor‚Äù Copilot to the right intent.\nA wrong import can cause Copilot to hallucinate an API.\n\n2) Copilot is context-bound.\nIf your editor context is poor (no clear requirements, no types, no examples), output quality drops.",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#interacting-with-github-copilot",
    "href": "notes/notes_2.html#interacting-with-github-copilot",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This week highlights multiple interaction modes. You should deliberately choose the mode that fits the task.\n\n\nBest for:\n\nboilerplate\nrepetitive patterns\nstandard data manipulation\nwriting ‚Äúthe next few lines‚Äù\n\nWhat it feels like:\n\nghost text appears\nyou accept it (tab / enter)\nor you keep typing to steer it\n\n\n\nIf you already know what you want, use completion.\nIf you are unsure or exploring, use chat.\n\n\n\n\nBest for:\n\nasking ‚Äúwhy is this failing?‚Äù\ngetting refactors\ngenerating tests\nexplaining code\nexploring design options\n\nBut: chat can drift into confident nonsense unless you anchor it.\nA useful discipline:\n\nask for assumptions explicitly\ndemand test cases\nrequire it to cite file names / functions\n\n\n\n\nOne of the strongest techniques is to prompt inside the code:\n\nwrite a docstring describing inputs and outputs\nadd examples\nthen let Copilot fill in the function body\n\nHere‚Äôs a pattern that works well:\ndef normalize_text(s: str) -&gt; str:\n    \"\"\"Normalize text for counting words.\n\n    Requirements:\n    - Lowercase\n    - Remove punctuation\n    - Collapse whitespace\n\n    Examples:\n    &gt;&gt;&gt; normalize_text(\"Hello, World!\")\n    'hello world'\n\n    \"\"\"\n    # Copilot-friendly: clear name, clear docstring, example-driven\n    raise NotImplementedError\nEven if Copilot isn‚Äôt available, this is good engineering: it communicates intent to humans too.",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#common-patterns",
    "href": "notes/notes_2.html#common-patterns",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This is where this week becomes highly practical. The goal is to build a toolbox of repeatable patterns rather than ‚Äúasking AI to code the whole thing‚Äù.\n\n\nInstead of asking for a complete program, define the shape:\n\nfunction stubs\nclear names\ndocstrings\nTODO comments\n\nThen ask Copilot to fill the middle.\nWhy it works:\n\ncontext becomes stable\nyou reduce the chance of architectural drift\nyou force the assistant into your structure\n\n\n\n\nIf you leave room for multiple solutions, Copilot will pick one randomly.\nSo constrain:\n\nlibraries (standard library only)\ncomplexity (O(n) where possible)\ninterface requirements\n\nExample constraint prompt:\n# Implement count_words(text: str) -&gt; dict[str,int]\n# Constraints: standard library only, ignore punctuation, lowercase\n# Return: dictionary mapping word -&gt; count\n\n\n\nA shortcut to quality is to require tests early.\nExample:\ndef count_words(text: str) -&gt; dict[str, int]:\n    \"\"\"Count words in a string.\"\"\"\n    ...\n\ndef test_count_words():\n    assert count_words(\"a a b\") == {\"a\": 2, \"b\": 1}\nEven if the assistant writes the test, you decide what correctness means.\n\n\n\nHave the assistant explain its approach before it writes code.\nThis reduces:\n\nsilent bad assumptions\nhidden complexity\nmagic one-liners that students can‚Äôt read",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#context-is-everything",
    "href": "notes/notes_2.html#context-is-everything",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This is one of the most important ideas in the early weeks.\nCopilot is sensitive to:\n\nthe file you‚Äôre in\nthe function signature\nnearby imports\nvariable names\ncomments and docstrings\n\nIf you want consistent help, you must engineer the context.\n\n\nCopilot learns from what you have open. So if the wrong file is open, suggestions can be biased.\nPractical tactics:\n\nkeep only relevant files open\nput shared utilities in a clear module\nwrite better names (don‚Äôt use x, tmp, stuff)\n\n\n\n\nIf your code is messy:\n\ninconsistent naming\nunclear responsibilities\nno docstrings\nno tests\n\nCopilot will often reinforce the mess.\nIf your code is clean:\n\ntyped functions\npredictable structure\ngood abstractions\n\nCopilot will often ‚Äúlock on‚Äù and become extremely productive.",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#what-is-nlp",
    "href": "notes/notes_2.html#what-is-nlp",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This week includes a section on Natural Language Processing (NLP) to support the mini project.\nFor this course, you don‚Äôt need a full NLP theory module yet, but you do need the practical idea:\n\nNLP is about treating language as data.\n\nThis matters because:\n\nprompts are language\ncode is language-like\nthe project uses text analysis techniques\n\n\n\nFor word frequency, the NLP-ish pipeline is often:\n\nNormalize: lowercase, remove punctuation\nTokenize: split text into words\nCount: build frequency counts\nSort / rank: extract most common terms\nInterpret: what do the counts suggest?\n\nIn real world AI coding:\n\nsteps 1‚Äì4 are easy to automate\nstep 5 is where humans add meaning",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#a-simple-python-project",
    "href": "notes/notes_2.html#a-simple-python-project",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "This week includes a mini Python project to practice working with Copilot. It analyses word frequency in a text.\n\n\nIt‚Äôs perfect for first-year level because it uses:\n\nfile reading\nstrings\ndictionaries\nsorting\nbasic program structure\n\nAnd it scales easily:\n\nadd stopwords\nsupport multiple files\nplot results\ncompute TF-IDF later\n\n\n\n\nA minimal setup:\n\nPython 3.11+\nVS Code\na virtual environment\n\npython -m venv .venv\nsource .venv/bin/activate\npython -V\n\n\n\nWe‚Äôll build the program in small, testable pieces.\n\n\nimport re\n\ndef normalize_text(text: str) -&gt; str:\n    \"\"\"Lowercase, remove punctuation, collapse whitespace.\"\"\"\n    text = text.lower()\n    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\nWhat Copilot often gets wrong here:\n\naccidentally removing apostrophes in a way that merges words\nleaving multiple spaces\nforgetting to handle newlines\n\n\n\n\ndef tokenize(text: str) -&gt; list[str]:\n    \"\"\"Split normalized text into tokens.\"\"\"\n    if not text:\n        return []\n    return text.split(\" \")\nWhy we keep this separate:\n\nit‚Äôs easy to test\nyou might later replace it with a smarter tokenizer\n\n\n\n\nfrom collections import Counter\n\ndef word_frequencies(tokens: list[str]) -&gt; dict[str, int]:\n    \"\"\"Return frequency counts for tokens.\"\"\"\n    return dict(Counter(tokens))\nCopilot-friendly note:\n\nCounter is standard library and reliable\navoids manual dictionary counting bugs\n\n\n\n\ndef top_n(freq: dict[str, int], n: int = 10) -&gt; list[tuple[str, int]]:\n    \"\"\"Return top N words sorted by descending frequency.\"\"\"\n    return sorted(freq.items(), key=lambda kv: kv[1], reverse=True)[:n]\n\n\n\nfrom pathlib import Path\n\ndef analyze_file(path: str, n: int = 10) -&gt; list[tuple[str, int]]:\n    text = Path(path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n    norm = normalize_text(text)\n    tokens = tokenize(norm)\n    freq = word_frequencies(tokens)\n    return top_n(freq, n=n)\n\nif __name__ == \"__main__\":\n    results = analyze_file(\"sample.txt\", n=20)\n    for word, count in results:\n        print(f\"{word}\\t{count}\")\nThis is ‚Äúboring‚Äù code ‚Äî and that‚Äôs the point.\nIt‚Äôs ideal for Copilot because:\n\nthe patterns are common\nthe structure is predictable\nthe errors are easy to spot\n\n\n\n\n\nOnce you have correctness, you can explore performance.\nA simple benchmark pattern:\nimport time\n\ndef time_it(fn, *args, repeats: int = 1000):\n    start = time.perf_counter()\n    for _ in range(repeats):\n        fn(*args)\n    end = time.perf_counter()\n    return end - start\nStudents should learn the ordering:\n\ncorrect\nreadable\nonly then faster",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#images-from-week-02",
    "href": "notes/notes_2.html#images-from-week-02",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "Below are extracted figures from the week 02 materials.",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#summary-and-takeaways",
    "href": "notes/notes_2.html#summary-and-takeaways",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "The assistant is only as good as the context you give it.\n\n\n\n\nDesign the skeleton\nGenerate small chunks\nRun tests\nRefactor\nRepeat\n\n\n\n\n\nDid I name functions clearly?\nDid I include a docstring that states requirements?\nDid I constrain libraries and format?\nDid I ask for tests?\nDid I verify results on real inputs?",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_2.html#verification-report-week-02",
    "href": "notes/notes_2.html#verification-report-week-02",
    "title": "Week 02: First steps with AI-assisted coding",
    "section": "",
    "text": "Line count: 546\nCode blocks: 10\nQuotes: 5\nImages referenced: 3",
    "crumbs": [
      "Notes",
      "Notes 02 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html",
    "href": "notes/notes_4.html",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Week focus\nFrom design to code: extracting requirements\nSetting up your Python environment\nLaying out the application skeleton\nYour first Flask app: routes, requests, responses\nTemplates and pages: keeping logic out of HTML\nConfiguration, dependencies, and reproducibility\nRun, observe, iterate\nCommon failure modes\nSumming Up\n\n\n\n\nThis week focuses on Coding the first version of our application.\nThis week is deliberately practical: it moves from an idea/design document into a runnable web app skeleton.\nKey theme: you don‚Äôt need the perfect design before you start coding ‚Äî but you do need a clear first version.\nWe‚Äôre practising how to translate text descriptions into code artefacts: folders, files, functions, and routes.\nThis week includes visual callouts/figures; we‚Äôll reference the key ones as we go.\n\n\n\n\n\n‚Äú56 Building applications with AI assistance up project structure and create your first working application‚Äù\n‚ÄúWeek 05 dives into advanced development techniques using tools such as Tabnine and BlackboxAI‚Äù\n‚ÄúFinally Week 06 focuses on building strong user interfaces and managing sessions with AI-generated code‚Äù\n‚ÄúI ve done this too‚Äù\n‚ÄúTaking time to plan an app s architecture leads to happy users and lower maintenance costs‚Äù\n‚ÄúHow can generative AI speed up the design process‚Äù\n\n\n\n\n\n\nThis week starts by treating your design notes as an input to development. The goal is to turn vague ideas into requirements you can implement.\nA requirement in this context is a short, testable statement of behaviour: what the user can do, or what the system must store/compute/display.\nA useful trick: rewrite each requirement as a user story: As a user, I want ‚Ä¶ so that ‚Ä¶.\nRequirements are not only ‚Äòfeatures‚Äô. They also include constraints like performance, security, and maintainability.\nWhen you work with AI coding tools, requirements become even more important: they are the anchor that keeps generated code aligned with your intent.\nPractical decomposition pattern used in this week:\nStart with the smallest end-to-end ‚Äòthin slice‚Äô (a page that loads; a form that submits; a result that displays).\nList the minimal data objects you need (e.g., a question bank, callsigns, categories, logs).\nIdentify the ‚Äòedges‚Äô: inputs (forms/API), outputs (HTML pages), and storage (files/DB).\nOnly then decide folder structure and module boundaries. \n\n\n\n\n\nPython projects should isolate libraries per project using a virtual environment (often abbreviated venv).\nIsolation matters because different projects need different versions of the same library (a common source of ‚Äòworks on my machine‚Äô bugs).\nIn a first-year course, we care about this early because it teaches reproducibility and reduces setup friction later. ### Create and activate a venv\nCreate the environment in your project folder (name is conventional: .venv).\nActivate it before installing packages so installs go into the venv, not your global Python.\n\npython -m venv .venv\nsource .venv/bin/activate  # macOS/Linux\n# .venv\\Scripts\\activate   # Windows (PowerShell)\npython -m pip install --upgrade pip\n\n\n\nThis week uses Flask as the minimal web framework: it‚Äôs small enough to understand without magic.\nTreat dependencies as part of your project: record them in requirements.txt so another machine can reproduce the same environment.\n\npip install flask\npip freeze &gt; requirements.txt\n\n\n\n\n\nBefore writing ‚Äòreal logic‚Äô, you create a project structure: folders for app code, templates, static assets, and tests.\nA structure is a communication tool: it tells future you (and teammates) where things belong.\nThis week‚Äôs key move is creating stubs: placeholder functions/routes that define the shape of the app before it is complete. ### A minimal, conventional Flask layout\n\nmyapp/\n  app.py\n  templates/\n    index.html\n  static/\n    style.css\n  requirements.txt\n  README.md\n\nYou can evolve this into a package layout (myapp/__init__.py) later. Start simple.\nKeep templates/ for HTML templates and static/ for CSS/JS/images, matching Flask conventions. \n\n\n\n\n\nA Flask app is basically a mapping from URLs to Python functions.\nEach mapping is a route. When a browser requests /, Flask calls the function and returns a response.\nYour job is to control: input ‚Üí processing ‚Üí output. ### The smallest runnable Flask app\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    return \"Hello! Week 4 app is running.\"\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\ndebug=True turns on debug mode: auto-reload + a helpful error page. Great for learning; disable in production.\nWhen something breaks, read the traceback top-to-bottom: it tells you where and often why. ### Running the app\n\npython app.py\n# Then open the printed URL (usually http://127.0.0.1:5000/)\n\n\n\nA browser makes an HTTP request (method + path + headers + optional body).\nYour route function returns a response (status code + headers + body).\nEven when you ‚Äòjust return a string‚Äô, Flask wraps it into a full HTTP response. ## Templates and pages: keeping logic out of HTML {#templates-and-pages-keeping-logic-out-of-html}\nOnce you move beyond plain strings, you‚Äôll render HTML templates.\nTemplates let you keep Python logic in Python and presentation in HTML.\nFlask uses Jinja2 templates; you inject values and loops into a mostly-normal HTML page. ### Example: render a template\n\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    return render_template(\"index.html\", title=\"Real World AI\")\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;{{ title }}&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;{{ title }}&lt;/h1&gt;\n    &lt;p&gt;Your Flask app is rendering templates.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nJinja placeholders like { title } are replaced at render time.\nWhen you later add forms, you‚Äôll pass user-submitted values into templates to show results. \n\n\n\n\n\n\nTreat every external library as a dependency you must track.\nrequirements.txt is the simplest approach: it records exact versions so installs are consistent.\nA clean workflow: create venv ‚Üí install deps ‚Üí freeze ‚Üí commit both code and requirements.\nIf a teammate can‚Äôt run your app, 80% of the time it‚Äôs: wrong venv, wrong Python, or missing deps. ### Recreating the environment from scratch\n\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt\n\n\n\n\nThis week‚Äôs development rhythm is iterative: make a small change, run the app, observe, and repeat.\nThis is not just ‚Äòcoding style‚Äô ‚Äî it‚Äôs risk management. Small steps make bugs easier to locate.\nWhen using AI assistants, keep iterations even smaller: generate a tiny piece, test it, then proceed. ### A tiny iteration loop (conceptual)\n\n\n\n\n\n\nflowchart TD\n  A[Write or generate small change] --&gt; B[Run unit of work]\n  B --&gt; C{Did it work?}\n  C -- Yes --&gt; D[Commit / move to next small change]\n  C -- No --&gt; E[Read error, reduce scope, fix]\n  E --&gt; A\n\n\n\n\n\n\n\n\n\n\nVenv not activated: pip install went to global Python; Flask isn‚Äôt found when running.\nWrong working directory: you run python app.py from a different folder and Flask can‚Äôt find templates/.\nPort already in use: another process is using 5000; you‚Äôll see an ‚ÄòAddress already in use‚Äô message.\nTemplate errors: misspelt variable names in Jinja; look at the stack trace and the highlighted line.\nImport cycles when you split files too early: keep it simple until you understand module imports. ## Summing Up {#summing-up}\nWeek 04 is about moving from idea to a runnable first version.\nYou practised translating requirements into a project skeleton and basic routes.\nYou set up a virtual environment, installed Flask, and captured dependencies for reproducibility.\nYou learned the core web mental model: request ‚Üí route ‚Üí response, then grew it into templates.\nNext weeks build on this baseline by generating more code with AI tools and expanding the app‚Äôs features.\n\n\n\n\n\nExplain the difference between a feature request and an implementation detail.\nWhat does a virtual environment protect you from? Give two concrete examples.\nWhy is requirements.txt useful even for a tiny project?\nWhat is a route? How is it different from a function that is never called by Flask?\nWhat is the advantage of templates compared to building HTML with string concatenation?\nDescribe the iteration loop you should follow when using an AI assistant to generate code.\n\n\n\n\n\nA strong starting point is to list user actions, then map each to a URL.\nExample: ‚ÄòStart a practice session‚Äô might map to /start, while ‚ÄòSubmit an answer‚Äô maps to /answer.\nThink about which actions change state (POST) versus which only read state (GET).\nEven if you ignore REST purity in week 4, using GET/POST correctly prevents common bugs.\n\n\n\n\n\nEarly versions often avoid databases. You can store small state in memory while learning.\nBut remember: in-memory state resets when the server restarts.\nFor learning, this is fine ‚Äî it encourages you to separate ‚Äòcore logic‚Äô from ‚Äòstorage‚Äô.\nLater weeks can swap storage without rewriting everything if your code is modular.\n\n\n\n\n\nWhen an error happens, copy the traceback and identify the first line in your codebase.\nAdd a print/log statement above that line to inspect variables.\nChange one thing at a time; rerun; confirm the effect.\nAvoid random guessing ‚Äî it‚Äôs slower than systematic diagnosis.\n\n\n\n\n\nThis week‚Äôs core move is: design artefacts ‚Üí requirements ‚Üí code skeleton.\nA useful mental model is to treat every paragraph of your design document as one of:\n\na feature (something the user can do)\na constraint (a limit: performance, privacy, usability)\nan assumption (something you are betting is true)\nan open question (something you must resolve)\n\nIf you can‚Äôt label a paragraph, it‚Äôs often ‚Äúhand-wavy‚Äù and needs rewriting.\nA simple requirement format (good enough for first year) is:\n\nAs a &lt;type of user&gt;\nI want &lt;capability&gt;\nSo that &lt;benefit&gt;\n\nThen add acceptance criteria:\n\n‚ÄúGiven ‚Ä¶ when ‚Ä¶ then ‚Ä¶‚Äù statements (these become tests later).\n\n\n\n\n\nSuppose your design doc says the app should help someone prepare for an exam.\nTurn that into requirements:\n\nAs a learner, I want to select a topic so I can practise questions.\nAs a learner, I want immediate feedback so I can correct misconceptions.\nAs a learner, I want progress tracking so I can focus on weak areas.\n\nNotice how this immediately suggests data structures and routes.\n\n# A tiny starting point: represent requirements as data\nrequirements = [\n    {\"as\": \"learner\", \"want\": \"select a topic\", \"so_that\": \"practise questions\"},\n    {\"as\": \"learner\", \"want\": \"immediate feedback\", \"so_that\": \"correct misconceptions\"},\n    {\"as\": \"learner\", \"want\": \"progress tracking\", \"so_that\": \"focus on weak areas\"},\n]\n\n# Later, you might render this in a template or export to JSON.\nimport json\nprint(json.dumps(requirements, indent=2))\n\nThis is intentionally ‚Äúlow-tech‚Äù ‚Äî the goal is to reduce ambiguity.\n\n\n\n\n\n\nWeek 04 emphasises a repeatable environment because web apps are dependency-heavy.\nTwo common mistakes by beginners:\n\ninstalling packages ‚Äúglobally‚Äù and then not remembering what you installed\nforgetting to activate the virtual environment and installing into the wrong place\n\nA virtual environment is just a folder containing:\n\na Python interpreter\nsite-packages (third-party libraries)\nscripts for activation\n\n\n\n\npython -m venv .venv\n\n# macOS / Linux\nsource .venv/bin/activate\n\n# Windows (PowerShell)\n# .venv\\Scripts\\Activate.ps1\n\nIf activation worked, your shell prompt usually changes (e.g., shows (.venv)).\nIf you get ‚Äúpermission‚Äù errors on Windows PowerShell, you may need to adjust the execution policy.\n\n\n\n\npython -m pip install --upgrade pip\npip install flask\n\npip freeze &gt; requirements.txt\ncat requirements.txt\n\nrequirements.txt is a ‚Äúsnapshot‚Äù of your environment.\nLater chapters build on this to make the project easier to share and deploy.\n\n\n\n\n\n\nThe chapter‚Äôs approach is basically: create stubs first, then fill them in.\nA stub is a small piece of code that compiles/runs but doesn‚Äôt do much yet.\n\n\n\n\nThe chapter‚Äôs screenshots illustrate a clean starting structure.\nA common layout is:\n\nmyapp/\n  app.py\n  templates/\n    index.html\n  static/\n    style.css\n  requirements.txt\n  README.md\n\nWhy separate templates/ and static/?\n\ntemplates are rendered by Flask (HTML with placeholders)\nstatic files are served directly (CSS, images, JS)\n\n\n\n\n\n\n\n\nUse these figures as reminders of the ‚Äúshape‚Äù of a small web app.\n\n\n\n\n\n\nStudents often think ‚ÄúFlask runs my code top-to-bottom each time‚Äù. Not quite.\nIn a Flask server:\n\nPython starts once\nFlask registers routes (URL patterns)\nthen waits for requests\n\nWhen a request arrives, Flask:\n\nmatches the URL to a route\ncalls the function for that route\nreturns the response\n\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    # This runs when the browser requests / (not when the file is imported)\n    return \"Hello from Week 4\"\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\ndebug=True is a development convenience:\n\nauto-reloads when files change\nshows a helpful debug page on errors\n\nYou must disable debug mode for production.\n\n\n\n\n\nChapter 4 pushes you toward templates early, which is good practice.\nTemplates help you avoid mixing Python logic with HTML.\n\n\n\n&lt;!-- templates/index.html --&gt;\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;{{ title }}&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;{{ heading }}&lt;/h1&gt;\n    &lt;p&gt;Today we are building the first version.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef index():\n    return render_template(\"index.html\", title=\"Week 4\", heading=\"Hello, Flask\")\n\nKey idea: render_template fills placeholders like { title }.\n\n\n\n\n\n\nChapter 4 is where the temptation to ‚Äúlet the AI write the whole app‚Äù becomes strong.\nThe safe workflow is:\n\nyou define the requirements and the ‚Äúshape‚Äù of the app\nyou ask the AI for small deltas (a route, a template, a helper function)\nyou run the code and inspect the results\n\nA good prompt pattern is:\n\ngive the current file structure\nspecify the exact change\nrequire that the output is a patch/diff\n\n\nYou are helping me with a Flask app.\nCurrent structure:\n- app.py\n- templates/index.html\nTask: add a new route GET /about that renders templates/about.html.\nConstraints:\n- keep app.py minimal\n- do not add new dependencies\nReturn: the full updated app.py and new about.html\n\nThis kind of prompt reduces ‚ÄúAI drift‚Äù (the model inventing extra features).\n\n\n\n\n\nHere are a few short phrases from Chapter 4 that capture the intent:\n\n‚Äúwe‚Äôre diving headfirst into the wild world‚Äù\n‚Äúbuilding a useful application‚Äù\n‚Äúintegrating these tools into your workflow‚Äù\n\nUse these as ‚Äúnorth stars‚Äù: the goal is a working workflow, not perfect code.\n\n\n\n\n\nBefore you start coding:\n\nyou can explain the user goal in one sentence\nyou can list 3‚Äì5 requirements\nyou know what data your app needs to store (even if it‚Äôs just in memory)\n\nWhen you set up the project:\n\nyou created .venv/\nyou can activate it\npython -m pip -V points inside .venv/\n\nWhen you run Flask:\n\nyou can visit http://127.0.0.1:5000/\nyou can change a file and see it reload\nyou can read a stack trace when it breaks\n\n\n\n\n\n\nChapter 4 is where your project becomes ‚Äúreal‚Äù: an app skeleton you can run.\nThe highest-value skills from this week:\n\nturning a vague design idea into concrete requirements\ncreating a reproducible Python environment\nbuilding stubs first, then iterating\nunderstanding the request/response cycle\nusing AI tools in small, testable steps",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#week-focus",
    "href": "notes/notes_4.html#week-focus",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "This week focuses on Coding the first version of our application.\nThis week is deliberately practical: it moves from an idea/design document into a runnable web app skeleton.\nKey theme: you don‚Äôt need the perfect design before you start coding ‚Äî but you do need a clear first version.\nWe‚Äôre practising how to translate text descriptions into code artefacts: folders, files, functions, and routes.\nThis week includes visual callouts/figures; we‚Äôll reference the key ones as we go.\n\n\n\n\n\n‚Äú56 Building applications with AI assistance up project structure and create your first working application‚Äù\n‚ÄúWeek 05 dives into advanced development techniques using tools such as Tabnine and BlackboxAI‚Äù\n‚ÄúFinally Week 06 focuses on building strong user interfaces and managing sessions with AI-generated code‚Äù\n‚ÄúI ve done this too‚Äù\n‚ÄúTaking time to plan an app s architecture leads to happy users and lower maintenance costs‚Äù\n‚ÄúHow can generative AI speed up the design process‚Äù",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#from-design-to-code-extracting-requirements",
    "href": "notes/notes_4.html#from-design-to-code-extracting-requirements",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "This week starts by treating your design notes as an input to development. The goal is to turn vague ideas into requirements you can implement.\nA requirement in this context is a short, testable statement of behaviour: what the user can do, or what the system must store/compute/display.\nA useful trick: rewrite each requirement as a user story: As a user, I want ‚Ä¶ so that ‚Ä¶.\nRequirements are not only ‚Äòfeatures‚Äô. They also include constraints like performance, security, and maintainability.\nWhen you work with AI coding tools, requirements become even more important: they are the anchor that keeps generated code aligned with your intent.\nPractical decomposition pattern used in this week:\nStart with the smallest end-to-end ‚Äòthin slice‚Äô (a page that loads; a form that submits; a result that displays).\nList the minimal data objects you need (e.g., a question bank, callsigns, categories, logs).\nIdentify the ‚Äòedges‚Äô: inputs (forms/API), outputs (HTML pages), and storage (files/DB).\nOnly then decide folder structure and module boundaries.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#setting-up-your-python-environment",
    "href": "notes/notes_4.html#setting-up-your-python-environment",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Python projects should isolate libraries per project using a virtual environment (often abbreviated venv).\nIsolation matters because different projects need different versions of the same library (a common source of ‚Äòworks on my machine‚Äô bugs).\nIn a first-year course, we care about this early because it teaches reproducibility and reduces setup friction later. ### Create and activate a venv\nCreate the environment in your project folder (name is conventional: .venv).\nActivate it before installing packages so installs go into the venv, not your global Python.\n\npython -m venv .venv\nsource .venv/bin/activate  # macOS/Linux\n# .venv\\Scripts\\activate   # Windows (PowerShell)\npython -m pip install --upgrade pip\n\n\n\nThis week uses Flask as the minimal web framework: it‚Äôs small enough to understand without magic.\nTreat dependencies as part of your project: record them in requirements.txt so another machine can reproduce the same environment.\n\npip install flask\npip freeze &gt; requirements.txt",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#laying-out-the-application-skeleton",
    "href": "notes/notes_4.html#laying-out-the-application-skeleton",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Before writing ‚Äòreal logic‚Äô, you create a project structure: folders for app code, templates, static assets, and tests.\nA structure is a communication tool: it tells future you (and teammates) where things belong.\nThis week‚Äôs key move is creating stubs: placeholder functions/routes that define the shape of the app before it is complete. ### A minimal, conventional Flask layout\n\nmyapp/\n  app.py\n  templates/\n    index.html\n  static/\n    style.css\n  requirements.txt\n  README.md\n\nYou can evolve this into a package layout (myapp/__init__.py) later. Start simple.\nKeep templates/ for HTML templates and static/ for CSS/JS/images, matching Flask conventions.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#your-first-flask-app-routes-requests-responses",
    "href": "notes/notes_4.html#your-first-flask-app-routes-requests-responses",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "A Flask app is basically a mapping from URLs to Python functions.\nEach mapping is a route. When a browser requests /, Flask calls the function and returns a response.\nYour job is to control: input ‚Üí processing ‚Üí output. ### The smallest runnable Flask app\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    return \"Hello! Week 4 app is running.\"\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\ndebug=True turns on debug mode: auto-reload + a helpful error page. Great for learning; disable in production.\nWhen something breaks, read the traceback top-to-bottom: it tells you where and often why. ### Running the app\n\npython app.py\n# Then open the printed URL (usually http://127.0.0.1:5000/)\n\n\n\nA browser makes an HTTP request (method + path + headers + optional body).\nYour route function returns a response (status code + headers + body).\nEven when you ‚Äòjust return a string‚Äô, Flask wraps it into a full HTTP response. ## Templates and pages: keeping logic out of HTML {#templates-and-pages-keeping-logic-out-of-html}\nOnce you move beyond plain strings, you‚Äôll render HTML templates.\nTemplates let you keep Python logic in Python and presentation in HTML.\nFlask uses Jinja2 templates; you inject values and loops into a mostly-normal HTML page. ### Example: render a template\n\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    return render_template(\"index.html\", title=\"Real World AI\")\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;{{ title }}&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;{{ title }}&lt;/h1&gt;\n    &lt;p&gt;Your Flask app is rendering templates.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nJinja placeholders like { title } are replaced at render time.\nWhen you later add forms, you‚Äôll pass user-submitted values into templates to show results.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#configuration-dependencies-and-reproducibility",
    "href": "notes/notes_4.html#configuration-dependencies-and-reproducibility",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Treat every external library as a dependency you must track.\nrequirements.txt is the simplest approach: it records exact versions so installs are consistent.\nA clean workflow: create venv ‚Üí install deps ‚Üí freeze ‚Üí commit both code and requirements.\nIf a teammate can‚Äôt run your app, 80% of the time it‚Äôs: wrong venv, wrong Python, or missing deps. ### Recreating the environment from scratch\n\npython -m venv .venv\nsource .venv/bin/activate\npip install -r requirements.txt",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#run-observe-iterate",
    "href": "notes/notes_4.html#run-observe-iterate",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "This week‚Äôs development rhythm is iterative: make a small change, run the app, observe, and repeat.\nThis is not just ‚Äòcoding style‚Äô ‚Äî it‚Äôs risk management. Small steps make bugs easier to locate.\nWhen using AI assistants, keep iterations even smaller: generate a tiny piece, test it, then proceed. ### A tiny iteration loop (conceptual)\n\n\n\n\n\n\nflowchart TD\n  A[Write or generate small change] --&gt; B[Run unit of work]\n  B --&gt; C{Did it work?}\n  C -- Yes --&gt; D[Commit / move to next small change]\n  C -- No --&gt; E[Read error, reduce scope, fix]\n  E --&gt; A",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#common-failure-modes",
    "href": "notes/notes_4.html#common-failure-modes",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Venv not activated: pip install went to global Python; Flask isn‚Äôt found when running.\nWrong working directory: you run python app.py from a different folder and Flask can‚Äôt find templates/.\nPort already in use: another process is using 5000; you‚Äôll see an ‚ÄòAddress already in use‚Äô message.\nTemplate errors: misspelt variable names in Jinja; look at the stack trace and the highlighted line.\nImport cycles when you split files too early: keep it simple until you understand module imports. ## Summing Up {#summing-up}\nWeek 04 is about moving from idea to a runnable first version.\nYou practised translating requirements into a project skeleton and basic routes.\nYou set up a virtual environment, installed Flask, and captured dependencies for reproducibility.\nYou learned the core web mental model: request ‚Üí route ‚Üí response, then grew it into templates.\nNext weeks build on this baseline by generating more code with AI tools and expanding the app‚Äôs features.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#appendix-check-your-understanding",
    "href": "notes/notes_4.html#appendix-check-your-understanding",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Explain the difference between a feature request and an implementation detail.\nWhat does a virtual environment protect you from? Give two concrete examples.\nWhy is requirements.txt useful even for a tiny project?\nWhat is a route? How is it different from a function that is never called by Flask?\nWhat is the advantage of templates compared to building HTML with string concatenation?\nDescribe the iteration loop you should follow when using an AI assistant to generate code.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#deep-dive-mapping-requirements-to-routes",
    "href": "notes/notes_4.html#deep-dive-mapping-requirements-to-routes",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "A strong starting point is to list user actions, then map each to a URL.\nExample: ‚ÄòStart a practice session‚Äô might map to /start, while ‚ÄòSubmit an answer‚Äô maps to /answer.\nThink about which actions change state (POST) versus which only read state (GET).\nEven if you ignore REST purity in week 4, using GET/POST correctly prevents common bugs.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#deep-dive-keeping-state-for-now",
    "href": "notes/notes_4.html#deep-dive-keeping-state-for-now",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Early versions often avoid databases. You can store small state in memory while learning.\nBut remember: in-memory state resets when the server restarts.\nFor learning, this is fine ‚Äî it encourages you to separate ‚Äòcore logic‚Äô from ‚Äòstorage‚Äô.\nLater weeks can swap storage without rewriting everything if your code is modular.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#deep-dive-debugging-discipline",
    "href": "notes/notes_4.html#deep-dive-debugging-discipline",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "When an error happens, copy the traceback and identify the first line in your codebase.\nAdd a print/log statement above that line to inspect variables.\nChange one thing at a time; rerun; confirm the effect.\nAvoid random guessing ‚Äî it‚Äôs slower than systematic diagnosis.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#a-worked-walkthrough-turning-the-week-into-a-plan",
    "href": "notes/notes_4.html#a-worked-walkthrough-turning-the-week-into-a-plan",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "This week‚Äôs core move is: design artefacts ‚Üí requirements ‚Üí code skeleton.\nA useful mental model is to treat every paragraph of your design document as one of:\n\na feature (something the user can do)\na constraint (a limit: performance, privacy, usability)\nan assumption (something you are betting is true)\nan open question (something you must resolve)\n\nIf you can‚Äôt label a paragraph, it‚Äôs often ‚Äúhand-wavy‚Äù and needs rewriting.\nA simple requirement format (good enough for first year) is:\n\nAs a &lt;type of user&gt;\nI want &lt;capability&gt;\nSo that &lt;benefit&gt;\n\nThen add acceptance criteria:\n\n‚ÄúGiven ‚Ä¶ when ‚Ä¶ then ‚Ä¶‚Äù statements (these become tests later).\n\n\n\n\n\nSuppose your design doc says the app should help someone prepare for an exam.\nTurn that into requirements:\n\nAs a learner, I want to select a topic so I can practise questions.\nAs a learner, I want immediate feedback so I can correct misconceptions.\nAs a learner, I want progress tracking so I can focus on weak areas.\n\nNotice how this immediately suggests data structures and routes.\n\n# A tiny starting point: represent requirements as data\nrequirements = [\n    {\"as\": \"learner\", \"want\": \"select a topic\", \"so_that\": \"practise questions\"},\n    {\"as\": \"learner\", \"want\": \"immediate feedback\", \"so_that\": \"correct misconceptions\"},\n    {\"as\": \"learner\", \"want\": \"progress tracking\", \"so_that\": \"focus on weak areas\"},\n]\n\n# Later, you might render this in a template or export to JSON.\nimport json\nprint(json.dumps(requirements, indent=2))\n\nThis is intentionally ‚Äúlow-tech‚Äù ‚Äî the goal is to reduce ambiguity.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#setting-up-your-python-environment-deeper-notes",
    "href": "notes/notes_4.html#setting-up-your-python-environment-deeper-notes",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Week 04 emphasises a repeatable environment because web apps are dependency-heavy.\nTwo common mistakes by beginners:\n\ninstalling packages ‚Äúglobally‚Äù and then not remembering what you installed\nforgetting to activate the virtual environment and installing into the wrong place\n\nA virtual environment is just a folder containing:\n\na Python interpreter\nsite-packages (third-party libraries)\nscripts for activation\n\n\n\n\npython -m venv .venv\n\n# macOS / Linux\nsource .venv/bin/activate\n\n# Windows (PowerShell)\n# .venv\\Scripts\\Activate.ps1\n\nIf activation worked, your shell prompt usually changes (e.g., shows (.venv)).\nIf you get ‚Äúpermission‚Äù errors on Windows PowerShell, you may need to adjust the execution policy.\n\n\n\n\npython -m pip install --upgrade pip\npip install flask\n\npip freeze &gt; requirements.txt\ncat requirements.txt\n\nrequirements.txt is a ‚Äúsnapshot‚Äù of your environment.\nLater chapters build on this to make the project easier to share and deploy.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#laying-out-the-application-skeleton-deeper-notes",
    "href": "notes/notes_4.html#laying-out-the-application-skeleton-deeper-notes",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "The chapter‚Äôs approach is basically: create stubs first, then fill them in.\nA stub is a small piece of code that compiles/runs but doesn‚Äôt do much yet.\n\n\n\n\nThe chapter‚Äôs screenshots illustrate a clean starting structure.\nA common layout is:\n\nmyapp/\n  app.py\n  templates/\n    index.html\n  static/\n    style.css\n  requirements.txt\n  README.md\n\nWhy separate templates/ and static/?\n\ntemplates are rendered by Flask (HTML with placeholders)\nstatic files are served directly (CSS, images, JS)\n\n\n\n\n\n\n\n\nUse these figures as reminders of the ‚Äúshape‚Äù of a small web app.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#flask-request-lifecycle-what-actually-happens",
    "href": "notes/notes_4.html#flask-request-lifecycle-what-actually-happens",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Students often think ‚ÄúFlask runs my code top-to-bottom each time‚Äù. Not quite.\nIn a Flask server:\n\nPython starts once\nFlask registers routes (URL patterns)\nthen waits for requests\n\nWhen a request arrives, Flask:\n\nmatches the URL to a route\ncalls the function for that route\nreturns the response\n\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef home():\n    # This runs when the browser requests / (not when the file is imported)\n    return \"Hello from Week 4\"\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\ndebug=True is a development convenience:\n\nauto-reloads when files change\nshows a helpful debug page on errors\n\nYou must disable debug mode for production.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#templates-expanded",
    "href": "notes/notes_4.html#templates-expanded",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Chapter 4 pushes you toward templates early, which is good practice.\nTemplates help you avoid mixing Python logic with HTML.\n\n\n\n&lt;!-- templates/index.html --&gt;\n&lt;!doctype html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;{{ title }}&lt;/title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;{{ heading }}&lt;/h1&gt;\n    &lt;p&gt;Today we are building the first version.&lt;/p&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n@app.get(\"/\")\ndef index():\n    return render_template(\"index.html\", title=\"Week 4\", heading=\"Hello, Flask\")\n\nKey idea: render_template fills placeholders like { title }.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#using-ai-tools-without-losing-control",
    "href": "notes/notes_4.html#using-ai-tools-without-losing-control",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Chapter 4 is where the temptation to ‚Äúlet the AI write the whole app‚Äù becomes strong.\nThe safe workflow is:\n\nyou define the requirements and the ‚Äúshape‚Äù of the app\nyou ask the AI for small deltas (a route, a template, a helper function)\nyou run the code and inspect the results\n\nA good prompt pattern is:\n\ngive the current file structure\nspecify the exact change\nrequire that the output is a patch/diff\n\n\nYou are helping me with a Flask app.\nCurrent structure:\n- app.py\n- templates/index.html\nTask: add a new route GET /about that renders templates/about.html.\nConstraints:\n- keep app.py minimal\n- do not add new dependencies\nReturn: the full updated app.py and new about.html\n\nThis kind of prompt reduces ‚ÄúAI drift‚Äù (the model inventing extra features).",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#more-micro-quotes-from-the-chapter",
    "href": "notes/notes_4.html#more-micro-quotes-from-the-chapter",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Here are a few short phrases from Chapter 4 that capture the intent:\n\n‚Äúwe‚Äôre diving headfirst into the wild world‚Äù\n‚Äúbuilding a useful application‚Äù\n‚Äúintegrating these tools into your workflow‚Äù\n\nUse these as ‚Äúnorth stars‚Äù: the goal is a working workflow, not perfect code.",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#extended-checklist-for-students",
    "href": "notes/notes_4.html#extended-checklist-for-students",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Before you start coding:\n\nyou can explain the user goal in one sentence\nyou can list 3‚Äì5 requirements\nyou know what data your app needs to store (even if it‚Äôs just in memory)\n\nWhen you set up the project:\n\nyou created .venv/\nyou can activate it\npython -m pip -V points inside .venv/\n\nWhen you run Flask:\n\nyou can visit http://127.0.0.1:5000/\nyou can change a file and see it reload\nyou can read a stack trace when it breaks",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_4.html#summing-up",
    "href": "notes/notes_4.html#summing-up",
    "title": "Week 04 ‚Äî Coding the first version of our application",
    "section": "",
    "text": "Chapter 4 is where your project becomes ‚Äúreal‚Äù: an app skeleton you can run.\nThe highest-value skills from this week:\n\nturning a vague design idea into concrete requirements\ncreating a reproducible Python environment\nbuilding stubs first, then iterating\nunderstanding the request/response cycle\nusing AI tools in small, testable steps",
    "crumbs": [
      "Notes",
      "Notes 04 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html",
    "href": "notes/notes_6.html",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "",
    "text": "This week focuses on Generating a software backend.\nWe are continuing the HAM radio practice-test app. In Week 05 we got a working scaffold (database + basic page). In Week 06 the focus shifts from ‚Äúit runs‚Äù to ‚Äúit behaves like a real application‚Äù: it must keep track of a test-taker over multiple clicks, handle restarts, and recover cleanly from bugs.\n\n\n\nTurning a static ‚Äúdump of questions‚Äù into an interactive workflow.\nCreating and maintaining persistent sessions so each student sees a consistent test flow.\nImplementing backend features in Flask with database integration.\nUsing Tabnine to:\n\ngenerate code (scaffolds and functions)\ndebug and fix errors\nrefactor toward cleaner modules\n\nCrafting prompts that produce useful help instead of vague output.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#what-this-week-covers-in-plain-language",
    "href": "notes/notes_6.html#what-this-week-covers-in-plain-language",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "",
    "text": "Turning a static ‚Äúdump of questions‚Äù into an interactive workflow.\nCreating and maintaining persistent sessions so each student sees a consistent test flow.\nImplementing backend features in Flask with database integration.\nUsing Tabnine to:\n\ngenerate code (scaffolds and functions)\ndebug and fix errors\nrefactor toward cleaner modules\n\nCrafting prompts that produce useful help instead of vague output.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#recap-of-the-app-architecture-so-far",
    "href": "notes/notes_6.html#recap-of-the-app-architecture-so-far",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Recap of the app architecture so far",
    "text": "Recap of the app architecture so far\nBy now you have:\n\nA SQLite database file (for example data/questions.db).\nModel code that opens a connection and fetches question data.\nA Flask app entry point that defines routes and renders templates.\n\nThe problem: the app works once, then fails on reload / restart / second session.\nThat is a classic ‚Äústate + lifecycle‚Äù bug.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#why-backend-work-matters-here",
    "href": "notes/notes_6.html#why-backend-work-matters-here",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Why backend work matters here",
    "text": "Why backend work matters here\nA lot of beginner web apps fail because they confuse:\n\na request (one browser hit)\na session (a user across many requests)\nan application run (the server process)\n\nWhen you build a ‚Äútest‚Äù experience, you are building a mini state machine:\n\nStart test ‚Üí choose 35 questions ‚Üí show question 1 ‚Üí record answer ‚Üí show question 2 ‚Üí ‚Ä¶ ‚Üí show results.\n\nIf you don‚Äôt store state, every click resets you.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#symptom-driven-debugging",
    "href": "notes/notes_6.html#symptom-driven-debugging",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Symptom-driven debugging",
    "text": "Symptom-driven debugging\nWhen an app works once and fails on the second run, the cause is often one of:\n\nstate is not reset correctly\nfile handles are not closed\ndatabase locks persist\ncached objects survive between sessions\nassumptions about directory paths are wrong\n\nThis week shows a concrete example: a SQLite error that appears when loading again.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#why-this-is-a-good-learning-bug",
    "href": "notes/notes_6.html#why-this-is-a-good-learning-bug",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Why this is a good learning bug",
    "text": "Why this is a good learning bug\nIt forces you to think in layers:\n\nWhat is the user action (reload, restart, new browser)?\nWhat is the server lifecycle (process reused, dev server reload)?\nWhat is the data layer lifecycle (connection, cursor, transaction)?",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#what-tabnine-is-good-at",
    "href": "notes/notes_6.html#what-tabnine-is-good-at",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "What Tabnine is good at",
    "text": "What Tabnine is good at\n\nproducing ‚Äústarter‚Äù implementations quickly\nsuggesting fixes when you show a stack trace\nrefactoring repetitive code into functions/classes\ngenerating tests and edge cases (if you ask clearly)",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#what-tabnine-is-bad-at-unless-you-guide-it",
    "href": "notes/notes_6.html#what-tabnine-is-bad-at-unless-you-guide-it",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "What Tabnine is bad at (unless you guide it)",
    "text": "What Tabnine is bad at (unless you guide it)\n\nunderstanding your full codebase without context\nmaking architectural decisions for you\nreliably preserving your project conventions\n\n\nPractical prompting pattern\nWhen you ask for help, include:\n\nthe goal in one sentence\nthe current behavior\nthe error message / stack trace\nthe relevant file(s) and function(s)\nwhat you already tried\n\nExample prompt structure (adapt for Tabnine or any assistant):\n\nI have a Flask app that selects 35 questions from SQLite. It works on first load but fails on reload with this error: ‚Ä¶ Here is my DatabaseConnection context manager and the route handler. Please diagnose the root cause and suggest a minimal fix.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#a-minimal-but-clean-flask-app-structure",
    "href": "notes/notes_6.html#a-minimal-but-clean-flask-app-structure",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "A minimal but clean Flask app structure",
    "text": "A minimal but clean Flask app structure\nA simple, testable structure often looks like:\n\napp/__init__.py (create_app)\napp/routes.py (blueprints)\napp/models/ (db + query logic)\napp/templates/ (Jinja2 HTML)\ntests/ (pytest)\n\nThis week keeps things lightweight but pushes toward separation:\n\nroutes should be thin\ndatabase code should be isolated\n‚Äúsession state‚Äù should be explicit",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#code-example-enabling-sessions-and-setting-a-secret-key",
    "href": "notes/notes_6.html#code-example-enabling-sessions-and-setting-a-secret-key",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Code example: enabling sessions and setting a secret key",
    "text": "Code example: enabling sessions and setting a secret key\nfrom flask import Flask\n\ndef create_app():\n    app = Flask(__name__)\n    # In production: load from environment variable\n    app.config[\"SECRET_KEY\"] = \"dev-only-change-me\"\n    return app\n\nWhy SECRET_KEY matters\nFlask signs session cookies. If the key changes between runs, the server can‚Äôt validate old cookies. That can look like ‚Äúrandom‚Äù session failures.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#code-example-selecting-questions-once-per-session",
    "href": "notes/notes_6.html#code-example-selecting-questions-once-per-session",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Code example: selecting questions once per session",
    "text": "Code example: selecting questions once per session\nimport random\nfrom flask import session\n\ndef init_test_session(question_ids, n=35):\n    # Store a stable random selection for this user\n    chosen = random.sample(question_ids, n)\n    session[\"question_ids\"] = chosen\n    session[\"current_index\"] = 0\n    session[\"answers\"] = {}\n\nPitfall\nIf you re-sample on every request, the test becomes inconsistent.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#code-example-route-that-shows-the-current-question",
    "href": "notes/notes_6.html#code-example-route-that-shows-the-current-question",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Code example: route that shows the current question",
    "text": "Code example: route that shows the current question\nfrom flask import render_template, session, redirect, url_for\n\n@app.route(\"/question\")\ndef show_question():\n    ids = session.get(\"question_ids\")\n    if not ids:\n        return redirect(url_for(\"start_test\"))\n\n    idx = session.get(\"current_index\", 0)\n    qid = ids[idx]\n    question = Questions(cursor).fetch_by_id(qid)\n\n    return render_template(\"question.html\", question=question, index=idx+1, total=len(ids))",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#code-example-recording-an-answer-post",
    "href": "notes/notes_6.html#code-example-recording-an-answer-post",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Code example: recording an answer (POST)",
    "text": "Code example: recording an answer (POST)\nfrom flask import request\n\n@app.post(\"/answer\")\ndef record_answer():\n    qid = request.form[\"question_id\"]\n    choice = request.form[\"choice\"]\n\n    answers = session.get(\"answers\", {})\n    answers[qid] = choice\n    session[\"answers\"] = answers\n\n    session[\"current_index\"] = session.get(\"current_index\", 0) + 1\n    return redirect(url_for(\"show_question\"))\n\nWhy we reassign session[\"answers\"]\nWith cookie-based sessions, Flask detects modifications when you set a key. Mutating a nested dict may not be detected consistently unless you reassign.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#make-failures-reproducible",
    "href": "notes/notes_6.html#make-failures-reproducible",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Make failures reproducible",
    "text": "Make failures reproducible\nGood debugging is about making ‚Äúsometimes‚Äù become ‚Äúalways‚Äù.\nTry:\n\nrestart server, load app, answer 1 question, reload\nopen private window (new session), repeat\ndelete cookies, repeat",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#code-example-quick-smoke-test-with-requests",
    "href": "notes/notes_6.html#code-example-quick-smoke-test-with-requests",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Code example: quick smoke test with requests",
    "text": "Code example: quick smoke test with requests\nimport requests\n\nbase = \"http://127.0.0.1:5000\"\nwith requests.Session() as s:\n    r = s.get(f\"{base}/start\")\n    r.raise_for_status()\n    r = s.get(f\"{base}/question\")\n    print(r.status_code, len(r.text))",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#common-error-classes-in-this-week",
    "href": "notes/notes_6.html#common-error-classes-in-this-week",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Common error classes in this week",
    "text": "Common error classes in this week\n\nSQLite ‚Äúdatabase is locked‚Äù\nfile path errors (relative vs absolute)\nsession cookie invalidation\nKeyError from missing session keys",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#checks-for-understanding",
    "href": "notes/notes_6.html#checks-for-understanding",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Checks for understanding",
    "text": "Checks for understanding\n\nExplain the difference between a request, a session, and a server process.\nList 5 pieces of state you need for a practice test workflow.\nDescribe one reason a SQLite app works once but fails on reload.\nGive an example of a good debugging prompt for Tabnine.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-1-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-1-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 1: What are we trying to achieve?",
    "text": "Step 1: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-2-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-2-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 2: What are we trying to achieve?",
    "text": "Step 2: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-3-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-3-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 3: What are we trying to achieve?",
    "text": "Step 3: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-4-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-4-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 4: What are we trying to achieve?",
    "text": "Step 4: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-5-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-5-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 5: What are we trying to achieve?",
    "text": "Step 5: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-6-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-6-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 6: What are we trying to achieve?",
    "text": "Step 6: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-7-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-7-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 7: What are we trying to achieve?",
    "text": "Step 7: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-8-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-8-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 8: What are we trying to achieve?",
    "text": "Step 8: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-9-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-9-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 9: What are we trying to achieve?",
    "text": "Step 9: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-10-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-10-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 10: What are we trying to achieve?",
    "text": "Step 10: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-11-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-11-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 11: What are we trying to achieve?",
    "text": "Step 11: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-12-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-12-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 12: What are we trying to achieve?",
    "text": "Step 12: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-13-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-13-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 13: What are we trying to achieve?",
    "text": "Step 13: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-14-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-14-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 14: What are we trying to achieve?",
    "text": "Step 14: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-15-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-15-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 15: What are we trying to achieve?",
    "text": "Step 15: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-16-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-16-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 16: What are we trying to achieve?",
    "text": "Step 16: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-17-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-17-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 17: What are we trying to achieve?",
    "text": "Step 17: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-18-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-18-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 18: What are we trying to achieve?",
    "text": "Step 18: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-19-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-19-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 19: What are we trying to achieve?",
    "text": "Step 19: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-20-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-20-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 20: What are we trying to achieve?",
    "text": "Step 20: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-21-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-21-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 21: What are we trying to achieve?",
    "text": "Step 21: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-22-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-22-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 22: What are we trying to achieve?",
    "text": "Step 22: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-23-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-23-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 23: What are we trying to achieve?",
    "text": "Step 23: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-24-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-24-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 24: What are we trying to achieve?",
    "text": "Step 24: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_6.html#step-25-what-are-we-trying-to-achieve",
    "href": "notes/notes_6.html#step-25-what-are-we-trying-to-achieve",
    "title": "Week 06 ‚Äî Generating a software backend",
    "section": "Step 25: What are we trying to achieve?",
    "text": "Step 25: What are we trying to achieve?\n\nGoal: make the app behave consistently for a single test-taker across multiple requests.\nWhy it matters: without stable state, a ‚Äòtest‚Äô is just random page loads.\nWhat to look for in the chapter: session keys, routes, and the bug-fix narrative with Tabnine.\nCommon pitfall: changing too many things at once; fix the minimal root cause first.",
    "crumbs": [
      "Notes",
      "Notes 06 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html",
    "href": "notes/notes_8.html",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Why testing matters in AI-assisted coding\nKey terms you must be able to use\nAI-assisted test generation workflow\nunittest vs pytest and when to use each\nIn-memory databases for isolated tests\nPrompting patterns for high-quality tests\nEvaluating and fixing AI-generated tests\nCommon failure modes and how to debug\nUsing generated tests in CI\nSumming up\n\n\n\n\nWeek 08 focuses on using generative AI to produce tests, but this week is really about trust.\nA test suite is your ‚Äúcontract‚Äù with future you: it describes what must stay true as code changes.\nAI can write tests quickly, but speed is useless if the tests are brittle, shallow, or wrong.\n‚ÄúGenerative AI tools are changing this boring, repetitive process.‚Äù\n‚ÄúThey can automatically create detailed test suites, spot edge cases, and generate boilerplate code.‚Äù\nIn AI-assisted workflows, tests do two jobs at once:\n\ncatch regressions, and 2) detect when the AI has hallucinated an API, edge case, or assumption.\n\nA bad test suite can make things worse by giving you false confidence.\n\n\n\n\n\ntest oracle ‚Äî what counts as correct output (and what your test is really asserting).\nfixture ‚Äî a repeatable setup/teardown wrapper that makes tests readable and reliable.\nmock ‚Äî a controlled stand‚Äëin that isolates your code from external systems.\nin‚Äëmemory database ‚Äî a temporary database (often SQLite) used for fast, isolated tests.\nregression test ‚Äî a test that locks in behaviour so future changes don‚Äôt break it.\nproperty‚Äëbased testing ‚Äî testing broad invariants by generating many inputs automatically.\n\n\n\n\n\nStart by writing a clear spec (even if it is only a paragraph). AI cannot test what you cannot describe.\nDecide what level you are testing: unit (small), integration (multiple parts), or end-to-end (system).\nGive the AI: the function signature, expected behaviour, edge cases, and any invariants.\nAsk for tests and a short explanation of why each test exists.\n‚ÄúThis week shows how GitHub Copilot, Tabnine, and Blackbox AI can enhance your testing workflow.‚Äù\nRun the tests immediately. If they fail, treat that as feedback about either the code or the prompt.\nRefactor the generated tests: rename, remove duplicates, add missing assertions, and simplify setup.\n\n\n\n\n\nBoth frameworks can express the same logic; the difference is ergonomics and ecosystem conventions.\nunittest is batteries-included and class-based; pytest is function-first and heavily fixture-driven.\nIf a project already uses one, prefer consistency over personal preference.\nAI tends to produce verbose unittest boilerplate unless you explicitly ask for pytest.\n‚ÄúThey can help you build strong, maintain¬≠ able test suites quickly, while upholding quality.‚Äù\nAsk the AI to follow your project‚Äôs test naming and folder conventions.\nDo not accept tests that assert implementation details (e.g., exact SQL query strings) unless required.\n\n\n\n\n\nAn in-memory DB makes tests fast and isolated: every test starts from a clean slate.\nThis week demonstrates creating temporary databases and seeding minimal data for reproducibility.\n‚Äú211 Why use generative AI for testing?‚Äù\nKey idea: tests should not depend on a developer‚Äôs local environment (paths, ports, or existing data).\nWhen you use SQLite in-memory, ensure your app‚Äôs DB layer can accept a connection string override.\n\n\n\n\n\nUse prompts that are specific about assertions, not just ‚Äúwrite tests‚Äù.\nAlways list edge cases you care about (empty inputs, None/null, boundary values, malformed data).\nIf you want parameterised tests, say so explicitly.\nIf you want mocks, name the dependencies to mock and the behaviour they should simulate.\n‚ÄúHigh-quality tests are vital for reliable software.‚Äù\nAsk for one test per behaviour: big ‚Äúkitchen sink‚Äù tests are hard to debug.\nAsk the AI to include comments that link each test back to a requirement line.\n\n\n\n\n\nTreat AI-generated tests as a draft. Your job is to make them true and useful.\nCheck: does the test actually fail when the code is wrong? (mutation testing mindset).\nCheck for false positives: tests that pass even if you delete the core logic.\nCheck for brittle fixtures: random data, timestamps, network calls, global state.\n‚ÄúThey catch bugs early and ensure new features don‚Äôt break existing code.‚Äù\nPrefer explicit assertions over printing/logging output.\n\n\n\n\n\nHallucinated imports: AI may invent packages or functions that do not exist in your environment.\nOver-mocking: if everything is mocked, you are not testing meaningful behaviour.\nTesting the wrong thing: asserting internal variable values rather than outputs or side effects.\nNondeterminism: tests that depend on ordering, random seeds, time, or network.\n‚ÄúThey also document how the code should behave.‚Äù\nFix strategy: reduce the test to the minimal reproducer, then rebuild structure with fixtures.\n\n\n\n\n\nA CI pipeline turns ‚Äúworks on my machine‚Äù into ‚Äúworks for everyone‚Äù.\nAI-generated tests are only valuable if they run reliably in a clean environment.\nMake dependencies explicit (requirements file / lockfile).\nPin versions when your tests rely on specific behaviour.\nKeep secrets out of tests; use environment variables and test doubles.\n\n\n\nimport pytest\n\ndef add(a, b):\n    return a + b\n\ndef test_add_basic():\n    assert add(2, 3) == 5\n\n@pytest.mark.parametrize('a,b,expected', [(0,0,0), (-1,1,0), (2,-5,-3)])\ndef test_add_parametrized(a,b,expected):\n    assert add(a,b) == expected\n\n\n\nimport unittest\n\ndef add(a, b):\n    return a + b\n\nclass TestAdd(unittest.TestCase):\n    def test_add_basic(self):\n        self.assertEqual(add(2,3), 5)\n\nif __name__ == '__main__':\n    unittest.main()\n\n\n\nimport sqlite3\n\ndef make_db():\n    conn = sqlite3.connect(':memory:')\n    cur = conn.cursor()\n    cur.execute('CREATE TABLE users(id INTEGER PRIMARY KEY, name TEXT)')\n    cur.execute('INSERT INTO users(name) VALUES (?)', ('Ada',))\n    conn.commit()\n    return conn\n\ndef test_user_seed():\n    conn = make_db()\n    cur = conn.cursor()\n    cur.execute('SELECT COUNT(*) FROM users')\n    assert cur.fetchone()[0] == 1\n\n\n\nfrom unittest.mock import Mock\n\nclass Client:\n    def __init__(self, http_get):\n        self.http_get = http_get\n\n    def fetch_status(self, url):\n        resp = self.http_get(url)\n        return resp.status_code\n\ndef test_fetch_status_mocked():\n    fake_resp = Mock()\n    fake_resp.status_code = 200\n    http_get = Mock(return_value=fake_resp)\n\n    c = Client(http_get=http_get)\n    assert c.fetch_status('https://example.com') == 200\n    http_get.assert_called_once()\n\n\n\nPROMPT = '''\nYou are generating tests for Python code.\n\nContext:\n- Framework: pytest\n- File under test: app/service.py\n- Function signatures: &lt;paste here&gt;\n\nRequirements:\n1) Write one test per requirement.\n2) Include edge cases: empty input, None, boundary values.\n3) Use fixtures for setup; avoid global state.\n4) Explain each test in 1 line comment.\n\nOutput: a complete pytest test module.\n'''\nprint(PROMPT)\n\n\n\n# Demonstration: if you break the function, does a test fail?\n\ndef area(radius):\n    return 3.14159 * radius * radius\n\ndef test_area_positive():\n    assert area(2) == 12.56636\n\n# Try changing area() to return 0 and rerun the test.\n\n\n\n\n         \n\n\n\n\nAI is a powerful assistant for drafting tests, but you still own correctness.\nThe best prompts specify behaviour, edge cases, and constraints (framework, fixtures, mocking).\nAlways run, review, and refactor generated tests; treat them like code written by a junior dev.\nIn-memory databases and isolated environments are key to reliable automated testing.\n\n\n\n\n\nQuick checklist before you trust an AI-generated test suite:\nDoes each test name describe behaviour (not implementation)?\nDo the tests include at least one negative case?\nAre edge cases explicit, not implied?\nIs the database/file system/network isolated or mocked?\nWould the tests still pass if you replaced your function body with pass?\nDo failures produce actionable error messages?\nDo fixtures reduce duplication (but not hide important details)?\nAre time-dependent values controlled (freeze time or inject clocks)?\nAre random values seeded?\nAre you asserting the right thing (outputs/side effects) rather than intermediate variables?\nMini Q&A (the kinds of questions you should be able to answer):\nWhat is a ‚Äútest oracle‚Äù and why is it hard for AI?\nWhen is mocking harmful?\nWhy is an in-memory database useful but sometimes misleading?\nHow do you know a test is not ‚Äútoo shallow‚Äù?\nWhat prompt information tends to improve assertion quality?\n\n\n\n\n\nWeek 08 keeps returning to a simple idea: tests get better when the specification is clearer than the code.\nWhen you prompt a tool to generate tests, you are effectively writing a mini test plan.\n\n\n\n\nUse this structure (adapt the wording, keep the slots):\nSystem/role: ‚ÄúYou are a software tester writing pytest tests.‚Äù\nGoal: ‚ÄúGenerate tests for function X.‚Äù\nBehaviour spec: list rules as bullets.\nEdge cases: list edge cases explicitly.\nConstraints:\n- no network\n- no real filesystem writes\n- deterministic outcomes (freeze time or inject clock)\nOutput format: ‚ÄúReturn only test code in one file.‚Äù\nA useful trick: ask the model to first list test cases (names + what they check), then write the code.\nIf you do that, you can review the case list quickly before trusting the code.\n\n\n\n\n\nAsk for meaningful assertions rather than ‚Äújust coverage‚Äù.\nAsk for failure-mode tests:\ninvalid inputs\nboundary values\nempty collections\nmissing keys\nduplicates\nIf the code touches randomness, instruct: ‚Äúinject a seed or mock the RNG.‚Äù\n\n\n\n\n\nAsk for fixtures with clear names: user_factory, db_session, tmp_project.\nAsk the tool to explain (briefly) what each fixture is responsible for.\nIf the tool creates a fixture that does too much, split it.\n\n\n\n\n\n\nBelow is a deliberately small example to illustrate the workflow Week 08 argues for:\nstart with a vague prompt ‚Üí get weak tests ‚Üí tighten the prompt ‚Üí get stronger tests.\n\n\n\n#| echo: true\n#| eval: false\n\ndef normalise_score(x: float) -&gt; float:\n    \"\"\"Clamp to [0, 1] and round to 2dp.\"\"\"\n    if x != x:  # NaN\n        raise ValueError(\"NaN\")\n    if x &lt; 0:\n        return 0.0\n    if x &gt; 1:\n        return 1.0\n    return round(x, 2)\n\n\n\n\nWeak tests often:\nonly test the ‚Äúhappy path‚Äù,\nassert very little,\nmiss NaN / boundary cases.\n\n#| echo: true\n#| eval: false\n\nimport pytest\n\n\ndef test_normalise_score_basic():\n    assert normalise_score(0.2) == 0.2\n\n\n\n#| echo: true\n#| eval: false\n\nimport math\nimport pytest\n\n\ndef test_clamps_low_values_to_zero():\n    assert normalise_score(-0.0001) == 0.0\n\n\ndef test_clamps_high_values_to_one():\n    assert normalise_score(1.0001) == 1.0\n\n\ndef test_rounds_to_two_decimal_places():\n    assert normalise_score(0.126) == 0.13\n\n\ndef test_boundary_values_are_stable():\n    assert normalise_score(0.0) == 0.0\n    assert normalise_score(1.0) == 1.0\n\n\ndef test_nan_raises_value_error():\n    with pytest.raises(ValueError):\n        normalise_score(math.nan)\n\nThis is the kind of result you get when you prompt with explicit rules and edge cases.\n\n\n\n\n\n\nWeek 08 discusses isolated environments because test reliability depends on control.\nA database is a common source of hidden coupling:\nleftover rows from previous runs\nschema drift\ntests that require manual setup\n\n\n\n\nSQLite can run entirely in memory by using :memory:.\nBenefit: every test run starts from a clean slate.\nTradeoff: behaviour can differ from your production database (types, constraints, concurrency).\n\n#| echo: true\n#| eval: false\n\nimport sqlite3\n\n\ndef make_db():\n    conn = sqlite3.connect(\":memory:\")\n    cur = conn.cursor()\n    cur.execute(\"CREATE TABLE items(id INTEGER PRIMARY KEY, name TEXT)\")\n    conn.commit()\n    return conn\n\n\ndef test_insert_and_query():\n    conn = make_db()\n    cur = conn.cursor()\n    cur.execute(\"INSERT INTO items(name) VALUES (?)\", (\"apple\",))\n    conn.commit()\n    cur.execute(\"SELECT name FROM items WHERE id=1\")\n    assert cur.fetchone()[0] == \"apple\"\n\nIf you‚Äôre using an ORM (SQLAlchemy), you can build a test session bound to an in-memory engine.\nPrompt tip: explicitly name the stack (SQLite + SQLAlchemy + pytest fixtures) so the model doesn‚Äôt invent libraries.\n\n\n\n\n\n\nCommon failure patterns (and how to spot them):\nAsserting implementation details: tests break when you refactor harmlessly.\nBrittle data: hard-coded timestamps, random ids, order-dependent lists.\nMocking the wrong thing: you end up testing the mock, not the behaviour.\nTesting the tool‚Äôs hallucination: the model invents functions/options that do not exist.\nDefensive habits:\nrun tests immediately\nread assertions carefully\ncheck that fixtures actually model the real domain\n\n\n\n\n\n‚ÄúGenerative AI tools are changing this boring, repetitive process.‚Äù\n‚ÄúThey can automatically create detailed test suites, spot edge cases, and generate boilerplate code.‚Äù\n‚ÄúThis week shows how GitHub Copilot, Tabnine, and Blackbox AI can enhance your testing workflow.‚Äù\n‚ÄúHigh-quality tests are vital for reliable software.‚Äù\n‚ÄúThey catch bugs early and ensure new features don‚Äôt break existing code.‚Äù\n‚ÄúThey also document how the code should behave.‚Äù\n\n\n\n\n\nWeek 08‚Äôs main message: AI can draft tests quickly, but good tests require judgement.\nYour workflow should be:\nspecify behaviour ‚Üí generate tests ‚Üí run ‚Üí review assertions ‚Üí improve prompts ‚Üí repeat.\nThe fastest way to level up is to treat tests as communication: a clear story about what the code must do.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#why-testing-matters",
    "href": "notes/notes_8.html#why-testing-matters",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Week 08 focuses on using generative AI to produce tests, but this week is really about trust.\nA test suite is your ‚Äúcontract‚Äù with future you: it describes what must stay true as code changes.\nAI can write tests quickly, but speed is useless if the tests are brittle, shallow, or wrong.\n‚ÄúGenerative AI tools are changing this boring, repetitive process.‚Äù\n‚ÄúThey can automatically create detailed test suites, spot edge cases, and generate boilerplate code.‚Äù\nIn AI-assisted workflows, tests do two jobs at once:\n\ncatch regressions, and 2) detect when the AI has hallucinated an API, edge case, or assumption.\n\nA bad test suite can make things worse by giving you false confidence.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#key-terms",
    "href": "notes/notes_8.html#key-terms",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "test oracle ‚Äî what counts as correct output (and what your test is really asserting).\nfixture ‚Äî a repeatable setup/teardown wrapper that makes tests readable and reliable.\nmock ‚Äî a controlled stand‚Äëin that isolates your code from external systems.\nin‚Äëmemory database ‚Äî a temporary database (often SQLite) used for fast, isolated tests.\nregression test ‚Äî a test that locks in behaviour so future changes don‚Äôt break it.\nproperty‚Äëbased testing ‚Äî testing broad invariants by generating many inputs automatically.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#ai-workflow",
    "href": "notes/notes_8.html#ai-workflow",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Start by writing a clear spec (even if it is only a paragraph). AI cannot test what you cannot describe.\nDecide what level you are testing: unit (small), integration (multiple parts), or end-to-end (system).\nGive the AI: the function signature, expected behaviour, edge cases, and any invariants.\nAsk for tests and a short explanation of why each test exists.\n‚ÄúThis week shows how GitHub Copilot, Tabnine, and Blackbox AI can enhance your testing workflow.‚Äù\nRun the tests immediately. If they fail, treat that as feedback about either the code or the prompt.\nRefactor the generated tests: rename, remove duplicates, add missing assertions, and simplify setup.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#unittest-vs-pytest",
    "href": "notes/notes_8.html#unittest-vs-pytest",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Both frameworks can express the same logic; the difference is ergonomics and ecosystem conventions.\nunittest is batteries-included and class-based; pytest is function-first and heavily fixture-driven.\nIf a project already uses one, prefer consistency over personal preference.\nAI tends to produce verbose unittest boilerplate unless you explicitly ask for pytest.\n‚ÄúThey can help you build strong, maintain¬≠ able test suites quickly, while upholding quality.‚Äù\nAsk the AI to follow your project‚Äôs test naming and folder conventions.\nDo not accept tests that assert implementation details (e.g., exact SQL query strings) unless required.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#in-memory-db",
    "href": "notes/notes_8.html#in-memory-db",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "An in-memory DB makes tests fast and isolated: every test starts from a clean slate.\nThis week demonstrates creating temporary databases and seeding minimal data for reproducibility.\n‚Äú211 Why use generative AI for testing?‚Äù\nKey idea: tests should not depend on a developer‚Äôs local environment (paths, ports, or existing data).\nWhen you use SQLite in-memory, ensure your app‚Äôs DB layer can accept a connection string override.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#prompting-patterns",
    "href": "notes/notes_8.html#prompting-patterns",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Use prompts that are specific about assertions, not just ‚Äúwrite tests‚Äù.\nAlways list edge cases you care about (empty inputs, None/null, boundary values, malformed data).\nIf you want parameterised tests, say so explicitly.\nIf you want mocks, name the dependencies to mock and the behaviour they should simulate.\n‚ÄúHigh-quality tests are vital for reliable software.‚Äù\nAsk for one test per behaviour: big ‚Äúkitchen sink‚Äù tests are hard to debug.\nAsk the AI to include comments that link each test back to a requirement line.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#evaluating",
    "href": "notes/notes_8.html#evaluating",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Treat AI-generated tests as a draft. Your job is to make them true and useful.\nCheck: does the test actually fail when the code is wrong? (mutation testing mindset).\nCheck for false positives: tests that pass even if you delete the core logic.\nCheck for brittle fixtures: random data, timestamps, network calls, global state.\n‚ÄúThey catch bugs early and ensure new features don‚Äôt break existing code.‚Äù\nPrefer explicit assertions over printing/logging output.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#failure-modes",
    "href": "notes/notes_8.html#failure-modes",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Hallucinated imports: AI may invent packages or functions that do not exist in your environment.\nOver-mocking: if everything is mocked, you are not testing meaningful behaviour.\nTesting the wrong thing: asserting internal variable values rather than outputs or side effects.\nNondeterminism: tests that depend on ordering, random seeds, time, or network.\n‚ÄúThey also document how the code should behave.‚Äù\nFix strategy: reduce the test to the minimal reproducer, then rebuild structure with fixtures.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#ci",
    "href": "notes/notes_8.html#ci",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "A CI pipeline turns ‚Äúworks on my machine‚Äù into ‚Äúworks for everyone‚Äù.\nAI-generated tests are only valuable if they run reliably in a clean environment.\nMake dependencies explicit (requirements file / lockfile).\nPin versions when your tests rely on specific behaviour.\nKeep secrets out of tests; use environment variables and test doubles.\n\n\n\nimport pytest\n\ndef add(a, b):\n    return a + b\n\ndef test_add_basic():\n    assert add(2, 3) == 5\n\n@pytest.mark.parametrize('a,b,expected', [(0,0,0), (-1,1,0), (2,-5,-3)])\ndef test_add_parametrized(a,b,expected):\n    assert add(a,b) == expected\n\n\n\nimport unittest\n\ndef add(a, b):\n    return a + b\n\nclass TestAdd(unittest.TestCase):\n    def test_add_basic(self):\n        self.assertEqual(add(2,3), 5)\n\nif __name__ == '__main__':\n    unittest.main()\n\n\n\nimport sqlite3\n\ndef make_db():\n    conn = sqlite3.connect(':memory:')\n    cur = conn.cursor()\n    cur.execute('CREATE TABLE users(id INTEGER PRIMARY KEY, name TEXT)')\n    cur.execute('INSERT INTO users(name) VALUES (?)', ('Ada',))\n    conn.commit()\n    return conn\n\ndef test_user_seed():\n    conn = make_db()\n    cur = conn.cursor()\n    cur.execute('SELECT COUNT(*) FROM users')\n    assert cur.fetchone()[0] == 1\n\n\n\nfrom unittest.mock import Mock\n\nclass Client:\n    def __init__(self, http_get):\n        self.http_get = http_get\n\n    def fetch_status(self, url):\n        resp = self.http_get(url)\n        return resp.status_code\n\ndef test_fetch_status_mocked():\n    fake_resp = Mock()\n    fake_resp.status_code = 200\n    http_get = Mock(return_value=fake_resp)\n\n    c = Client(http_get=http_get)\n    assert c.fetch_status('https://example.com') == 200\n    http_get.assert_called_once()\n\n\n\nPROMPT = '''\nYou are generating tests for Python code.\n\nContext:\n- Framework: pytest\n- File under test: app/service.py\n- Function signatures: &lt;paste here&gt;\n\nRequirements:\n1) Write one test per requirement.\n2) Include edge cases: empty input, None, boundary values.\n3) Use fixtures for setup; avoid global state.\n4) Explain each test in 1 line comment.\n\nOutput: a complete pytest test module.\n'''\nprint(PROMPT)\n\n\n\n# Demonstration: if you break the function, does a test fail?\n\ndef area(radius):\n    return 3.14159 * radius * radius\n\ndef test_area_positive():\n    assert area(2) == 12.56636\n\n# Try changing area() to return 0 and rerun the test.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#summing-up",
    "href": "notes/notes_8.html#summing-up",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "AI is a powerful assistant for drafting tests, but you still own correctness.\nThe best prompts specify behaviour, edge cases, and constraints (framework, fixtures, mocking).\nAlways run, review, and refactor generated tests; treat them like code written by a junior dev.\nIn-memory databases and isolated environments are key to reliable automated testing.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#sanity",
    "href": "notes/notes_8.html#sanity",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Quick checklist before you trust an AI-generated test suite:\nDoes each test name describe behaviour (not implementation)?\nDo the tests include at least one negative case?\nAre edge cases explicit, not implied?\nIs the database/file system/network isolated or mocked?\nWould the tests still pass if you replaced your function body with pass?\nDo failures produce actionable error messages?\nDo fixtures reduce duplication (but not hide important details)?\nAre time-dependent values controlled (freeze time or inject clocks)?\nAre random values seeded?\nAre you asserting the right thing (outputs/side effects) rather than intermediate variables?\nMini Q&A (the kinds of questions you should be able to answer):\nWhat is a ‚Äútest oracle‚Äù and why is it hard for AI?\nWhen is mocking harmful?\nWhy is an in-memory database useful but sometimes misleading?\nHow do you know a test is not ‚Äútoo shallow‚Äù?\nWhat prompt information tends to improve assertion quality?",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#prompt-patterns-for-test-generation",
    "href": "notes/notes_8.html#prompt-patterns-for-test-generation",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Week 08 keeps returning to a simple idea: tests get better when the specification is clearer than the code.\nWhen you prompt a tool to generate tests, you are effectively writing a mini test plan.\n\n\n\n\nUse this structure (adapt the wording, keep the slots):\nSystem/role: ‚ÄúYou are a software tester writing pytest tests.‚Äù\nGoal: ‚ÄúGenerate tests for function X.‚Äù\nBehaviour spec: list rules as bullets.\nEdge cases: list edge cases explicitly.\nConstraints:\n- no network\n- no real filesystem writes\n- deterministic outcomes (freeze time or inject clock)\nOutput format: ‚ÄúReturn only test code in one file.‚Äù\nA useful trick: ask the model to first list test cases (names + what they check), then write the code.\nIf you do that, you can review the case list quickly before trusting the code.\n\n\n\n\n\nAsk for meaningful assertions rather than ‚Äújust coverage‚Äù.\nAsk for failure-mode tests:\ninvalid inputs\nboundary values\nempty collections\nmissing keys\nduplicates\nIf the code touches randomness, instruct: ‚Äúinject a seed or mock the RNG.‚Äù\n\n\n\n\n\nAsk for fixtures with clear names: user_factory, db_session, tmp_project.\nAsk the tool to explain (briefly) what each fixture is responsible for.\nIf the tool creates a fixture that does too much, split it.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#worked-example",
    "href": "notes/notes_8.html#worked-example",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Below is a deliberately small example to illustrate the workflow Week 08 argues for:\nstart with a vague prompt ‚Üí get weak tests ‚Üí tighten the prompt ‚Üí get stronger tests.\n\n\n\n#| echo: true\n#| eval: false\n\ndef normalise_score(x: float) -&gt; float:\n    \"\"\"Clamp to [0, 1] and round to 2dp.\"\"\"\n    if x != x:  # NaN\n        raise ValueError(\"NaN\")\n    if x &lt; 0:\n        return 0.0\n    if x &gt; 1:\n        return 1.0\n    return round(x, 2)\n\n\n\n\nWeak tests often:\nonly test the ‚Äúhappy path‚Äù,\nassert very little,\nmiss NaN / boundary cases.\n\n#| echo: true\n#| eval: false\n\nimport pytest\n\n\ndef test_normalise_score_basic():\n    assert normalise_score(0.2) == 0.2\n\n\n\n#| echo: true\n#| eval: false\n\nimport math\nimport pytest\n\n\ndef test_clamps_low_values_to_zero():\n    assert normalise_score(-0.0001) == 0.0\n\n\ndef test_clamps_high_values_to_one():\n    assert normalise_score(1.0001) == 1.0\n\n\ndef test_rounds_to_two_decimal_places():\n    assert normalise_score(0.126) == 0.13\n\n\ndef test_boundary_values_are_stable():\n    assert normalise_score(0.0) == 0.0\n    assert normalise_score(1.0) == 1.0\n\n\ndef test_nan_raises_value_error():\n    with pytest.raises(ValueError):\n        normalise_score(math.nan)\n\nThis is the kind of result you get when you prompt with explicit rules and edge cases.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#in-memory-databases",
    "href": "notes/notes_8.html#in-memory-databases",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Week 08 discusses isolated environments because test reliability depends on control.\nA database is a common source of hidden coupling:\nleftover rows from previous runs\nschema drift\ntests that require manual setup\n\n\n\n\nSQLite can run entirely in memory by using :memory:.\nBenefit: every test run starts from a clean slate.\nTradeoff: behaviour can differ from your production database (types, constraints, concurrency).\n\n#| echo: true\n#| eval: false\n\nimport sqlite3\n\n\ndef make_db():\n    conn = sqlite3.connect(\":memory:\")\n    cur = conn.cursor()\n    cur.execute(\"CREATE TABLE items(id INTEGER PRIMARY KEY, name TEXT)\")\n    conn.commit()\n    return conn\n\n\ndef test_insert_and_query():\n    conn = make_db()\n    cur = conn.cursor()\n    cur.execute(\"INSERT INTO items(name) VALUES (?)\", (\"apple\",))\n    conn.commit()\n    cur.execute(\"SELECT name FROM items WHERE id=1\")\n    assert cur.fetchone()[0] == \"apple\"\n\nIf you‚Äôre using an ORM (SQLAlchemy), you can build a test session bound to an in-memory engine.\nPrompt tip: explicitly name the stack (SQLite + SQLAlchemy + pytest fixtures) so the model doesn‚Äôt invent libraries.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#where-ai-tests-go-wrong",
    "href": "notes/notes_8.html#where-ai-tests-go-wrong",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Common failure patterns (and how to spot them):\nAsserting implementation details: tests break when you refactor harmlessly.\nBrittle data: hard-coded timestamps, random ids, order-dependent lists.\nMocking the wrong thing: you end up testing the mock, not the behaviour.\nTesting the tool‚Äôs hallucination: the model invents functions/options that do not exist.\nDefensive habits:\nrun tests immediately\nread assertions carefully\ncheck that fixtures actually model the real domain",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#micro-quotes-week8",
    "href": "notes/notes_8.html#micro-quotes-week8",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "‚ÄúGenerative AI tools are changing this boring, repetitive process.‚Äù\n‚ÄúThey can automatically create detailed test suites, spot edge cases, and generate boilerplate code.‚Äù\n‚ÄúThis week shows how GitHub Copilot, Tabnine, and Blackbox AI can enhance your testing workflow.‚Äù\n‚ÄúHigh-quality tests are vital for reliable software.‚Äù\n‚ÄúThey catch bugs early and ensure new features don‚Äôt break existing code.‚Äù\n‚ÄúThey also document how the code should behave.‚Äù",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "notes/notes_8.html#summing-up-week8",
    "href": "notes/notes_8.html#summing-up-week8",
    "title": "Week 08 ‚Äî Building effective tests with generative AI",
    "section": "",
    "text": "Week 08‚Äôs main message: AI can draft tests quickly, but good tests require judgement.\nYour workflow should be:\nspecify behaviour ‚Üí generate tests ‚Üí run ‚Üí review assertions ‚Üí improve prompts ‚Üí repeat.\nThe fastest way to level up is to treat tests as communication: a clear story about what the code must do.",
    "crumbs": [
      "Notes",
      "Notes 08 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_0/0.1_shorts.html",
    "href": "problems/pset_0/0.1_shorts.html",
    "title": "Shorts",
    "section": "",
    "text": "Shorts\n\nyoutube.com/playlist?list=PLhQjrBD2T381eWtNm274cXo8zxUFX-lyn\n\nAPI Calls\nBoolean Expressions\nCapture Groups\nClasses\nClass Methods and Class Variables\nConditionals\nCreating Modules and Packages\nDebugging\nDictionaries\nDictionary Methods\nFor Loops\nFunctions\nHanding Exceptions\nInstance Methods\nInstance Variables\nLists\nList and Dictionary Comprehensions\nList Methods\nPatterns\nPillow\npytest\nrandom\nRaising Exceptions\nReading and Writing CSVs\nReading and Writing Files\nRecursion\nReturn Values\nSide Effects\nString Methods\nString Slicing\nStyle\nTuples\nVariables\nVisual Studio Code for CS50\nWhile Loops"
  },
  {
    "objectID": "problems/pset_0/0.3_playback_speed.html",
    "href": "problems/pset_0/0.3_playback_speed.html",
    "title": "Playback Speed",
    "section": "",
    "text": "Some people have a habit of lecturing speaking rather quickly, and it‚Äôd be nice to slow them down, a la YouTube‚Äôs 0.75 playback speed, or even by having them pause between words.\nIn a file called playback.py, implement a program in Python that prompts the user for input and then outputs that same input, replacing each space with ... (i.e., three periods).\n\n\n\nRecall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir playback\n\nto make a folder called playback in your codespace.\nThen execute\ncd playback\n\nto change directories into that folder. You should now see your terminal prompt as playback/ $. You can now execute\ncode playback.py\n\nto make a file called playback.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python playback.py. Type This is CS50 and press Enter. Your program should output:\nThis...is...CS50    \n\nRun your program with python playback.py. Type This is our week on functions and press Enter. Your program should output:\nThis...is...our...week...on...functions\n\nRun your program with python playback.py. Type Let's implement a function called hello and press Enter. Your program should output\nLet's...implement...a...function...called...hello"
  },
  {
    "objectID": "problems/pset_0/0.3_playback_speed.html#hints",
    "href": "problems/pset_0/0.3_playback_speed.html#hints",
    "title": "Playback Speed",
    "section": "",
    "text": "Recall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods."
  },
  {
    "objectID": "problems/pset_0/0.3_playback_speed.html#before-you-begin",
    "href": "problems/pset_0/0.3_playback_speed.html#before-you-begin",
    "title": "Playback Speed",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir playback\n\nto make a folder called playback in your codespace.\nThen execute\ncd playback\n\nto change directories into that folder. You should now see your terminal prompt as playback/ $. You can now execute\ncode playback.py\n\nto make a file called playback.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_0/0.3_playback_speed.html#how-to-test",
    "href": "problems/pset_0/0.3_playback_speed.html#how-to-test",
    "title": "Playback Speed",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python playback.py. Type This is CS50 and press Enter. Your program should output:\nThis...is...CS50    \n\nRun your program with python playback.py. Type This is our week on functions and press Enter. Your program should output:\nThis...is...our...week...on...functions\n\nRun your program with python playback.py. Type Let's implement a function called hello and press Enter. Your program should output\nLet's...implement...a...function...called...hello"
  },
  {
    "objectID": "problems/pset_0/0.5_einstein.html",
    "href": "problems/pset_0/0.5_einstein.html",
    "title": "Einstein",
    "section": "",
    "text": "Even if you haven‚Äôt studied physics (recently or ever!), you might have heard that (E = mc^2), wherein (E) represents energy (measured in Joules), (m) represents mass (measured in kilograms), and (c) represents the speed of light (measured approximately as 300000000 meters per second), per Albert Einstein et al.¬†Essentially, the formula means that mass and energy are equivalent.\nIn a file called einstein.py, implement a program in Python that prompts the user for mass as an integer (in kilograms) and then outputs the equivalent number of Joules as an integer. Assume that the user will input an integer.\n\n\n\nRecall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that int can convert a str to an int, per docs.python.org/3/library/functions.html#int.\nRecall that Python comes with several built-in functions, per docs.python.org/3/library/functions.html.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir einstein\n\nto make a folder called einstein in your codespace.\nThen execute\ncd einstein\n\nto change directories into that folder. You should now see your terminal prompt as einstein/ $. You can now execute\ncode einstein.py\n\nto make a file called einstein.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python einstein.py. Type 1 and press Enter. Your program should output:\n90000000000000000\n\nRun your program with python einstein.py. Type 14 and press Enter. Your program should output:\n1260000000000000000\n\nRun your program with python einstein.py. Type 50 and press Enter. Your program should output\n4500000000000000000"
  },
  {
    "objectID": "problems/pset_0/0.5_einstein.html#hints",
    "href": "problems/pset_0/0.5_einstein.html#hints",
    "title": "Einstein",
    "section": "",
    "text": "Recall that input returns a str, per docs.python.org/3/library/functions.html#input.\nRecall that int can convert a str to an int, per docs.python.org/3/library/functions.html#int.\nRecall that Python comes with several built-in functions, per docs.python.org/3/library/functions.html."
  },
  {
    "objectID": "problems/pset_0/0.5_einstein.html#before-you-begin",
    "href": "problems/pset_0/0.5_einstein.html#before-you-begin",
    "title": "Einstein",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir einstein\n\nto make a folder called einstein in your codespace.\nThen execute\ncd einstein\n\nto change directories into that folder. You should now see your terminal prompt as einstein/ $. You can now execute\ncode einstein.py\n\nto make a file called einstein.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_0/0.5_einstein.html#how-to-test",
    "href": "problems/pset_0/0.5_einstein.html#how-to-test",
    "title": "Einstein",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python einstein.py. Type 1 and press Enter. Your program should output:\n90000000000000000\n\nRun your program with python einstein.py. Type 14 and press Enter. Your program should output:\n1260000000000000000\n\nRun your program with python einstein.py. Type 50 and press Enter. Your program should output\n4500000000000000000"
  },
  {
    "objectID": "problems/pset_0/pset_0.html",
    "href": "problems/pset_0/pset_0.html",
    "title": "Problem Set week 0",
    "section": "",
    "text": "Complete the following problems\n\nIndoor Voice\nPlayback Speed\nMaking Faces\nEinstein\nTip Calculator",
    "crumbs": [
      "Problem Sets",
      "Problem Set 00 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_0/pset_0.html#what-to-do",
    "href": "problems/pset_0/pset_0.html#what-to-do",
    "title": "Problem Set week 0",
    "section": "",
    "text": "Complete the following problems\n\nIndoor Voice\nPlayback Speed\nMaking Faces\nEinstein\nTip Calculator",
    "crumbs": [
      "Problem Sets",
      "Problem Set 00 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_1/1.3_home_federal_savings_bank.html",
    "href": "problems/pset_1/1.3_home_federal_savings_bank.html",
    "title": "Home Federal Savings Bank",
    "section": "",
    "text": "In season 7, episode 24 of Seinfeld, Kramer visits a bank that promises to give $100 to anyone who isn‚Äôt greeted with a ‚Äúhello.‚Äù Kramer is instead greeted with a ‚Äúhey,‚Äù which he insists isn‚Äôt a ‚Äúhello,‚Äù and so he asks for $100. The bank‚Äôs manager proposes a compromise: ‚ÄúYou got a greeting that starts with an ‚Äòh,‚Äô how does $20 sound?‚Äù Kramer accepts.\nIn a file called bank.py, implement a program that prompts the user for a greeting. If the greeting starts with ‚Äúhello‚Äù, output $0. If the greeting starts with an ‚Äúh‚Äù (but not ‚Äúhello‚Äù), output $20. Otherwise, output $100. Ignore any leading whitespace in the user‚Äôs greeting, and treat the user‚Äôs greeting case-insensitively.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nBe sure to give $0 not only for ‚Äúhello‚Äù but also ‚Äúhello there‚Äù, ‚Äúhello, Newman‚Äù, and the like.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir bank\n\nto make a folder called bank in your codespace.\nThen execute\ncd bank\n\nto change directories into that folder. You should now see your terminal prompt as bank/ $. You can now execute\ncode bank.py\n\nto make a file called bank.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python bank.py. Type Hello and press Enter. Your program should output:\n$0 \n\nRun your program with python bank.py. Type Hello, Newman and press Enter. Your program should output:\n$0\n\nRun your program with python bank.py. Type How you doing? and press Enter. Your program should output\n$20\n\nRun your program with python bank.py. Type What's happening? and press Enter. Your program should output\n$100"
  },
  {
    "objectID": "problems/pset_1/1.3_home_federal_savings_bank.html#hints",
    "href": "problems/pset_1/1.3_home_federal_savings_bank.html#hints",
    "title": "Home Federal Savings Bank",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nBe sure to give $0 not only for ‚Äúhello‚Äù but also ‚Äúhello there‚Äù, ‚Äúhello, Newman‚Äù, and the like."
  },
  {
    "objectID": "problems/pset_1/1.3_home_federal_savings_bank.html#before-you-begin",
    "href": "problems/pset_1/1.3_home_federal_savings_bank.html#before-you-begin",
    "title": "Home Federal Savings Bank",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir bank\n\nto make a folder called bank in your codespace.\nThen execute\ncd bank\n\nto change directories into that folder. You should now see your terminal prompt as bank/ $. You can now execute\ncode bank.py\n\nto make a file called bank.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_1/1.3_home_federal_savings_bank.html#how-to-test",
    "href": "problems/pset_1/1.3_home_federal_savings_bank.html#how-to-test",
    "title": "Home Federal Savings Bank",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python bank.py. Type Hello and press Enter. Your program should output:\n$0 \n\nRun your program with python bank.py. Type Hello, Newman and press Enter. Your program should output:\n$0\n\nRun your program with python bank.py. Type How you doing? and press Enter. Your program should output\n$20\n\nRun your program with python bank.py. Type What's happening? and press Enter. Your program should output\n$100"
  },
  {
    "objectID": "problems/pset_1/1.5_math_interpreter.html",
    "href": "problems/pset_1/1.5_math_interpreter.html",
    "title": "Math Interpreter",
    "section": "",
    "text": "Python already supports math, whereby you can write code to add, subtract, multiply, or divide values and even variables. But let‚Äôs write a program that enables users to do math, even without knowing Python.\nIn a file called interpreter.py, implement a program that prompts the user for an arithmetic expression and then calculates and outputs the result as a floating-point value formatted to one decimal place. Assume that the user‚Äôs input will be formatted as x y z, with one space between x and y and one space between y and z, wherein:\n\nx is an integer\ny is +, -, *, or /\nz is an integer\n\nFor instance, if the user inputs 1 + 1, your program should output 2.0. Assume that, if y is /, then z will not be 0.\nNote that, just as python itself is an interpreter for Python, so will your interpreter.py be an interpreter for math!\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split, which separates a str into a sequence of values, all of which can be assigned to variables at once. For instance, if expression is a str like 1 + 1, then\nx, y, z = expression.split(\" \")\n\nwill assign 1 to x, + to y, and 1 to z.\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir interpreter\n\nto make a folder called interpreter in your codespace.\nThen execute\ncd interpreter\n\nto change directories into that folder. You should now see your terminal prompt as interpreter/ $. You can now execute\ncode interpreter.py\n\nto make a file called interpreter.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python interpreter.py. Type 1 + 1 and press Enter. Your program should output:\n2.0 \n\nRun your program with python interpreter.py. Type 2 - 3 and press Enter. Your program should output:\n-1.0\n\nRun your program with python interpreter.py. Type 2 * 2 and press Enter. Your program should output\n4.0\n\nRun your program with python interpreter.py. Type 50 / 5 and press Enter. Your program should output\n10.0"
  },
  {
    "objectID": "problems/pset_1/1.5_math_interpreter.html#hints",
    "href": "problems/pset_1/1.5_math_interpreter.html#hints",
    "title": "Math Interpreter",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split, which separates a str into a sequence of values, all of which can be assigned to variables at once. For instance, if expression is a str like 1 + 1, then\nx, y, z = expression.split(\" \")\n\nwill assign 1 to x, + to y, and 1 to z."
  },
  {
    "objectID": "problems/pset_1/1.5_math_interpreter.html#before-you-begin",
    "href": "problems/pset_1/1.5_math_interpreter.html#before-you-begin",
    "title": "Math Interpreter",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir interpreter\n\nto make a folder called interpreter in your codespace.\nThen execute\ncd interpreter\n\nto change directories into that folder. You should now see your terminal prompt as interpreter/ $. You can now execute\ncode interpreter.py\n\nto make a file called interpreter.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_1/1.5_math_interpreter.html#how-to-test",
    "href": "problems/pset_1/1.5_math_interpreter.html#how-to-test",
    "title": "Math Interpreter",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python interpreter.py. Type 1 + 1 and press Enter. Your program should output:\n2.0 \n\nRun your program with python interpreter.py. Type 2 - 3 and press Enter. Your program should output:\n-1.0\n\nRun your program with python interpreter.py. Type 2 * 2 and press Enter. Your program should output\n4.0\n\nRun your program with python interpreter.py. Type 50 / 5 and press Enter. Your program should output\n10.0"
  },
  {
    "objectID": "problems/pset_1/pset_1.html",
    "href": "problems/pset_1/pset_1.html",
    "title": "Problem Set week 1",
    "section": "",
    "text": "Complete the following problems\n\nDeep Thought\nHome Federal Savings Bank\nFile Extensions\nMath Interpreter\nMeal Time",
    "crumbs": [
      "Problem Sets",
      "Problem Set 01 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_1/pset_1.html#what-to-do",
    "href": "problems/pset_1/pset_1.html#what-to-do",
    "title": "Problem Set week 1",
    "section": "",
    "text": "Complete the following problems\n\nDeep Thought\nHome Federal Savings Bank\nFile Extensions\nMath Interpreter\nMeal Time",
    "crumbs": [
      "Problem Sets",
      "Problem Set 01 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_2/2.3_coke_machine.html",
    "href": "problems/pset_2/2.3_coke_machine.html",
    "title": "Coke Machine",
    "section": "",
    "text": "CS50 Coke Bottle\n\n\nSuppose that a machine sells bottles of Coca-Cola (Coke) for 50 cents and only accepts coins in these denominations: 25 cents, 10 cents, and 5 cents.\nIn a file called coke.py, implement a program that prompts the user to insert a coin, one at a time, each time informing the user of the amount due. Once the user has inputted at least 50 cents, output how many cents in change the user is owed. Assume that the user will only input integers, and ignore any integer that isn‚Äôt an accepted denomination.\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir coke\n\nto make a folder called coke in your codespace.\nThen execute\ncd coke\n\nto change directories into that folder. You should now see your terminal prompt as coke/ $. You can now execute\ncode coke.py\n\nto make a file called coke.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter. Your program should output:\nAmount Due: 25   \n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 10 and press Enter. Your program should output:\nAmount Due: 40\n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 5 and press Enter. Your program should output:\nAmount Due: 45\n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 30 and press Enter. Your program should output:\nAmount Due: 50\n\nbecause the machine doesn‚Äôt accept 30-cent coins! Your program should then continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter, then type 25 again and press Enter. Your program should halt and display:\nChange Owed: 0\n\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter, then type 10 and press Enter. Type 25 again and press Enter, after which your program should halt and display:\nChange Owed: 10"
  },
  {
    "objectID": "problems/pset_2/2.3_coke_machine.html#before-you-begin",
    "href": "problems/pset_2/2.3_coke_machine.html#before-you-begin",
    "title": "Coke Machine",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir coke\n\nto make a folder called coke in your codespace.\nThen execute\ncd coke\n\nto change directories into that folder. You should now see your terminal prompt as coke/ $. You can now execute\ncode coke.py\n\nto make a file called coke.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_2/2.3_coke_machine.html#how-to-test",
    "href": "problems/pset_2/2.3_coke_machine.html#how-to-test",
    "title": "Coke Machine",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter. Your program should output:\nAmount Due: 25   \n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 10 and press Enter. Your program should output:\nAmount Due: 40\n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 5 and press Enter. Your program should output:\nAmount Due: 45\n\nand continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 30 and press Enter. Your program should output:\nAmount Due: 50\n\nbecause the machine doesn‚Äôt accept 30-cent coins! Your program should then continue prompting the user for coins.\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter, then type 25 again and press Enter. Your program should halt and display:\nChange Owed: 0\n\nRun your program with python coke.py. At your Insert Coin: prompt, type 25 and press Enter, then type 10 and press Enter. Type 25 again and press Enter, after which your program should halt and display:\nChange Owed: 10"
  },
  {
    "objectID": "problems/pset_2/2.5_vanity_plates.html",
    "href": "problems/pset_2/2.5_vanity_plates.html",
    "title": "Vanity Plates",
    "section": "",
    "text": "CS50 license plate\n\n\nIn the UK, like in a lot of places, it‚Äôs possible to request a vanity registration plate for your vehicle for your car, with your choice of letters and numbers instead of random ones.\nImagine these requirements:\n\n‚ÄúAll vanity plates must start with at least two letters.‚Äù\n‚Äú‚Ä¶ vanity plates may contain a maximum of 6 characters (letters or numbers) and a minimum of 2 characters.‚Äù\n‚ÄúNumbers cannot be used in the middle of a plate; they must come at the end. For example, AAA222 would be an acceptable ‚Ä¶ vanity plate; AAA22A would not be acceptable. The first number used cannot be a ‚Äò0‚Äô.‚Äù\n‚ÄúNo periods, spaces, or punctuation marks are allowed.‚Äù\n\nIn plates.py, implement a program that prompts the user for a vanity plate and then output Valid if meets all of the requirements or Invalid if it does not. Assume that any letters in the user‚Äôs input will be uppercase. Structure your program per the below, wherein is_valid returns True if s meets all requirements and False if it does not. Assume that s will be a str. You‚Äôre welcome to implement additional functions for is_valid to call (e.g., one function per requirement).\ndef main():\n    plate = input(\"Plate: \")\n    if is_valid(plate):\n        print(\"Valid\")\n    else:\n        print(\"Invalid\")\n\n\ndef is_valid(s):\n    ...\n\n\nmain()\n\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is a ‚Äúsequence‚Äù (of characters), which means it can be ‚Äúsliced‚Äù into shorter strings with syntax like s[i:j]. For instance, if s is \"CS50\", then s[0:2] would be \"CS\".\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir plates\n\nto make a folder called plates in your codespace.\nThen execute\ncd plates\n\nto change directories into that folder. You should now see your terminal prompt as plates/ $. You can now execute\ncode plates.py\n\nto make a file called plates.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python plates.py. Type CS50 and press Enter. Your program should output:\nValid\n\nRun your program with python plates.py. Type CS05 and press Enter. Your program should output:\nInvalid\n\nRun your program with python plates.py. Type CS50P and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type PI3.14 and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type H and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type OUTATIME and press Enter. Your program should output\nInvalid"
  },
  {
    "objectID": "problems/pset_2/2.5_vanity_plates.html#hints",
    "href": "problems/pset_2/2.5_vanity_plates.html#hints",
    "title": "Vanity Plates",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods.\nMuch like a list, a str is a ‚Äúsequence‚Äù (of characters), which means it can be ‚Äúsliced‚Äù into shorter strings with syntax like s[i:j]. For instance, if s is \"CS50\", then s[0:2] would be \"CS\"."
  },
  {
    "objectID": "problems/pset_2/2.5_vanity_plates.html#before-you-begin",
    "href": "problems/pset_2/2.5_vanity_plates.html#before-you-begin",
    "title": "Vanity Plates",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir plates\n\nto make a folder called plates in your codespace.\nThen execute\ncd plates\n\nto change directories into that folder. You should now see your terminal prompt as plates/ $. You can now execute\ncode plates.py\n\nto make a file called plates.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_2/2.5_vanity_plates.html#how-to-test",
    "href": "problems/pset_2/2.5_vanity_plates.html#how-to-test",
    "title": "Vanity Plates",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python plates.py. Type CS50 and press Enter. Your program should output:\nValid\n\nRun your program with python plates.py. Type CS05 and press Enter. Your program should output:\nInvalid\n\nRun your program with python plates.py. Type CS50P and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type PI3.14 and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type H and press Enter. Your program should output\nInvalid\n\nRun your program with python plates.py. Type OUTATIME and press Enter. Your program should output\nInvalid"
  },
  {
    "objectID": "problems/pset_2/pset_2.html",
    "href": "problems/pset_2/pset_2.html",
    "title": "Problem Set week 2",
    "section": "",
    "text": "Complete the following problems\n\ncamelCase\nCoke Machine\nJust setting up my twttr\nVanity Plates\nNutrition Facts",
    "crumbs": [
      "Problem Sets",
      "Problem Set 02 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_2/pset_2.html#what-to-do",
    "href": "problems/pset_2/pset_2.html#what-to-do",
    "title": "Problem Set week 2",
    "section": "",
    "text": "Complete the following problems\n\ncamelCase\nCoke Machine\nJust setting up my twttr\nVanity Plates\nNutrition Facts",
    "crumbs": [
      "Problem Sets",
      "Problem Set 02 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_3/3.3_felipes_taqueria.html",
    "href": "problems/pset_3/3.3_felipes_taqueria.html",
    "title": "Felipe‚Äôs Taqueria",
    "section": "",
    "text": "Felipe‚Äôs Taqueria\n\n\nA popular places to eat in Harvard Square is Felipe‚Äôs Taqueria, which offers a menu of entrees, per the dict below, wherein the value of each key is a price in dollars:\n{\n    \"Baja Taco\": 4.25,\n    \"Burrito\": 7.50,\n    \"Bowl\": 8.50,\n    \"Nachos\": 11.00,\n    \"Quesadilla\": 8.50,\n    \"Super Burrito\": 8.50,\n    \"Super Quesadilla\": 9.50,\n    \"Taco\": 3.00,\n    \"Tortilla Salad\": 8.00\n}\n\nIn a file called taqueria.py, implement a program that enables a user to place an order, prompting them for items, one per line, until the user inputs control-d (which is a common way of ending one‚Äôs input to a program). After each inputted item, display the total cost of all items inputted thus far, prefixed with a dollar sign ($) and formatted to two decimal places. Treat the user‚Äôs input case insensitively. Ignore any input that isn‚Äôt an item. Assume that every item on the menu will be titlecased.\n\n\n\nNote that you can detect when the user has inputted control-d by catching an EOFError with code like:\ntry:\n    item = input()\nexcept EOFError:\n    ...\n\nYou might want to print a new line so that the user‚Äôs cursor (and subsequent prompt) doesn‚Äôt remain on the same line as your program‚Äôs own prompt.\nInputting control-d does not require inputting Enter as well, and so the user‚Äôs cursor (and subsequent prompt) might thus remain on the same line as your program‚Äôs own prompt. You can move the user‚Äôs cursor to a new line by printing \\n yourself!\nNote that a dict comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#mapping-types-dict, among them get, and supports operations like:\nd[key]\n\nand\nif key in d:\n    ...\n\nwherein d is a dict and key is a str.\nBe sure to avoid or catch any KeyError.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir taqueria\n\nto make a folder called taqueria in your codespace.\nThen execute\ncd taqueria\n\nto change directories into that folder. You should now see your terminal prompt as taqueria/ $. You can now execute\ncode taqueria.py\n\nto make a file called taqueria.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python taqueria.py. Type Taco and press Enter, then type Taco again and press Enter. Your program should output:\nTotal: $6.00  \n\nand continue prompting the user until they input control-d.\nRun your program with python taqueria.py. Type Baja Taco and press Enter, then type Tortilla Salad and press enter. Your program should output:\nTotal: $12.25\n\nand continue prompting the user until they input control-d.\nRun your program with python taqueria.py. Type Burger and press Enter. Your program should reprompt the user.\n\nBe sure to try other foods and vary the casing of your input. Your program should behave as expected, case-insensitively."
  },
  {
    "objectID": "problems/pset_3/3.3_felipes_taqueria.html#hints",
    "href": "problems/pset_3/3.3_felipes_taqueria.html#hints",
    "title": "Felipe‚Äôs Taqueria",
    "section": "",
    "text": "Note that you can detect when the user has inputted control-d by catching an EOFError with code like:\ntry:\n    item = input()\nexcept EOFError:\n    ...\n\nYou might want to print a new line so that the user‚Äôs cursor (and subsequent prompt) doesn‚Äôt remain on the same line as your program‚Äôs own prompt.\nInputting control-d does not require inputting Enter as well, and so the user‚Äôs cursor (and subsequent prompt) might thus remain on the same line as your program‚Äôs own prompt. You can move the user‚Äôs cursor to a new line by printing \\n yourself!\nNote that a dict comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#mapping-types-dict, among them get, and supports operations like:\nd[key]\n\nand\nif key in d:\n    ...\n\nwherein d is a dict and key is a str.\nBe sure to avoid or catch any KeyError."
  },
  {
    "objectID": "problems/pset_3/3.3_felipes_taqueria.html#before-you-begin",
    "href": "problems/pset_3/3.3_felipes_taqueria.html#before-you-begin",
    "title": "Felipe‚Äôs Taqueria",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir taqueria\n\nto make a folder called taqueria in your codespace.\nThen execute\ncd taqueria\n\nto change directories into that folder. You should now see your terminal prompt as taqueria/ $. You can now execute\ncode taqueria.py\n\nto make a file called taqueria.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_3/3.3_felipes_taqueria.html#how-to-test",
    "href": "problems/pset_3/3.3_felipes_taqueria.html#how-to-test",
    "title": "Felipe‚Äôs Taqueria",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python taqueria.py. Type Taco and press Enter, then type Taco again and press Enter. Your program should output:\nTotal: $6.00  \n\nand continue prompting the user until they input control-d.\nRun your program with python taqueria.py. Type Baja Taco and press Enter, then type Tortilla Salad and press enter. Your program should output:\nTotal: $12.25\n\nand continue prompting the user until they input control-d.\nRun your program with python taqueria.py. Type Burger and press Enter. Your program should reprompt the user.\n\nBe sure to try other foods and vary the casing of your input. Your program should behave as expected, case-insensitively."
  },
  {
    "objectID": "problems/pset_3/3.5_outdated.html",
    "href": "problems/pset_3/3.5_outdated.html",
    "title": "Outdated",
    "section": "",
    "text": "In the United States, dates are typically formatted in month-day-year order (MM/DD/YYYY), otherwise known as middle-endian order, which is arguably bad design. Dates in that format can‚Äôt be easily sorted because the date‚Äôs year comes last instead of first. Try sorting, for instance, 2/2/1800, 3/3/1900, and 1/1/2000 chronologically in any program (e.g., a spreadsheet). Dates in that format are also ambiguous. Harvard was founded on September 8, 1636, but 9/8/1636 could also be interpreted as August 9, 1636!\nFortunately, computers tend to use ISO 8601, an international standard that prescribes that dates should be formatted in year-month-day (YYYY-MM-DD) order, no matter the country, formatting years with four digits, months with two digits, and days with two digits, ‚Äúpadding‚Äù each with leading zeroes as needed.\nIn a file called outdated.py, implement a program that prompts the user for a date, anno Domini, in month-day-year order, formatted like 9/8/1636 or September 8, 1636, wherein the month in the latter might be any of the values in the list below:\n[\n    \"January\",\n    \"February\",\n    \"March\",\n    \"April\",\n    \"May\",\n    \"June\",\n    \"July\",\n    \"August\",\n    \"September\",\n    \"October\",\n    \"November\",\n    \"December\"\n]\n\nThen output that same date in YYYY-MM-DD format. If the user‚Äôs input is not a valid date in either format, prompt the user again. Assume that every month has no more than 31 days; no need to validate whether a month has 28, 29, 30, or 31 days.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split.\nRecall that a list comes with quite a few methods, per docs.python.org/3/tutorial/datastructures.html#more-on-lists, among which is index.\nNote that you can format an int with leading zeroes with code like\nprint(f\"{n:02}\")\n\nwherein, if n is a single digit, it will be prefixed with one 0, per docs.python.org/3/library/string.html#format-string-syntax.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir outdated\n\nto make a folder called outdated in your codespace.\nThen execute\ncd outdated\n\nto change directories into that folder. You should now see your terminal prompt as outdated/ $. You can now execute\ncode outdated.py\n\nto make a file called outdated.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python outdated.py. Type 9/8/1636 and press Enter. Your program should output:\n1636-09-08\n\nRun your program with python outdated.py. Type September 8, 1636 and press Enter. Your program should output:\n1636-09-08\n\nRun your program with python outdated.py. Type 23/6/1912 and press Enter. Your program should reprompt the user.\nRun your program with python outdated.py. Type December 80, 1980 and press Enter. Your program should reprompt the user."
  },
  {
    "objectID": "problems/pset_3/3.5_outdated.html#hints",
    "href": "problems/pset_3/3.5_outdated.html#hints",
    "title": "Outdated",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including split.\nRecall that a list comes with quite a few methods, per docs.python.org/3/tutorial/datastructures.html#more-on-lists, among which is index.\nNote that you can format an int with leading zeroes with code like\nprint(f\"{n:02}\")\n\nwherein, if n is a single digit, it will be prefixed with one 0, per docs.python.org/3/library/string.html#format-string-syntax."
  },
  {
    "objectID": "problems/pset_3/3.5_outdated.html#before-you-begin",
    "href": "problems/pset_3/3.5_outdated.html#before-you-begin",
    "title": "Outdated",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir outdated\n\nto make a folder called outdated in your codespace.\nThen execute\ncd outdated\n\nto change directories into that folder. You should now see your terminal prompt as outdated/ $. You can now execute\ncode outdated.py\n\nto make a file called outdated.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_3/3.5_outdated.html#how-to-test",
    "href": "problems/pset_3/3.5_outdated.html#how-to-test",
    "title": "Outdated",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python outdated.py. Type 9/8/1636 and press Enter. Your program should output:\n1636-09-08\n\nRun your program with python outdated.py. Type September 8, 1636 and press Enter. Your program should output:\n1636-09-08\n\nRun your program with python outdated.py. Type 23/6/1912 and press Enter. Your program should reprompt the user.\nRun your program with python outdated.py. Type December 80, 1980 and press Enter. Your program should reprompt the user."
  },
  {
    "objectID": "problems/pset_4/4.2_emojize.html",
    "href": "problems/pset_4/4.2_emojize.html",
    "title": "Emojize",
    "section": "",
    "text": "Because emoji aren‚Äôt quite as easy to type as text, at least on laptops and desktops, some programs support ‚Äúcodes,‚Äù whereby you can type, for instance, :thumbs_up:, which will be automatically converted to üëç. Some programs additionally support aliases, whereby you can more succinctly type, for instance, :thumbsup:, which will also be automatically converted to üëç.\nSee carpedm20.github.io/emoji/all.html?enableList=enable_list_alias for a list of codes with aliases.\nIn a file called emojize.py, implement a program that prompts the user for a str in English and then outputs the ‚Äúemojized‚Äù version of that str, converting any codes (or aliases) therein to their corresponding emoji.\n\n\n\nNote that the emoji module comes with two functions, per pypi.org/project/emoji, one of which is emojize, which takes an optional, named parameter called language. You can install it with:\npip install emoji\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir emojize\n\nto make a folder called emojize in your codespace.\nThen execute\ncd emojize\n\nto change directories into that folder. You should now see your terminal prompt as emojize/ $. You can now execute\ncode emojize.py\n\nto make a file called emojize.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python emojize.py. Type :1st_place_medal: and press Enter. Your program should output:\nOutput: ü•á\n\nRun your program with python emojize.py. Type :money_bag: and press Enter. Your program should output:\nOutput: üí∞\n\nRun your program with python emojize.py. Type :smile_cat: and press Enter. Your program should output:\nOutput: üò∏"
  },
  {
    "objectID": "problems/pset_4/4.2_emojize.html#hints",
    "href": "problems/pset_4/4.2_emojize.html#hints",
    "title": "Emojize",
    "section": "",
    "text": "Note that the emoji module comes with two functions, per pypi.org/project/emoji, one of which is emojize, which takes an optional, named parameter called language. You can install it with:\npip install emoji"
  },
  {
    "objectID": "problems/pset_4/4.2_emojize.html#before-you-begin",
    "href": "problems/pset_4/4.2_emojize.html#before-you-begin",
    "title": "Emojize",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir emojize\n\nto make a folder called emojize in your codespace.\nThen execute\ncd emojize\n\nto change directories into that folder. You should now see your terminal prompt as emojize/ $. You can now execute\ncode emojize.py\n\nto make a file called emojize.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.2_emojize.html#how-to-test",
    "href": "problems/pset_4/4.2_emojize.html#how-to-test",
    "title": "Emojize",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python emojize.py. Type :1st_place_medal: and press Enter. Your program should output:\nOutput: ü•á\n\nRun your program with python emojize.py. Type :money_bag: and press Enter. Your program should output:\nOutput: üí∞\n\nRun your program with python emojize.py. Type :smile_cat: and press Enter. Your program should output:\nOutput: üò∏"
  },
  {
    "objectID": "problems/pset_4/4.4_adieu_adieu.html",
    "href": "problems/pset_4/4.4_adieu_adieu.html",
    "title": "Adieu, Adieu",
    "section": "",
    "text": "In The Sound of Music, there‚Äôs a song sung largely in English, So Long, Farewell, with these lyrics, wherein ‚Äúadieu‚Äù means ‚Äúgoodbye‚Äù in French:\n\nAdieu, adieu, to yieu and yieu and yieu\n\nOf course, the line isn‚Äôt grammatically correct, since it would typically be written (with an Oxford comma) as:\n\nAdieu, adieu, to yieu, yieu, and yieu\n\nTo be fair, ‚Äúyieu‚Äù isn‚Äôt even a word; it just rhymes with ‚Äúyou‚Äù!\nIn a file called adieu.py, implement a program that prompts the user for names, one per line, until the user inputs control-d.¬†Assume that the user will input at least one name. Then bid adieu to those names, separating two names with one and, three names with two commas and one and, and (n) names with (n-1) commas and one and, as in the below:\n\nAdieu, adieu, to Liesl\nAdieu, adieu, to Liesl and Friedrich\nAdieu, adieu, to Liesl, Friedrich, and Louisa\nAdieu, adieu, to Liesl, Friedrich, Louisa, and Kurt\nAdieu, adieu, to Liesl, Friedrich, Louisa, Kurt, and Brigitta\nAdieu, adieu, to Liesl, Friedrich, Louisa, Kurt, Brigitta, and Marta\nAdieu, adieu, to Liesl, Friedrich, Louisa, Kurt, Brigitta, Marta, and Gretl\n\n\n\n\nNote that the inflect module comes with quite a few methods, per pypi.org/project/inflect. You can install it with:\npip install inflect\n\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir adieu\n\nto make a folder called adieu in your codespace.\nThen execute\ncd adieu\n\nto change directories into that folder. You should now see your terminal prompt as adieu/ $. You can now execute\ncode adieu.py\n\nto make a file called adieu.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python adieu.py. Type Liesl and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl \n\nRun your program with python adieu.py. Type Liesl and press Enter, then type Friedrich and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl and Friedrich\n\nRun your program with python adieu.py. Type Liesl and press Enter, then type Friedrich and press Enter. Now type Louisa and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl, Friedrich, and Louisa"
  },
  {
    "objectID": "problems/pset_4/4.4_adieu_adieu.html#hints",
    "href": "problems/pset_4/4.4_adieu_adieu.html#hints",
    "title": "Adieu, Adieu",
    "section": "",
    "text": "Note that the inflect module comes with quite a few methods, per pypi.org/project/inflect. You can install it with:\npip install inflect"
  },
  {
    "objectID": "problems/pset_4/4.4_adieu_adieu.html#before-you-begin",
    "href": "problems/pset_4/4.4_adieu_adieu.html#before-you-begin",
    "title": "Adieu, Adieu",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir adieu\n\nto make a folder called adieu in your codespace.\nThen execute\ncd adieu\n\nto change directories into that folder. You should now see your terminal prompt as adieu/ $. You can now execute\ncode adieu.py\n\nto make a file called adieu.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.4_adieu_adieu.html#how-to-test",
    "href": "problems/pset_4/4.4_adieu_adieu.html#how-to-test",
    "title": "Adieu, Adieu",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python adieu.py. Type Liesl and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl \n\nRun your program with python adieu.py. Type Liesl and press Enter, then type Friedrich and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl and Friedrich\n\nRun your program with python adieu.py. Type Liesl and press Enter, then type Friedrich and press Enter. Now type Louisa and press Enter, followed by control-d.¬†Your program should output:\nAdieu, adieu, to Liesl, Friedrich, and Louisa"
  },
  {
    "objectID": "problems/pset_4/4.6_little_professor.html",
    "href": "problems/pset_4/4.6_little_professor.html",
    "title": "Little Professor",
    "section": "",
    "text": "One of David‚Äôs first toys as a child, funny enough, was Little Professor, a ‚Äúcalculator‚Äù that would generate ten different math problems for David to solve. For instance, if the toy were to display 4 + 0 = , David would (hopefully) answer with 4. If the toy were to display 4 + 1 = , David would (hopefully) answer with 5. If David were to answer incorrectly, the toy would display EEE. And after three incorrect answers for the same problem, the toy would simply display the correct answer (e.g., 4 + 0 = 4 or 4 + 1 = 5).\nIn a file called professor.py, implement a program that:\n\nPrompts the user for a level, (n). If the user does not input 1, 2, or 3, the program should prompt again.\nRandomly generates ten (10) math problems formatted as X + Y = , wherein each of X and Y is a non-negative integer with (n) digits. No need to support operations other than addition (+).\n\nNote: The order in which you generate x and y matters. Your program should generate random numbers in x, y pairs to simulate generating one math question at a time (e.g., x0 with y0, x1 with y1, and so on).\n\nPrompts the user to solve each of those problems. If an answer is not correct (or not even a number), the program should output EEE and prompt the user again, allowing the user up to three tries in total for that problem. If the user has still not answered correctly after three tries, the program should output the correct answer.\nThe program should ultimately output the user‚Äôs score: the number of correct answers out of 10.\n\nStructure your program as follows, wherein get_level prompts (and, if need be, re-prompts) the user for a level and returns 1, 2, or 3, and generate_integer returns a single randomly generated non-negative integer with level digits or raises a ValueError if level is not 1, 2, or 3:\nimport random\n\n\ndef main():\n    ...\n\n\ndef get_level():\n    ...\n\n\ndef generate_integer(level):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n\n\nNote that you can raise an exception like ValueError with code like:\nraise ValueError\n\nNote that the random module comes with quite a few functions, per docs.python.org/3/library/random.html. Of particular interest, perhaps, are the functions specialized for returning integers, such as randint and randrange.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir professor\n\nto make a folder called professor in your codespace.\nThen execute\ncd professor\n\nto change directories into that folder. You should now see your terminal prompt as professor/ $. You can now execute\ncode professor.py\n\nto make a file called professor.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python professor.py. Type -1 and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python professor.py. Type 4 and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python professor.py. Type 1 and press Enter. Your program should begin posing addition problems with positive, single-digit integers. For example:\n6 + 6 =\n\nYour program should output 10 distinct problems before printing the number of questions you answered correctly and exiting.\nRun your program with python professor.py. Type 1 and press Enter. Answer the first question incorrectly. Your program should output:\nEEE\n\nbefore reprompting you with the same question.\nRun your program with python professor.py. Type 1 and press Enter. Answer the first question incorrectly, three times. Your program should output the correct answer. For example:\n6 + 6 = 12\n\nand then move on to another question. Answer the remaining questions correctly. Your program should output a score of 9.\nRun your program with python professor.py. Type 1 and press Enter. Answer all 10 questions correctly. Your program should output a score of 10."
  },
  {
    "objectID": "problems/pset_4/4.6_little_professor.html#hints",
    "href": "problems/pset_4/4.6_little_professor.html#hints",
    "title": "Little Professor",
    "section": "",
    "text": "Note that you can raise an exception like ValueError with code like:\nraise ValueError\n\nNote that the random module comes with quite a few functions, per docs.python.org/3/library/random.html. Of particular interest, perhaps, are the functions specialized for returning integers, such as randint and randrange."
  },
  {
    "objectID": "problems/pset_4/4.6_little_professor.html#before-you-begin",
    "href": "problems/pset_4/4.6_little_professor.html#before-you-begin",
    "title": "Little Professor",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir professor\n\nto make a folder called professor in your codespace.\nThen execute\ncd professor\n\nto change directories into that folder. You should now see your terminal prompt as professor/ $. You can now execute\ncode professor.py\n\nto make a file called professor.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_4/4.6_little_professor.html#how-to-test",
    "href": "problems/pset_4/4.6_little_professor.html#how-to-test",
    "title": "Little Professor",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python professor.py. Type -1 and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python professor.py. Type 4 and press Enter. Your program should reprompt you:\nLevel:\n\nRun your program with python professor.py. Type 1 and press Enter. Your program should begin posing addition problems with positive, single-digit integers. For example:\n6 + 6 =\n\nYour program should output 10 distinct problems before printing the number of questions you answered correctly and exiting.\nRun your program with python professor.py. Type 1 and press Enter. Answer the first question incorrectly. Your program should output:\nEEE\n\nbefore reprompting you with the same question.\nRun your program with python professor.py. Type 1 and press Enter. Answer the first question incorrectly, three times. Your program should output the correct answer. For example:\n6 + 6 = 12\n\nand then move on to another question. Answer the remaining questions correctly. Your program should output a score of 9.\nRun your program with python professor.py. Type 1 and press Enter. Answer all 10 questions correctly. Your program should output a score of 10."
  },
  {
    "objectID": "problems/pset_4/pset_4.html",
    "href": "problems/pset_4/pset_4.html",
    "title": "Problem Set week 4",
    "section": "",
    "text": "Complete the following problems\n\nEmojize\nFrank, Ian and Glen‚Äôs Letters\nAdieu, Adieu\nGuessing Game\nLittle Professor\nBitcoin Price Index",
    "crumbs": [
      "Problem Sets",
      "Problem Set 04 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_4/pset_4.html#what-to-do",
    "href": "problems/pset_4/pset_4.html#what-to-do",
    "title": "Problem Set week 4",
    "section": "",
    "text": "Complete the following problems\n\nEmojize\nFrank, Ian and Glen‚Äôs Letters\nAdieu, Adieu\nGuessing Game\nLittle Professor\nBitcoin Price Index",
    "crumbs": [
      "Problem Sets",
      "Problem Set 04 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_5/5.3_back_to_the_bank.html",
    "href": "problems/pset_5/5.3_back_to_the_bank.html",
    "title": "Back to the Bank",
    "section": "",
    "text": "In a file called bank.py, reimplement Home Federal Savings Bank from Problem Set 1, restructuring your code per the below, wherein value expects a str as input and returns an int, namely 0 if that str starts with ‚Äúhello‚Äù, 20 if that str starts with an ‚Äúh‚Äù (but not ‚Äúhello‚Äù), or 100 otherwise, treating the str case-insensitively. You can assume that the string passed to the value function will not contain any leading spaces. Only main should call print.\ndef main():\n    ...\n\n\ndef value(greeting):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\nThen, in a file called test_bank.py, implement three or more functions that collectively test your implementation of value thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_bank.py\n\n\n\n\nBe sure to include\nimport bank\n\nor\nfrom bank import value\n\natop test_bank.py so that you can call value in your tests.\nTake care to return, not print, an int in value. Only main should call print.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_bank\n\nto make a folder called test_bank in your codespace.\nThen execute\ncd test_bank\n\nto change directories into that folder. You should now see your terminal prompt as test_bank/ $. You can now execute\ncode test_bank.py\n\nto make a file called test_bank.py where you‚Äôll write your tests.\n\n\n\nTo test your tests, run pytest test_bank.py. Be sure you have a copy of a bank.py file in the same folder. Try to use correct and incorrect versions of bank.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of bank.py. Run your tests by executing pytest test_bank.py. pytest should show that all of your tests have passed.\nModify the correct version of bank.py, changing the values provided for each greeting. Your program might, for example, mistakenly provide $100 to a customer greeted by ‚ÄúHello‚Äù and $0 to a customer greeted with ‚ÄúWhat‚Äôs up‚Äù! Now, run your tests by executing pytest test_bank.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.3_back_to_the_bank.html#hints",
    "href": "problems/pset_5/5.3_back_to_the_bank.html#hints",
    "title": "Back to the Bank",
    "section": "",
    "text": "Be sure to include\nimport bank\n\nor\nfrom bank import value\n\natop test_bank.py so that you can call value in your tests.\nTake care to return, not print, an int in value. Only main should call print."
  },
  {
    "objectID": "problems/pset_5/5.3_back_to_the_bank.html#before-you-begin",
    "href": "problems/pset_5/5.3_back_to_the_bank.html#before-you-begin",
    "title": "Back to the Bank",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_bank\n\nto make a folder called test_bank in your codespace.\nThen execute\ncd test_bank\n\nto change directories into that folder. You should now see your terminal prompt as test_bank/ $. You can now execute\ncode test_bank.py\n\nto make a file called test_bank.py where you‚Äôll write your tests."
  },
  {
    "objectID": "problems/pset_5/5.3_back_to_the_bank.html#how-to-test",
    "href": "problems/pset_5/5.3_back_to_the_bank.html#how-to-test",
    "title": "Back to the Bank",
    "section": "",
    "text": "To test your tests, run pytest test_bank.py. Be sure you have a copy of a bank.py file in the same folder. Try to use correct and incorrect versions of bank.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of bank.py. Run your tests by executing pytest test_bank.py. pytest should show that all of your tests have passed.\nModify the correct version of bank.py, changing the values provided for each greeting. Your program might, for example, mistakenly provide $100 to a customer greeted by ‚ÄúHello‚Äù and $0 to a customer greeted with ‚ÄúWhat‚Äôs up‚Äù! Now, run your tests by executing pytest test_bank.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.5_refueling.html",
    "href": "problems/pset_5/5.5_refueling.html",
    "title": "Refueling",
    "section": "",
    "text": "In a file called fuel.py, reimplement Fuel Gauge from Problem Set 3, restructuring your code per the below, wherein:\n\nconvert expects a str in X/Y format as input, wherein each of X and Y is a positive integer, and returns that fraction as a percentage rounded to the nearest int between 0 and 100, inclusive. If X and/or Y is not an integer, or if X is greater than Y, then convert should raise a ValueError. If Y is 0, then convert should raise a ZeroDivisionError.\ngauge expects an int and returns a str that is:\n\n\"E\" if that int is less than or equal to 1,\n\"F\" if that int is greater than or equal to 99,\nand \"Z%\" otherwise, wherein Z is that same int.\n\n\ndef main():\n    ...\n\n\ndef convert(fraction):\n    ...\n\n\ndef gauge(percentage):\n    ...\n\n\nif __name__ == \"__main__\":\n    main()\n\nThen, in a file called test_fuel.py, implement two or more functions that collectively test your implementations of convert and gauge thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_fuel.py\n\n\n\n\nBe sure to include\nimport fuel\n\nor\nfrom fuel import convert, gauge\n\natop test_fuel.py so that you can call convert and gauge in your tests.\nTake care to return, not print, an int in convert and a str in gauge. Only main should call print.\nNote that you can raise an exception like ValueError with code like:\nraise ValueError\n\nNote that you can check with pytest whether a function has raised an exception, per docs.pytest.org/en/latest/how-to/assert.html#assertions-about-expected-exceptions.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_fuel\n\nto make a folder called test_fuel in your codespace.\nThen execute\ncd test_fuel\n\nto change directories into that folder. You should now see your terminal prompt as test_fuel/ $. You can now execute\ncode test_fuel.py\n\nto make a file called test_fuel.py where you‚Äôll write your tests.\n\n\n\nTo test your tests, run pytest test_fuel.py. Be sure you have a copy of a fuel.py file in the same folder. Try to use correct and incorrect versions of fuel.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of fuel.py. Run your tests by executing pytest test_fuel.py. pytest should show that all of your tests have passed.\nModify the correct version of fuel.py, changing the return values of convert. Your program might, for example, mistakenly return a str instead of an int. Run your tests by executing pytest test_fuel.py. pytest should show that at least one of your tests has failed.\nSimilarly, modify the correct version of fuel.py, changing the return values of gauge. Your program might, for example, mistakenly omit a % in the resulting str. Run your tests by executing pytest test_fuel.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_5/5.5_refueling.html#hints",
    "href": "problems/pset_5/5.5_refueling.html#hints",
    "title": "Refueling",
    "section": "",
    "text": "Be sure to include\nimport fuel\n\nor\nfrom fuel import convert, gauge\n\natop test_fuel.py so that you can call convert and gauge in your tests.\nTake care to return, not print, an int in convert and a str in gauge. Only main should call print.\nNote that you can raise an exception like ValueError with code like:\nraise ValueError\n\nNote that you can check with pytest whether a function has raised an exception, per docs.pytest.org/en/latest/how-to/assert.html#assertions-about-expected-exceptions."
  },
  {
    "objectID": "problems/pset_5/5.5_refueling.html#before-you-begin",
    "href": "problems/pset_5/5.5_refueling.html#before-you-begin",
    "title": "Refueling",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir test_fuel\n\nto make a folder called test_fuel in your codespace.\nThen execute\ncd test_fuel\n\nto change directories into that folder. You should now see your terminal prompt as test_fuel/ $. You can now execute\ncode test_fuel.py\n\nto make a file called test_fuel.py where you‚Äôll write your tests."
  },
  {
    "objectID": "problems/pset_5/5.5_refueling.html#how-to-test",
    "href": "problems/pset_5/5.5_refueling.html#how-to-test",
    "title": "Refueling",
    "section": "",
    "text": "To test your tests, run pytest test_fuel.py. Be sure you have a copy of a fuel.py file in the same folder. Try to use correct and incorrect versions of fuel.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of fuel.py. Run your tests by executing pytest test_fuel.py. pytest should show that all of your tests have passed.\nModify the correct version of fuel.py, changing the return values of convert. Your program might, for example, mistakenly return a str instead of an int. Run your tests by executing pytest test_fuel.py. pytest should show that at least one of your tests has failed.\nSimilarly, modify the correct version of fuel.py, changing the return values of gauge. Your program might, for example, mistakenly omit a % in the resulting str. Run your tests by executing pytest test_fuel.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_6/6.2_lines_of_code.html",
    "href": "problems/pset_6/6.2_lines_of_code.html",
    "title": "Lines of Code",
    "section": "",
    "text": "One way to measure the complexity of a program is to count its number of lines of code (LOC), excluding blank lines and comments. For instance, a program like\n# Say hello\n\nname = input(\"What's your name? \")\nprint(f\"hello, {name}\")\n\nhas just two lines of code, not four, since its first line is a comment, and its second line is blank (i.e., just whitespace). That‚Äôs not that many, so odds are the program isn‚Äôt that complex. Of course, just because a program (or even function) has more lines of code than another doesn‚Äôt necessarily mean it‚Äôs more complex. For instance, a function like\ndef is_even(n):\n    if n % 2 == 0:\n        return True\n    else:\n        return False\n\nisn‚Äôt really twice as complex as a function like\ndef is_even(n):\n    return n % 2 == 0\n\neven though the former has (more than) twice as many lines of code. In fact, the former might arguably be simpler if it‚Äôs easier to read! So lines of code should be taken with a grain of salt.\nEven so, in a file called lines.py, implement a program that expects exactly one command-line argument, the name (or path) of a Python file, and outputs the number of lines of code in that file, excluding comments and blank lines. If the user does not specify exactly one command-line argument, or if the specified file‚Äôs name does not end in .py, or if the specified file does not exist, the program should instead exit via sys.exit.\nAssume that any line that starts with #, optionally preceded by whitespace, is a comment. (A docstring should not be considered a comment.) Assume that any line that only contains whitespace is blank.\n\n\n\nRecall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including lstrip and startswith.\nNote that open can raise a FileNotFoundError, per docs.python.org/3/library/exceptions.html#FileNotFoundError.\nYou might find it helpful to test your program on, e.g., some of Week 6‚Äôs source code as well as on programs of your own.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir lines\n\nto make a folder called lines in your codespace.\nThen execute\ncd lines\n\nto change directories into that folder. You should now see your terminal prompt as lines/ $. You can now execute\ncode lines.py\n\nto make a file called lines.py where you‚Äôll write your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python lines.py. Your program should exit with sys.exit and provide an error message:\nToo few command-line arguments\n\nCreate two python programs, hello.py and goodbye.py. Run python lines.py hello.py goodbye.py. Your program should exit with sys.exit and provide an error message:\nToo many command-line arguments\n\nCreate a text file called invalid_extension.txt. Run your program with python lines.py invalid_extension.txt. Your program should exit with sys.exit and provide an error message:\nNot a Python file\n\nRun your program with python lines.py non_existent_file.py. Assuming non_existent_file.py doesn‚Äôt exist, your program should exit with sys.exit and provide an error message:\nFile does not exist\n\nCreate additional python programs which vary in complexity: create some with comments, some docstrings, and some whitespace. For each of these files run python lines.py FILENAME where FILENAME is the name of the file. lines.py should output the number of lines, excluding comments and whitespace, present in the given file."
  },
  {
    "objectID": "problems/pset_6/6.2_lines_of_code.html#hints",
    "href": "problems/pset_6/6.2_lines_of_code.html#hints",
    "title": "Lines of Code",
    "section": "",
    "text": "Recall that a str comes with quite a few methods, per docs.python.org/3/library/stdtypes.html#string-methods, including lstrip and startswith.\nNote that open can raise a FileNotFoundError, per docs.python.org/3/library/exceptions.html#FileNotFoundError.\nYou might find it helpful to test your program on, e.g., some of Week 6‚Äôs source code as well as on programs of your own."
  },
  {
    "objectID": "problems/pset_6/6.2_lines_of_code.html#before-you-begin",
    "href": "problems/pset_6/6.2_lines_of_code.html#before-you-begin",
    "title": "Lines of Code",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir lines\n\nto make a folder called lines in your codespace.\nThen execute\ncd lines\n\nto change directories into that folder. You should now see your terminal prompt as lines/ $. You can now execute\ncode lines.py\n\nto make a file called lines.py where you‚Äôll write your program."
  },
  {
    "objectID": "problems/pset_6/6.2_lines_of_code.html#how-to-test",
    "href": "problems/pset_6/6.2_lines_of_code.html#how-to-test",
    "title": "Lines of Code",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python lines.py. Your program should exit with sys.exit and provide an error message:\nToo few command-line arguments\n\nCreate two python programs, hello.py and goodbye.py. Run python lines.py hello.py goodbye.py. Your program should exit with sys.exit and provide an error message:\nToo many command-line arguments\n\nCreate a text file called invalid_extension.txt. Run your program with python lines.py invalid_extension.txt. Your program should exit with sys.exit and provide an error message:\nNot a Python file\n\nRun your program with python lines.py non_existent_file.py. Assuming non_existent_file.py doesn‚Äôt exist, your program should exit with sys.exit and provide an error message:\nFile does not exist\n\nCreate additional python programs which vary in complexity: create some with comments, some docstrings, and some whitespace. For each of these files run python lines.py FILENAME where FILENAME is the name of the file. lines.py should output the number of lines, excluding comments and whitespace, present in the given file."
  },
  {
    "objectID": "problems/pset_6/6.4_scourgify.html",
    "href": "problems/pset_6/6.4_scourgify.html",
    "title": "Scourgify",
    "section": "",
    "text": "‚ÄúAh, well,‚Äù said Tonks, slamming the trunk‚Äôs lid shut, ‚Äúat least it‚Äôs all in. That could do with a bit of cleaning, too.‚Äù She pointed her wand at Hedwig‚Äôs cage. ‚ÄúScourgify.‚Äù A few feathers and droppings vanished.\n‚Äî Harry Potter and the Order of the Phoenix\n\nData, too, often needs to be ‚Äúcleaned,‚Äù as by reformatting it, so that values are in a consistent, if not more convenient, format. Consider, for instance, this CSV file of students, &lt;before.csv&gt;, below:\nname,house\n\"Abbott, Hannah\",Hufflepuff\n\"Bell, Katie\",Gryffindor\n\"Bones, Susan\",Hufflepuff\n\"Boot, Terry\",Ravenclaw\n\"Brown, Lavender\",Gryffindor\n\"Bulstrode, Millicent\",Slytherin\n\"Chang, Cho\",Ravenclaw\n\"Clearwater, Penelope\",Ravenclaw\n\"Crabbe, Vincent\",Slytherin\n\"Creevey, Colin\",Gryffindor\n\"Creevey, Dennis\",Gryffindor\n\"Diggory, Cedric\",Hufflepuff\n\"Edgecombe, Marietta\",Ravenclaw\n\"Finch-Fletchley, Justin\",Hufflepuff\n\"Finnigan, Seamus\",Gryffindor\n\"Goldstein, Anthony\",Ravenclaw\n\"Goyle, Gregory\",Slytherin\n\"Granger, Hermione\",Gryffindor\n\"Johnson, Angelina\",Gryffindor\n\"Jordan, Lee\",Gryffindor\n\"Longbottom, Neville\",Gryffindor\n\"Lovegood, Luna\",Ravenclaw\n\"Lupin, Remus\",Gryffindor\n\"Malfoy, Draco\",Slytherin\n\"Malfoy, Scorpius\",Slytherin\n\"Macmillan, Ernie\",Hufflepuff\n\"McGonagall, Minerva\",Gryffindor\n\"Midgen, Eloise\",Gryffindor\n\"McLaggen, Cormac\",Gryffindor\n\"Montague, Graham\",Slytherin\n\"Nott, Theodore\",Slytherin\n\"Parkinson, Pansy\",Slytherin\n\"Patil, Padma\",Gryffindor\n\"Patil, Parvati\",Gryffindor\n\"Potter, Harry\",Gryffindor\n\"Riddle, Tom\",Slytherin\n\"Robins, Demelza\",Gryffindor\n\"Scamander, Newt\",Hufflepuff\n\"Slughorn, Horace\",Slytherin\n\"Smith, Zacharias\",Hufflepuff\n\"Snape, Severus\",Slytherin\n\"Spinnet, Alicia\",Gryffindor\n\"Sprout, Pomona\",Hufflepuff\n\"Thomas, Dean\",Gryffindor\n\"Vane, Romilda\",Gryffindor\n\"Warren, Myrtle\",Ravenclaw\n\"Weasley, Fred\",Gryffindor\n\"Weasley, George\",Gryffindor\n\"Weasley, Ginny\",Gryffindor\n\"Weasley, Percy\",Gryffindor\n\"Weasley, Ron\",Gryffindor\n\"Wood, Oliver\",Gryffindor\n\"Zabini, Blaise\",Slytherin\n\nSource: en.wikipedia.org/wiki/List_of_Harry_Potter_characters\nEven though each ‚Äúrow‚Äù in the file has three values (last name, first name, and house), the first two are combined into one ‚Äúcolumn‚Äù (name), escaped with double quotes, with last name and first name separated by a comma and space. Not ideal if Hogwarts wants to send a form letter to each student, as via mail merge, since it‚Äôd be strange to start a letter with:\n\nDear Potter, Harry,\n\nRather than with, for instance:\n\nDear Harry,\n\nIn a file called scourgify.py, implement a program that:\n\nExpects the user to provide two command-line arguments:\n\nthe name of an existing CSV file to read as input, whose columns are assumed to be, in order, name and house, and\nthe name of a new CSV to write as output, whose columns should be, in order, first, last, and house.\n\nConverts that input to that output, splitting each name into a first name and last name. Assume that each student will have both a first name and last name.\n\nIf the user does not provide exactly two command-line arguments, or if the first cannot be read, the program should exit via sys.exit with an error message.\n\n\n\nNote that csv module comes with quite a few methods, per docs.python.org/3/library/csv.html, among which are DictReader, per docs.python.org/3/library/csv.html#csv.DictReader and DictWriter, per docs.python.org/3/library/csv.html#csv.DictWriter.\nNote that you can tell a DictWriter to write its fieldnames to a file using writeheader with no arguments, per docs.python.org/3/library/csv.html#csv.DictWriter.writeheader.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir scourgify\n\nto make a folder called scourgify in your codespace.\nThen execute\ncd scourgify\n\nto change directories into that folder. You should now see your terminal prompt as scourgify/ $. You can now execute\ncode scourgify.py\n\nto make a file called scourgify.py where you‚Äôll write your program. Be sure to run\nwget https://cs50.harvard.edu/python/2022/psets/6/scourgify/before.csv\n\nto download &lt;before.csv&gt; into your folder.\n\n\n\nHere‚Äôs how to test your code manually:\n\nRun your program with python scourgify.py. Your program should exit using sys.exit and provide an error message:\nToo few command-line arguments\n\nCreate empty files 1.csv, 2.csv, and 3.csv. Run your program with python scourgify.py 1.csv 2.csv 3.csv. Your program should output:\nToo many command-line arguments\n\nRun your program with python scourgify.py invalid_file.csv output.csv. Assuming invalid_file.csv doesn‚Äôt exist, your program should exit using sys.exit and provide an error message:\nCould not read invalid_file.csv\n\nRun your program with python scourgify.py before.csv after.csv. Assuming before.csv exists, your program should create a new file, after.csv, whose columns should be, in order, first, last, and house."
  },
  {
    "objectID": "problems/pset_6/6.4_scourgify.html#hints",
    "href": "problems/pset_6/6.4_scourgify.html#hints",
    "title": "Scourgify",
    "section": "",
    "text": "Note that csv module comes with quite a few methods, per docs.python.org/3/library/csv.html, among which are DictReader, per docs.python.org/3/library/csv.html#csv.DictReader and DictWriter, per docs.python.org/3/library/csv.html#csv.DictWriter.\nNote that you can tell a DictWriter to write its fieldnames to a file using writeheader with no arguments, per docs.python.org/3/library/csv.html#csv.DictWriter.writeheader."
  },
  {
    "objectID": "problems/pset_6/6.4_scourgify.html#before-you-begin",
    "href": "problems/pset_6/6.4_scourgify.html#before-you-begin",
    "title": "Scourgify",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir scourgify\n\nto make a folder called scourgify in your codespace.\nThen execute\ncd scourgify\n\nto change directories into that folder. You should now see your terminal prompt as scourgify/ $. You can now execute\ncode scourgify.py\n\nto make a file called scourgify.py where you‚Äôll write your program. Be sure to run\nwget https://cs50.harvard.edu/python/2022/psets/6/scourgify/before.csv\n\nto download &lt;before.csv&gt; into your folder."
  },
  {
    "objectID": "problems/pset_6/6.4_scourgify.html#how-to-test",
    "href": "problems/pset_6/6.4_scourgify.html#how-to-test",
    "title": "Scourgify",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nRun your program with python scourgify.py. Your program should exit using sys.exit and provide an error message:\nToo few command-line arguments\n\nCreate empty files 1.csv, 2.csv, and 3.csv. Run your program with python scourgify.py 1.csv 2.csv 3.csv. Your program should output:\nToo many command-line arguments\n\nRun your program with python scourgify.py invalid_file.csv output.csv. Assuming invalid_file.csv doesn‚Äôt exist, your program should exit using sys.exit and provide an error message:\nCould not read invalid_file.csv\n\nRun your program with python scourgify.py before.csv after.csv. Assuming before.csv exists, your program should create a new file, after.csv, whose columns should be, in order, first, last, and house."
  },
  {
    "objectID": "problems/pset_7/7.2_numb3rs.html",
    "href": "problems/pset_7/7.2_numb3rs.html",
    "title": "NUMB3RS",
    "section": "",
    "text": "In Season 5, Episode 23 of NUMB3RS, a supposed IP address appears on screen, 275.3.6.28, which isn‚Äôt actually a valid IPv4 (or IPv6) address.\nAn IPv4 address is a numeric identifier that a device (or, on TV, hacker) uses to communicate on the internet, akin to a postal address in the real world, typically formatted in dot-decimal notation as #.#.#.#. But each # should be a number between 0 and 255, inclusive. Suffice it to say 275 is not in that range! If only NUMB3RS had validated the address in that scene!\nIn a file called numb3rs.py, implement a function called validate that expects an IPv4 address as input as a str and then returns True or False, respectively, if that input is a valid IPv4 address or not.\nStructure numb3rs.py as follows, wherein you‚Äôre welcome to modify main and/or implement other functions as you see fit, but you may not import any other libraries. You‚Äôre welcome, but not required, to use re and/or sys.\nimport re\nimport sys\n\n\ndef main():\n    print(validate(input(\"IPv4 Address: \")))\n\n\ndef validate(ip):\n    ...\n\n\n...\n\n\nif __name__ == \"__main__\":\n    main()\n\nEither before or after you implement validate in numb3rs.py, additionally implement, in a file called test_numb3rs.py, two or more functions that collectively test your implementation of validate thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_numb3rs.py\n\n\n\n\nRecall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including search.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns, else pytest will warn with DeprecationWarning: invalid escape sequence. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that re.search, if passed a pattern with ‚Äúcapturing groups‚Äù (i.e., parentheses), returns a ‚Äúmatch object,‚Äù per docs.python.org/3/library/re.html#match-objects, wherein matches are 1-indexed, which you can access individually with group, per docs.python.org/3/library/re.html#re.Match.group, or collectively with groups, per docs.python.org/3/library/re.html#re.Match.groups.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir numb3rs\n\nto make a folder called numb3rs in your codespace.\nThen execute\ncd numb3rs\n\nto change directories into that folder. You should now see your terminal prompt as numb3rs/ $. You can now execute\ncode numb3rs.py\n\nto make a file called numb3rs.py where you‚Äôll write your program. Be sure to also execute\ncode test_numb3rs.py\n\nto create a file called test_numb3rs.py where you‚Äôll write tests for your program.\n\n\n\n\n\nHere‚Äôs how to test numb3rs.py manually:\n\nRun your program with python numb3rs.py. Ensure your program prompts you for an IPv4 address. Type 127.0.0.1, followed by Enter. Your validate function should return True.\nRun your program with python numb3rs.py. Type 255.255.255.255, followed by Enter. Your validate function should return True.\nRun your program with python numb3rs.py. Type 512.512.512.512, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type 1.2.3.1000, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type 192.168.001.1, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type cat, followed by Enter. Your validate function should return False.\n\nWhile leading zeros in IP addresses are technically possible in some contexts, they are generally discouraged due to potential ambiguity. For this problem, treat them as invalid. If you‚Äôd like to learn more about IP address formatting standards, see RFC 3986, Section 7.4.\n\n\n\nTo test your tests, run pytest test_numb3rs.py. Try to use correct and incorrect versions of numb3rs.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of numb3rs.py. Run your tests by executing pytest test_numb3rs.py. pytest should show that all of your tests have passed.\nModify the validate function in the correct version of numb3rs.py. validate might, for example, only check whether the first byte of the IPv4 address is valid. Run your tests by executing pytest test_numb3rs.py. pytest should show that at least one of your tests has failed.\nAgain modify the correct version of numb3rs.py. validate might, for example, mistakenly return True when the user inputs an incorrect IPv4 format. Run your tests by executing pytest test_numb3rs.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_7/7.2_numb3rs.html#hints",
    "href": "problems/pset_7/7.2_numb3rs.html#hints",
    "title": "NUMB3RS",
    "section": "",
    "text": "Recall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including search.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns, else pytest will warn with DeprecationWarning: invalid escape sequence. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that re.search, if passed a pattern with ‚Äúcapturing groups‚Äù (i.e., parentheses), returns a ‚Äúmatch object,‚Äù per docs.python.org/3/library/re.html#match-objects, wherein matches are 1-indexed, which you can access individually with group, per docs.python.org/3/library/re.html#re.Match.group, or collectively with groups, per docs.python.org/3/library/re.html#re.Match.groups."
  },
  {
    "objectID": "problems/pset_7/7.2_numb3rs.html#before-you-begin",
    "href": "problems/pset_7/7.2_numb3rs.html#before-you-begin",
    "title": "NUMB3RS",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir numb3rs\n\nto make a folder called numb3rs in your codespace.\nThen execute\ncd numb3rs\n\nto change directories into that folder. You should now see your terminal prompt as numb3rs/ $. You can now execute\ncode numb3rs.py\n\nto make a file called numb3rs.py where you‚Äôll write your program. Be sure to also execute\ncode test_numb3rs.py\n\nto create a file called test_numb3rs.py where you‚Äôll write tests for your program."
  },
  {
    "objectID": "problems/pset_7/7.2_numb3rs.html#how-to-test",
    "href": "problems/pset_7/7.2_numb3rs.html#how-to-test",
    "title": "NUMB3RS",
    "section": "",
    "text": "Here‚Äôs how to test numb3rs.py manually:\n\nRun your program with python numb3rs.py. Ensure your program prompts you for an IPv4 address. Type 127.0.0.1, followed by Enter. Your validate function should return True.\nRun your program with python numb3rs.py. Type 255.255.255.255, followed by Enter. Your validate function should return True.\nRun your program with python numb3rs.py. Type 512.512.512.512, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type 1.2.3.1000, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type 192.168.001.1, followed by Enter. Your validate function should return False.\nRun your program with python numb3rs.py. Type cat, followed by Enter. Your validate function should return False.\n\nWhile leading zeros in IP addresses are technically possible in some contexts, they are generally discouraged due to potential ambiguity. For this problem, treat them as invalid. If you‚Äôd like to learn more about IP address formatting standards, see RFC 3986, Section 7.4.\n\n\n\nTo test your tests, run pytest test_numb3rs.py. Try to use correct and incorrect versions of numb3rs.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of numb3rs.py. Run your tests by executing pytest test_numb3rs.py. pytest should show that all of your tests have passed.\nModify the validate function in the correct version of numb3rs.py. validate might, for example, only check whether the first byte of the IPv4 address is valid. Run your tests by executing pytest test_numb3rs.py. pytest should show that at least one of your tests has failed.\nAgain modify the correct version of numb3rs.py. validate might, for example, mistakenly return True when the user inputs an incorrect IPv4 format. Run your tests by executing pytest test_numb3rs.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_7/7.4_regular_um_expressions.html",
    "href": "problems/pset_7/7.4_regular_um_expressions.html",
    "title": "Regular, um, Expressions",
    "section": "",
    "text": "It‚Äôs not uncommon, in English, at least, to say ‚Äúum‚Äù when trying to, um, think of a word. The more you do it, though, the more noticeable it tends to be!\nIn a file called um.py, implement a function called count that expects a line of text as input as a str and returns, as an int, the number of times that ‚Äúum‚Äù appears in that text, case-insensitively, as a word unto itself, not as a substring of some other word. For instance, given text like hello, um, world, the function should return 1. Given text like yummy, though, the function should return 0.\nStructure um.py as follows, wherein you‚Äôre welcome to modify main and/or implement other functions as you see fit, but you may not import any other libraries. You‚Äôre welcome, but not required, to use re and/or sys.\nimport re\nimport sys\n\n\ndef main():\n    print(count(input(\"Text: \")))\n\n\ndef count(s):\n    ...\n\n\n...\n\n\nif __name__ == \"__main__\":\n    main()\n\nEither before or after you implement count in um.py, additionally implement, in a file called test_um.py, three or more functions that collectively test your implementation of count thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_um.py\n\n\n\n\nRecall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including findall.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that \\b is ‚Äúdefined as the boundary between a \\w and a \\W character (or vice versa), or between \\w at the beginning/end of the string,‚Äù per docs.python.org/3/library/re.html#regular-expression-syntax.\nYou might find regex101.com or regexr.com helpful for testing regular expressions (and visualizing matches).\nSee thefreedictionary.com/words-containing-um for some words that contain ‚Äúum‚Äù.\n\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir um\n\nto make a folder called um in your codespace.\nThen execute\ncd um\n\nto change directories into that folder. You should now see your terminal prompt as um/ $. You can now execute\ncode um.py\n\nto make a file called um.py where you‚Äôll write your program. Be sure to also execute\ncode test_um.py\n\nto create a file called test_um.py where you‚Äôll, um, write tests for your program.\n\n\n\n\n\nHere‚Äôs how to test um.py manually:\n\nRun your program with python um.py. Ensure your program prompts you for an input. Type um, followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type um?, followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type Um, thanks for the album., followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type Um, thanks, um..., followed by Enter. Your count function should return 2.\n\n\n\n\nTo test your tests, run pytest test_um.py. Try to use correct and incorrect versions of um.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of um.py. Run your tests by executing pytest test_um.py. pytest should show that all of your tests have passed.\nModify the count function in the correct version of um.py. count might, for example, mistakently also count any ‚Äúum‚Äù that is part of a word. Run your tests by executing pytest test_um.py. pytest should show that at least one of your tests has failed.\nAgain modify the count function in the correct version of um.py. count might, for example, mistakenly only match an ‚Äúum‚Äù that is surrounded on either side by a space. Run your tests by executing pytest test_um.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_7/7.4_regular_um_expressions.html#hints",
    "href": "problems/pset_7/7.4_regular_um_expressions.html#hints",
    "title": "Regular, um, Expressions",
    "section": "",
    "text": "Recall that the re module comes with quite a few functions, per docs.python.org/3/library/re.html, including findall.\nRecall that regular expressions support quite a few special characters, per docs.python.org/3/library/re.html#regular-expression-syntax.\nBecause backslashes in regular expressions could be mistaken for escape sequences (like \\n), best to use Python‚Äôs raw string notation for regular expression patterns. Just as format strings are prefixed with f, so are raw strings prefixed with r. For instance, instead of \"harvard\\.edu\", use r\"harvard\\.edu\".\nNote that \\b is ‚Äúdefined as the boundary between a \\w and a \\W character (or vice versa), or between \\w at the beginning/end of the string,‚Äù per docs.python.org/3/library/re.html#regular-expression-syntax.\nYou might find regex101.com or regexr.com helpful for testing regular expressions (and visualizing matches).\nSee thefreedictionary.com/words-containing-um for some words that contain ‚Äúum‚Äù."
  },
  {
    "objectID": "problems/pset_7/7.4_regular_um_expressions.html#before-you-begin",
    "href": "problems/pset_7/7.4_regular_um_expressions.html#before-you-begin",
    "title": "Regular, um, Expressions",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir um\n\nto make a folder called um in your codespace.\nThen execute\ncd um\n\nto change directories into that folder. You should now see your terminal prompt as um/ $. You can now execute\ncode um.py\n\nto make a file called um.py where you‚Äôll write your program. Be sure to also execute\ncode test_um.py\n\nto create a file called test_um.py where you‚Äôll, um, write tests for your program."
  },
  {
    "objectID": "problems/pset_7/7.4_regular_um_expressions.html#how-to-test",
    "href": "problems/pset_7/7.4_regular_um_expressions.html#how-to-test",
    "title": "Regular, um, Expressions",
    "section": "",
    "text": "Here‚Äôs how to test um.py manually:\n\nRun your program with python um.py. Ensure your program prompts you for an input. Type um, followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type um?, followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type Um, thanks for the album., followed by Enter. Your count function should return 1.\nRun your program with python um.py. Type Um, thanks, um..., followed by Enter. Your count function should return 2.\n\n\n\n\nTo test your tests, run pytest test_um.py. Try to use correct and incorrect versions of um.py to determine how well your tests spot errors:\n\nEnsure you have a correct version of um.py. Run your tests by executing pytest test_um.py. pytest should show that all of your tests have passed.\nModify the count function in the correct version of um.py. count might, for example, mistakently also count any ‚Äúum‚Äù that is part of a word. Run your tests by executing pytest test_um.py. pytest should show that at least one of your tests has failed.\nAgain modify the count function in the correct version of um.py. count might, for example, mistakenly only match an ‚Äúum‚Äù that is surrounded on either side by a space. Run your tests by executing pytest test_um.py. pytest should show that at least one of your tests has failed."
  },
  {
    "objectID": "problems/pset_7/pset_7.html",
    "href": "problems/pset_7/pset_7.html",
    "title": "Problem Set week 7",
    "section": "",
    "text": "Complete the following problems\n\nNUMB3RS\nWorking 9 to 5\nRegular, um, Expressions\nResponse Validation",
    "crumbs": [
      "Problem Sets",
      "Problem Set 07 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_7/pset_7.html#what-to-do",
    "href": "problems/pset_7/pset_7.html#what-to-do",
    "title": "Problem Set week 7",
    "section": "",
    "text": "Complete the following problems\n\nNUMB3RS\nWorking 9 to 5\nRegular, um, Expressions\nResponse Validation",
    "crumbs": [
      "Problem Sets",
      "Problem Set 07 ü§ñ"
    ]
  },
  {
    "objectID": "problems/pset_8/8.3_cookie_jar.html",
    "href": "problems/pset_8/8.3_cookie_jar.html",
    "title": "Cookie Jar",
    "section": "",
    "text": "Cookie Monster\n\n\nSource: Sesame Street\nSuppose that you‚Äôd like to implement a cookie jar in which to store cookies. In a file called jar.py, implement a class called Jar with these methods:\n\n__init__ should initialize a cookie jar with the given capacity, which represents the maximum number of cookies that can fit in the cookie jar. If capacity is not a non-negative int, though, __init__ should instead raise a ValueError.\n__str__ should return a str with (n) üç™, where (n) is the number of cookies in the cookie jar. For instance, if there are 3 cookies in the cookie jar, then str should return \"üç™üç™üç™\"\ndeposit should add n cookies to the cookie jar. If adding that many would exceed the cookie jar‚Äôs capacity, though, deposit should instead raise a ValueError.\nwithdraw should remove n cookies from the cookie jar. Nom nom nom. If there aren‚Äôt that many cookies in the cookie jar, though, withdraw should instead raise a ValueError.\ncapacity should return the cookie jar‚Äôs capacity.\nsize should return the number of cookies actually in the cookie jar, initially 0.\n\nStructure your class per the below. You may not alter these methods‚Äô parameters, but you may add your own methods.\nclass Jar:\n    def __init__(self, capacity=12):\n        ...\n\n    def __str__(self):\n        ...\n\n    def deposit(self, n):\n        ...\n\n    def withdraw(self, n):\n        ...\n\n    @property\n    def capacity(self):\n        ...\n\n    @property\n    def size(self):\n        ...\n\nEither before or after you implement jar.py, additionally implement, in a file called test_jar.py, four or more functions that collectively test your implementation of Jar thoroughly, each of whose names should begin with test_ so that you can execute your tests with:\npytest test_jar.py\n\nNote that it‚Äôs not as easy to test instance methods as it is to test functions alone, since instance methods sometimes manipulate the same ‚Äústate‚Äù (i.e., instance variables). To test one method (e.g., withdraw), then, you might need to call another method first (e.g., deposit). But the method you call first might itself not be correct!\nAnd so programmers sometimes mock (i.e., simulate) state when testing methods, as with Python‚Äôs own mock object library, so that you can call just the one method but modify the underlying state first, without calling the other method to do so.\nFor simplicity, though, no need to mock any state. Implement your tests as you normally would!\n\n\nfrom jar import Jar\n\n\ndef test_init():\n    ...\n\n\ndef test_str():\n    jar = Jar()\n    assert str(jar) == \"\"\n    jar.deposit(1)\n    assert str(jar) == \"üç™\"\n    jar.deposit(11)\n    assert str(jar) == \"üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™\"\n\n\ndef test_deposit():\n    ...\n\n\ndef test_withdraw():\n    ...\n\nYou‚Äôre welcome, but not required, to implement a main function, so this is all we can demo!\n\n\n\nCookie Monster\n\n\nSource: Sesame Street\n\n\n\nExecute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir jar\n\nto make a folder called jar in your codespace.\nThen execute\ncd jar\n\nto change directories into that folder. You should now see your terminal prompt as jar/ $. You can now execute\ncode jar.py\n\nto make a file called jar.py where you‚Äôll write your program. You can also execute\ncode test_jar.py\n\nto create a file called test_jar.py where you can write tests for your program.\n\n\n\nHere‚Äôs how to test your code manually:\n\nOpen your test_jar.py file and import your Jar class with from jar import Jar. Create a function called test_init, wherein you create a new instance of Jar with jar = Jar(). assert that this jar has the capacity it should, then run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_str. In test_str, create a new instance of your Jar class and deposit a few cookies. assert that str(jar) prints out as many cookies as have been deposited, then run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_deposit. In test_deposit, create a new instance of your Jar class and deposit a few cookies. assert that the jar‚Äôs size attribute is as large as the number of cookies that have been deposited.¬†Also assert that, if you deposit more than the jar‚Äôs capacity, deposit should raise a ValueError. Run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_withdraw. In test_withdraw, create a new instance of your Jar class and first deposit a few cookies. assert that withdrawing from the jar leaves the appropriate number of cookies in the jar‚Äôs size attribute. Also assert that, if you withdraw more than the jar‚Äôs size, withdraw should raise a ValueError. Run your tests with pytest test_jar.py."
  },
  {
    "objectID": "problems/pset_8/8.3_cookie_jar.html#hints",
    "href": "problems/pset_8/8.3_cookie_jar.html#hints",
    "title": "Cookie Jar",
    "section": "",
    "text": "from jar import Jar\n\n\ndef test_init():\n    ...\n\n\ndef test_str():\n    jar = Jar()\n    assert str(jar) == \"\"\n    jar.deposit(1)\n    assert str(jar) == \"üç™\"\n    jar.deposit(11)\n    assert str(jar) == \"üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™üç™\"\n\n\ndef test_deposit():\n    ...\n\n\ndef test_withdraw():\n    ...\n\nYou‚Äôre welcome, but not required, to implement a main function, so this is all we can demo!\n\n\n\nCookie Monster\n\n\nSource: Sesame Street"
  },
  {
    "objectID": "problems/pset_8/8.3_cookie_jar.html#before-you-begin",
    "href": "problems/pset_8/8.3_cookie_jar.html#before-you-begin",
    "title": "Cookie Jar",
    "section": "",
    "text": "Execute cd by itself in your terminal window. You should find that your terminal window‚Äôs prompt resembles the below:\n$\n\nNext execute\nmkdir jar\n\nto make a folder called jar in your codespace.\nThen execute\ncd jar\n\nto change directories into that folder. You should now see your terminal prompt as jar/ $. You can now execute\ncode jar.py\n\nto make a file called jar.py where you‚Äôll write your program. You can also execute\ncode test_jar.py\n\nto create a file called test_jar.py where you can write tests for your program."
  },
  {
    "objectID": "problems/pset_8/8.3_cookie_jar.html#how-to-test",
    "href": "problems/pset_8/8.3_cookie_jar.html#how-to-test",
    "title": "Cookie Jar",
    "section": "",
    "text": "Here‚Äôs how to test your code manually:\n\nOpen your test_jar.py file and import your Jar class with from jar import Jar. Create a function called test_init, wherein you create a new instance of Jar with jar = Jar(). assert that this jar has the capacity it should, then run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_str. In test_str, create a new instance of your Jar class and deposit a few cookies. assert that str(jar) prints out as many cookies as have been deposited, then run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_deposit. In test_deposit, create a new instance of your Jar class and deposit a few cookies. assert that the jar‚Äôs size attribute is as large as the number of cookies that have been deposited.¬†Also assert that, if you deposit more than the jar‚Äôs capacity, deposit should raise a ValueError. Run your tests with pytest test_jar.py.\nAdd another function to your test_jar.py file called test_withdraw. In test_withdraw, create a new instance of your Jar class and first deposit a few cookies. assert that withdrawing from the jar leaves the appropriate number of cookies in the jar‚Äôs size attribute. Also assert that, if you withdraw more than the jar‚Äôs size, withdraw should raise a ValueError. Run your tests with pytest test_jar.py."
  }
]