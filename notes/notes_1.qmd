# Week 01 — Introducing generative AI

![](images/week_01/fig_01.png){fig-alt="AI slop" width="500"}

> "...use your existing Python expertise alongside AI that understands your code context..."

## Overview

> "Supercharge your coding with AI" "No AI expertise is required." -Some AI Bro

In this week we introduce **generative AI** as a practical toolset for real software development. The goal is not to turn you into an ML creator. The goal is to help you build code solutions, with less busywork, and fewer defects.

### What you should get out of this week

-   A working definition of **generative AI** in the context of programming work.
-   A map of the *developer tool landscape* (general chat models vs IDE assistants vs specialist tools).
-   A mental model for *how LLMs work* at a useful, developer-friendly level.
-   A realistic view of benefits *and* failure modes (hallucinations, shallow tests, brittle outputs).

------------------------------------------------------------------------

## 1.0 Why this matters for "Real World AI"

The week frames AI coding tools as an "extra pair of hands" for experienced developers. The promise is not magic — it’s leverage:

-   faster scaffolding
-   faster iteration
-   earlier bug discovery
-   improved test coverage

> "...reduced implementation time by approximately 30%, while improving code quality..."

The course lens: *real world* means we care about:

-   practical constraints
-   maintainability
-   security
-   correctness
-   team workflows

------------------------------------------------------------------------

## 1.1 Generative AI for coders

### What is generative AI

**Generative AI** refers to models that *produce new content* (text, code, images) based on learned patterns. For coding, the relevant output types are:

-   code snippets (functions, classes, scripts)
-   refactors (changing structure without changing behaviour)
-   tests (unit tests, fuzz tests, property-based tests)
-   documentation (docstrings, READMEs, API docs)

### The most common coding use-cases

This week highlights several practical use cases. We’ll treat these as *work modes* you can switch between.

#### 1) Code generation and autocompletion

This is the "pair programmer" mode. You describe what you want, and the tool produces starter code.

Key reality check:

-   generated code is rarely perfect
-   it is *often plausible*
-   you must still review and test

> "...anticipates patterns, and generates implementation details..."

#### 2) Bug detection and automated fixes

Tools can propose patches quickly — especially for:

-   common exceptions
-   misuse of APIs
-   off-by-one errors
-   missing edge-case handling

But: AI doesn’t *understand* your logic. It matches patterns. If your bug is domain-specific, AI help may be weaker.

#### 3) Documentation generation

AI is good at turning code into:

-   docstrings
-   usage examples
-   “how it works” summaries

The risk is **confident incorrectness**. Docs can become wrong faster than code. So you should treat AI-generated docs as a *draft*, not truth.

#### 4) Refactoring and optimisation

AI can help with:

-   extracting helper functions
-   renaming variables for clarity
-   reorganising modules
-   performance suggestions

But optimisation suggestions can be dangerous if they change semantics. Always lock behaviour first with tests.

#### 5) Test generation and mock data

AI is useful for producing *lots of tests quickly*. This is a big deal because tests are often the bottleneck.

However:

-   AI tests can be shallow
-   AI may test implementation details instead of behaviour

So we’ll keep a rule of thumb:

> Test behaviour, not the code’s current shape.

------------------------------------------------------------------------

## 1.2 Developer tools landscape

This week separates tools into categories. You should be able to explain *what each category is good for*.

### General-purpose chat models

These include ChatGPT / Claude-style assistants. They are good for:

-   explaining concepts
-   drafting code in isolation
-   brainstorming designs
-   generating documentation

But they can struggle with:

-   large codebases
-   project-wide refactors
-   keeping context consistent

### IDE-based assistants

These integrate into editors (VS Code, JetBrains, etc.). They can:

-   autocomplete in-place
-   understand surrounding code context
-   suggest local refactors

### Specialised coding tools

Some tools focus on a specific workflow:

-   code search + fixes
-   security checks
-   test generation

This week calls out tools like Cursor, Blackbox AI, and Tabnine later. Your skill as a developer is choosing the *right tool* for the task.

> "...practical guide to using AI tools to supercharge your coding..."

------------------------------------------------------------------------

## 1.3 How does generative AI work?

This is the part where people often get intimidated. This week's key message is:

-   you don’t need the math
-   you do need the mental model

We’ll focus on what helps you predict failure modes.

### A useful mental model

Think of a large language model (LLM) as:

-   a probability engine over sequences of tokens
-   trained to predict “what comes next”

It does not “know” facts the way humans do. It generates outputs that are statistically likely given its training.

### The three-layer story (developer-friendly)

This week describes internal steps like:

-   input embedding (tokens → vectors)
-   transformer layers (attention)
-   output decoding (vectors → tokens)

We’ll capture this with a diagram.

```{mermaid}
flowchart LR
  A[Input prompt] --> B[Tokenisation]
  B --> C[Embeddings]
  C --> D[Transformer layers<br/>attention + feedforward]
  D --> E[Next-token probabilities]
  E --> F[Sampling / decoding]
  F --> G[Output text/code]
```

> "An LLM is a deep learning architecture based on the Transformer model..."

### Why attention matters

Attention is what allows the model to:

-   “focus” on relevant parts of the prompt
-   relate tokens across distance
-   keep patterns consistent (sometimes!)

When you see a model forget instructions, it’s often because:

-   the prompt was too long
-   the instruction got buried
-   the model weighted other tokens as more relevant

------------------------------------------------------------------------

## 1.4 What an LLM is (and isn’t)

### What it *is*

An LLM is a model trained on huge amounts of text and code. It learns patterns like:

-   how functions are structured
-   how docs are written
-   how bugs are commonly fixed
-   how tests are typically expressed

### What it *isn’t*

It is not:

-   a compiler
-   a proof system
-   a deterministic system
-   a guaranteed factual source

This week hints at the most important practical issue:

-   outputs can be *fluent* and *wrong*

> "...determines whether 'this is most likely to be correct and functional source code'"

------------------------------------------------------------------------

## 1.5 The potential of LLMs

This is where this week is optimistic. The potential is that AI tools can shift your role upward:

-   from typing code → designing systems
-   from debugging syntax → validating behaviour
-   from writing boilerplate → reviewing structure

### What “potential” looks like in practice

It usually means:

-   faster first drafts
-   earlier working prototypes
-   more time spent on architecture

But only if you adopt a workflow that includes:

-   review
-   tests
-   iteration

------------------------------------------------------------------------

## 1.6 Generative AI vs code completion

Many students confuse these. This week draws a distinction:

### Traditional code completion

-   rule-based or simple statistical
-   local suggestions
-   limited context

### Generative AI

-   can produce *novel* combinations
-   can respond to higher-level instructions
-   can create multi-file scaffolds

> "Unlike traditional code completion... generative AI creates..."

The key point:

**Generative AI is a collaborator**. **Code completion is a convenience feature**.

------------------------------------------------------------------------

## 1.7 Other types of generative AI (quick map)

Even though this week is coding-focused, generative AI includes:

-   image generation
-   audio generation
-   video generation

Why you should care:

-   real products combine modalities
-   documentation and UI work often needs imagery

------------------------------------------------------------------------

## 1.8 Project workflow with AI assistance

This is the most “real world” section. It breaks software development into stages where AI can help.

### Stage 1: Ideation and planning

Where AI helps:

-   brainstorming features
-   generating user stories
-   drafting requirements

Risk:

-   “feature creep” (AI happily invents scope)

### Stage 2: Code generation and assistance

Where AI helps:

-   scaffolding projects
-   drafting modules
-   writing repetitive code

Risk:

-   inconsistent design decisions
-   hidden complexity

### Stage 3: Code review and analysis

Where AI helps:

-   spotting style issues
-   suggesting simplifications
-   identifying missing error handling

Risk:

-   false confidence (the model sounds sure)

### Stage 4: Testing and debugging

Where AI helps:

-   generating test cases
-   suggesting likely failure points
-   explaining stack traces

Risk:

-   shallow tests that don’t reflect real requirements

### Stage 5: Documentation and content generation

Where AI helps:

-   explaining APIs
-   improving README clarity
-   generating examples

Risk:

-   docs drift from reality

> "This cycle creates a powerful symbiotic relationship..."

------------------------------------------------------------------------

## 1.9 Choosing the right generative AI tools

This week emphasises selection criteria. In real teams, you choose tools based on:

-   **integration** (does it fit your IDE/workflow?)
-   **context** (does it see your project?)
-   **privacy** (can you send code externally?)
-   **quality** (accuracy + helpfulness)

### Practical checklist

-   Does it understand multi-file projects?
-   Does it support test generation?
-   Does it help you refactor safely?
-   Does it provide citations or traceability?

------------------------------------------------------------------------

## 1.10 Common failure modes (what students must learn)

This week implies several failure modes. We make them explicit because they will recur all term.

### Hallucination

The model invents:

-   nonexistent functions
-   wrong APIs
-   fake “facts”

Mitigation:

-   verify against docs
-   run the code
-   write tests

### Overfitting to your prompt

Sometimes your prompt “accidentally” forces a weird design. Mitigation:

-   ask for alternatives
-   request tradeoffs
-   iterate

### Weak testing

AI-generated tests often:

-   only test “happy path”
-   mirror implementation details

Mitigation:

-   use boundary cases
-   test behaviour
-   add negative tests

------------------------------------------------------------------------

## 1.11 Go forth and code!

This final section is motivational. This week's message is:

-   don’t fear the tools
-   treat them as assistants
-   keep your engineering discipline

------------------------------------------------------------------------



## Example 1: A simple "AI as refactor assistant" workflow

```python
# A tiny refactor candidate

def total_cost(prices, tax_rate):
    # NOTE: intentionally minimal
    return sum(prices) * (1 + tax_rate)

print(total_cost([10, 20, 30], 0.2))
```

## Example 2: Turning a prompt into a structured specification

```python
from dataclasses import dataclass

@dataclass
class FeatureSpec:
    name: str
    user_story: str
    acceptance_criteria: list[str]

spec = FeatureSpec(
    name="Export report as CSV",
    user_story="As a user, I want to export my report so I can analyse it in Excel.",
    acceptance_criteria=[
        "Export button downloads a .csv file",
        "CSV includes headers",
        "Handles empty datasets gracefully",
    ],
)

print(spec)
```

## Example 3: A minimal test-first habit

```python
# Simple behaviour test (no frameworks yet)

def add(a, b):
    return a + b

assert add(2, 3) == 5
assert add(-1, 1) == 0
print("All tests passed")
```

------------------------------------------------------------------------

# Summing up

-   **Generative AI** can improve coding productivity, but it must be combined with testing and review.
-   The developer tool landscape includes chat models, IDE assistants, and specialised coding tools.
-   LLMs are probabilistic systems (fluent but not guaranteed correct).
-   Real-world workflows use AI across ideation, implementation, review, testing, and documentation.

